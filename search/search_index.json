{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"about/","title":"Acerca de mi","text":""},{"location":"home/","title":"Portal de estudio y notas Eddier Ocampo Mar\u00edn","text":"<p>Este micrositio est\u00e1 dise\u00f1ado para el estudio y practica de las certificaciones y estudios.</p>"},{"location":"planning/","title":"Planeaci\u00f3n","text":""},{"location":"planning/#semanal","title":"Semanal","text":"Time MON TUE WEM THU FRI Weekend 03:15 OCP 4.X English Satellite English Ansible 5:15 Meditaci\u00f3n 14:00 English"},{"location":"planning/#_1","title":"Planning","text":"Objetivo Fecha Objetivo % Avance Certificaci\u00f3n C2 Ingl\u00e9s Noviembre 2024 RHEL (Training) RHEL Automation with Ansible (Training) Manage Enterprise Automation with RH-AAP (Training) Developing Advanced Automation with RH-AAP (Training) Red Hat Satellite 6 Administration (Training) Red Hat OpenShift Administration (Training) Red Hat OpenShift Administration II Red Hat OpenShift Development I"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/","title":"Red Hat Certified System Administrator (RHCSA) exam","text":""},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#puntos-del-examen","title":"Puntos del ex\u00e1men","text":""},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#entender-el-uso-esencial-de-las-herramientas","title":"Entender el uso esencial de las herramientas","text":"Objetivo Estado Acceder a Shell prompt y ejecutar comandos con la sintaxis correcta Usar input-output  de redirecci\u00f3n '(&gt;, &gt;&gt;,|, 2&gt;, etc.)' Acceso remoto a systemas usando SSH Log in y switch de usuarios en obketivos multiusuario Archivar, comprimir, descomprimir y descomprimir archivos mediante tar, gzip y bzip2. Crear y editar archivos de texto Crear, eliminar, copiar y mover archivos y directorios. Crear enlaces hard y soft Listar, establecer y cambiar permisos est\u00e1ndar ugo/rwx Localizar, leer y utilizar documentaci\u00f3n del sistema, incluyendo man, info y archivos en /usr/share/doc"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#crear-shell-scripts-simples","title":"Crear shell scripts simples","text":"Objetivo Estado Ejecutar c\u00f3digo condicionalmente (uso de: if, test, [], etc.) Uso de construcciones en bucle (for, etc.) para procesar entradas de archivos o l\u00edneas de comandos Procesar intputs de script ($1, $2, etc.) Procesar outputs de comandos de shell dentro de un script"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#operar-sistemas-en-ejecucion","title":"Operar sistemas en ejecuci\u00f3n","text":"Objetivo Estado Boot, reinicio y apagado del sistema normalmente Boot con diferente objetivo manualmente Interrrumpir el boot para acceder al sistema Identificar procesos itensivos de CPU/memoria y matarlos Ajustar la programaci\u00f3n de procesos Gestionar el ajuste de perfiles Localizar e interpretar los logs del sistema y diarios Iniciar, detener y verificar el estado de los servicios de red Transferir archivos entre sistemas de forma segura"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#configurar-storage-local","title":"Configurar Storage local","text":"Objetivo Estado Listar, crear y eliminar particiones en discos MBR y GPT Crear y eliminar vol\u00famenes f\u00edsicos Asignar vol\u00famenes f\u00edsicos a grupos de vol\u00famenes Crear y eliminar vol\u00famenes l\u00f3gicos Configurar sistemas para montar sistemas de archivos en el boot por ID \u00fanico universal (UUID) o etiqueta A\u00f1adir nuevas particiones y vol\u00famenes l\u00f3gicos, e intercambiar a un sistema de forma no destructiva"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#crear-y-configurar-sistemas-de-archivos","title":"Crear y configurar sistemas de archivos","text":"Objetivo Estado Crear, montar, desmontar y utilizar sistemas de archivos vfat, ext4 y xfs Montar y desmontar sistemas de archivos de red mediante NFS Configuraci\u00f3n de autofs Ampliar vol\u00famenes l\u00f3gicos existentes Crear y configurar directorios set-GID para colaboraci\u00f3n Diagnosticar y corregir problemas de permisos de archivos"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#despliegue-configuracion-y-mantenimiento-de-sistemas","title":"Despliegue, configuraci\u00f3n y mantenimiento de sistemas","text":"Objetivo Estado Programar tareas mediante at y cron Iniciar y detener servicios y configurar servicios para que se inicien autom\u00e1ticamente en el arranque Configurar sistemas para que arranquen autom\u00e1ticamente en un destino espec\u00edfico Configurar clientes de servicios horarios Instalar y actualizar paquetes de software desde Red Hat Network, un repositorio remoto o desde el sistema de archivos local Modificar el gestor de arranque del sistema"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#administracion-de-redes-basicas","title":"Administraci\u00f3n de redes (b\u00e1sicas)","text":"Objetivo Estado Configurar direcciones IPv4 e IPv6 Configurar la resoluci\u00f3n de nombres de host Configurar los servicios de red para que se inicien autom\u00e1ticamente al arrancar Restringir el acceso a la red mediante firewall-cmd/firewall"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#administrar-usuarios-y-grupos","title":"Administrar usuarios y grupos","text":"Objetivo Estado Crear, eliminar y modificar cuentas de usuario locales Cambiar contrase\u00f1as y ajustar el tiempo de caducidad de las contrase\u00f1as de las cuentas de usuario locales Crear, eliminar y modificar grupos locales y pertenencias a grupos Configurar el acceso de superusuario"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#administracion-de-seguridad","title":"Administraci\u00f3n de seguridad","text":"Objetivo Estado Configurar el firewall con firewall-cmd/firewalld Gesti\u00f3n de permisos de archivos por defecto Configurar la autenticaci\u00f3n basada en claves para SSH Establecer modos de aplicaci\u00f3n y permisivos para SELinux Enumerar e identificar contextos de archivos y procesos SELinux Restaurar contextos de archivo predeterminados Gesti\u00f3n de etiquetas de puertos SELinux Utilizar configuraciones booleanas para modificar la configuraci\u00f3n de SELinux del sistema Diagnosticar y resolver infracciones rutinarias de la pol\u00edtica SELinux"},{"location":"01_redhat/01-RH199/01-EX200_RHCSA/#administracion-de-containers","title":"Administraci\u00f3n de containers","text":"Objetivo Estado Buscar y recuperar im\u00e1genes de contenedores de un registro remoto Inspeccionar im\u00e1genes de contenedores Realizar la gesti\u00f3n de contenedores utilizando comandos como podman y skopeo Construir un contenedor a partir de un archivo de contenedor Realizar la gesti\u00f3n b\u00e1sica de contenedores como ejecutar, iniciar, detener y listar contenedores en ejecuci\u00f3n Ejecutar un servicio dentro de un contenedor Configurar un contenedor para que se inicie autom\u00e1ticamente como un servicio systemd Adjuntar almacenamiento persistente a un contenedor"},{"location":"01_redhat/01-RH199/01-RH199_C1/","title":"Cap\u00edtulo 1 - Sistema de accesos y obtener soporte","text":""},{"location":"01_redhat/01-RH199/01-RH199_C1/#edicion-de-texto-desde-el-shell","title":"Edici\u00f3n de texto desde el Shell","text":"<ul> <li>Se utiliza el editor vim</li> <li>Tiene el modo visual (se activa al digitar la letra v) y el modo comandos (nativamente al ingresar)</li> <li>Presionando la tecla ESC unos segundos puede regresar al modo comandos.</li> </ul>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#the-minimum-basic-vim-workflow","title":"The Minimum, Basic Vim Workflow","text":"Letra Acci\u00f3n u Deshace la \u00faltima acci\u00f3n x Borra solo 1 caracter :w Solo guarda los cambios :wq Guarda los cambios y sale del editor :q! Salir sin guardar y \u00f3 'ESC y'  p \u00f3 'ESC  p' Selecciona varias filas seleccionadas y las almacena en memoria  Pega las filas seleccionadas"},{"location":"01_redhat/01-RH199/01-RH199_C1/#vim-configuration-files","title":"Vim Configuration Files","text":"<pre><code>    $ cat /etc/vimrc\n    $ cat ~/.vimrc\n</code></pre> <p>Vim Reference Manual: Vim Options https://vimhelp.org/options.txt.html#options.txt</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#configure-ssh-key-based-authentication","title":"Configure SSH Key-based Authentication","text":"<p>Configurar llaves de acceso basadas en autenticaci\u00f3n sin utilizar password</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#se-guardan-por-defecto-en","title":"Se guardan por defecto en:","text":"<pre><code>    $ cat ~/.ssh/id_rsa\n    $ cat ~/.ssh/id_rsa.pub\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#generation-share-the-public-key-non-interactive-troubleshooting","title":"Generation, Share the Public Key, Non-interactive, Troubleshooting","text":"Comando Acci\u00f3n ssh-keygen Genera la la llave p\u00fablica y la privada: en el proceso puede asignarle un password llamado passphrase ssh-keygen -f .ssh/nombre_llave Argumento -f para cambiar el nombre de las llaves ssh-copy-id -i .ssh/key-with-pass.pub user@remotehost Comparte la llave p\u00fablica en host remoto  NOTA: Si la llave tiene passphrase, se debe escribir la primera ves eval $(ssh-agent) Iniciar el programa ssh-agent ssh-add Cargar manualmente su passphrase de llave privada a ~/.ssh/ id_rsa ssh -i .ssh/key-with-pass user@remotehost Argumento -i sirve para conectarse utilizando una llave espec\u00edfica ssh -v user@remotehost Argumento -v para realizar Troubleshooting, puede hasta 3 niveles <p>NOTA: Durante la creaci\u00f3n si ya existe unas llaves con nombres por defecto, estos se reemplazan</p> <p>#### SSH Client Configuration</p> <pre><code>    $ cat ~/.ssh/config\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#create-a-diagnostics-report","title":"Create a Diagnostics Report","text":""},{"location":"01_redhat/01-RH199/01-RH199_C1/#resources-on-the-red-hat-customer-portal","title":"Resources on the Red Hat Customer Portal","text":"<p>The Red Hat Customer Portal https://access.redhat.com</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#navigate-the-red-hat-customer-portal-menus","title":"Navigate the Red Hat Customer Portal Menus","text":"Categories Descriopci\u00f3n Products &amp; Services Informaci\u00f3n de productos y servicios con sus gui\u00edas Tools Herramientas de ayuda para los productos RH Security Acceso al centro de productos de seguridad para productos RH Comunity Portal de comunidades, foros"},{"location":"01_redhat/01-RH199/01-RH199_C1/#contact-red-hat-customer-support","title":"Contact Red Hat Customer Support","text":"<p>Apertura de casos de soporte para productos con suscripci\u00f3n</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#prepare-a-support-case","title":"Prepare a Support Case","text":"<ol> <li>Definir el problema especificando los s\u00edntomas</li> <li>Recopilar la informaci\u00f3n de referencia: version de producto, un SOS Report, etc</li> <li> <p>Determinar la severidad del caso</p> <p>3.1. Urgent (severidad 1)</p> <p>3.2. High (severidad 2)</p> <p>3.3. Medium (severidad 3)</p> <p>3.4. Low (severidad 4)</p> </li> </ol>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#generate-an-sos-report-with-the-web-console","title":"Generate an sos Report with the Web Console","text":"<ul> <li>Login con usuario root, consola en el servidor local (https://localhost:9090) en el apartado Diagnostic Reports</li> <li> <p>Instalar el paquete y luego genera el reporte</p> <pre><code>        [root@host ~]# dnf install sos\n        [root@host ~]# sos report\n</code></pre> </li> <li> <p>Validar si el servicio est\u00e9 arriba:</p> <pre><code>        [root@host ~]# systemctl status cockpit.socket\n</code></pre> </li> </ul>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#referencias","title":"Referencias:","text":"<p>Contacting Red Hat Technical Support</p> <p>Help - Red Hat Customer Portal</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#detect-and-resolve-issues-with-red-hat-insights","title":"Detect and Resolve Issues with Red Hat Insights","text":"<p>Red Hat Insights es una herramienta de analisis predictivo que ayuda a identificar y remediar brechas de seguridad, performance, diponibilidad y estabilidad de los sistemas en la infraestructura de los productos Red Hat. Realiza recomendaciones sobre:</p> <ul> <li>Red Hat Enterprise Linux 6.4 and later</li> <li>Red Hat Virtualization</li> <li>Red Hat Satellite 6 and later</li> <li>Red Hat OpenShift Container Platform</li> <li>Red Hat OpenStack Platform 7 and later</li> <li>Red Hat Ansible Automation Platform</li> </ul> <p>Insights high-level architecture</p> <p></p> Comando Acci\u00f3n insights-client Refrescar la metadata del cliente subscription-manager register --auto-attach Registra el sistema interactivamente en RHSM dnf install insights-client instala el cliente en el sistema insights-client --register registra el sistema en servicio Insight <p>En Red Hat Insights https://console.redhat.com/insights se valida el estaod de los sistemas.</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#referencias_1","title":"Referencias:","text":"<p>For more information about Red Hat Insights, refer to the Product Documentation for Red Hat Insights</p> <p>For more information about excluding data that Insights collects, refer to the Red Hat Insights Client Data Obfuscation and Red Hat Insights Client Data Redaction chapters in the Client Configuration Guide for Red Hat Insights</p> <p>Information about the data that Red Hat Insights collects is available System Information Collected by Red Hat Insights</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#manage-files-from-the-command-line","title":"Manage Files from the Command Line","text":""},{"location":"01_redhat/01-RH199/01-RH199_C1/#describe-linux-file-system-hierarchy-concepts","title":"Describe Linux File System Hierarchy Concepts","text":"<p>La forma es como almacena los archivos en el sistema de manera organizada y con un \u00fanico \u00e1rbol de jerarqu\u00eda</p>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#make-links-between-files","title":"Make Links Between Files","text":"Comando Acci\u00f3n Tipo de Link ln file.txt /path_target/file-hl2.txt crea el hard link Hard Link ln -il file.txt /path_target/file-hl2.txt muestra el # de inodo Hard Link ln -s ~/newfile-l2.txt /tmp/newfile-symlink.txt Crea el link simb\u00f3lico Symbolic Link"},{"location":"01_redhat/01-RH199/01-RH199_C1/#limitaciones","title":"Limitaciones","text":"<ul> <li>Hard link Solo funciona con archivos regulares, no se puede usar con directorios</li> <li>Se pueden utilizar si ambos pertenecen al mismo sistema de archivos en hard link</li> <li>Un hard link dirige un nombre a los datos de un dispositivo de almacenamiento.</li> <li>Un link simb\u00f3lico apunta un nombre a otro nombre, que apunta a datos en un dispositivo de almacenamiento.</li> </ul>"},{"location":"01_redhat/01-RH199/01-RH199_C1/#match-file-names-with-shell-expansions","title":"Match File Names with Shell Expansions","text":"Comando Acci\u00f3n mkdir glob ; cd glob ; puede unir varias lineas touch alfa bravo charlie delta en el ejemplo, el comando touch crea tanto archivos como la lista separada por espacio ls a* lista el contenido que inicia con letra a ls a Lista todo lo que contenga la letra a ls [ac]* Todo lo contenga las letras a o c ls ???? muestra el contenido que por nombre temga 4 caracteres echo {Sunday,Monday,Tuesday,Wednesday}.log en el ejemplo echo imprime cada archivo nombrado entre los corchetes echo file{1..3}.txt imprime los archivos del 1 al 3 echo file{a..c}.txt muestra los archivos de la a la c echo file{a,b}{1,2}.txt muestra concatenando las agrupaciones de cada contenido de corchetes echo file{a{1,2},b,c}.txt concatena de interno a externo"},{"location":"01_redhat/01-RH199/01-RH199_C10/","title":"Capitulo 10 - Gesti\u00f3n de Almacenamiento (Storage)","text":""},{"location":"01_redhat/01-RH199/01-RH199_C10/#crear-extender-volumenes-logicos","title":"Crear &amp; Extender volumenes l\u00f3gicos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C11/","title":"Capitulo 11 - Servicios de Control y Procesos de Boot","text":""},{"location":"01_redhat/01-RH199/01-RH199_C11/#identificacion-de-procesos-de-inicio-automatico-del-sistema","title":"Identificaci\u00f3n de Procesos de Inicio Autom\u00e1tico del Sistema","text":""},{"location":"01_redhat/01-RH199/01-RH199_C11/#servicios-de-control-del-sistema","title":"Servicios de Control del Sistema","text":""},{"location":"01_redhat/01-RH199/01-RH199_C11/#seleccion-del-boot","title":"Selecci\u00f3n del Boot","text":""},{"location":"01_redhat/01-RH199/01-RH199_C11/#reset-password-root","title":"Reset Password Root","text":""},{"location":"01_redhat/01-RH199/01-RH199_C11/#reparar-problemas-del-sistema-de-archivos-en-el-boot","title":"Reparar problemas del sistema de archivos en el Boot","text":""},{"location":"01_redhat/01-RH199/01-RH199_C12/","title":"Capitulo 12 - An\u00e1lisis y Almacenamiento de Logs","text":""},{"location":"01_redhat/01-RH199/01-RH199_C12/#describir-la-arquitectura-del-systema-de-log","title":"Describir la Arquitectura del Systema de Log","text":""},{"location":"01_redhat/01-RH199/01-RH199_C12/#revision-de-archivos-de-syslog","title":"Revisi\u00f3n de Archivos de Syslog","text":""},{"location":"01_redhat/01-RH199/01-RH199_C12/#revision-de-entradas-del-sistema-journal","title":"Revisi\u00f3n de Entradas del Sistema Journal","text":""},{"location":"01_redhat/01-RH199/01-RH199_C12/#conservar-el-sistema-journal","title":"Conservar el Sistema Journal","text":""},{"location":"01_redhat/01-RH199/01-RH199_C12/#mantenimiento-de-sincronizacion-de-tiempo","title":"Mantenimiento de Sincronizaci\u00f3n de Tiempo","text":""},{"location":"01_redhat/01-RH199/01-RH199_C13/","title":"Capitulo 13 - Administraci\u00f3n de Redes (Networking)","text":""},{"location":"01_redhat/01-RH199/01-RH199_C13/#validacion-de-configuracion-de-red","title":"Validaci\u00f3n de Configuraci\u00f3n de Red","text":""},{"location":"01_redhat/01-RH199/01-RH199_C13/#configuracion-de-networking-desde-cli","title":"Configuraci\u00f3n de Networking desde CLI","text":""},{"location":"01_redhat/01-RH199/01-RH199_C13/#modificar-archivos-de-configuracion-de-red","title":"Modificar Archivos de Configuraci\u00f3n de Red","text":""},{"location":"01_redhat/01-RH199/01-RH199_C13/#configuracion-de-hostname-resolucion-de-nombre","title":"Configuraci\u00f3n de Hostname &amp; Resoluci\u00f3n de Nombre","text":""},{"location":"01_redhat/01-RH199/01-RH199_C14/","title":"Capitulo 14 - Acceso de Almacenamiento de Red","text":""},{"location":"01_redhat/01-RH199/01-RH199_C14/#administrar-almacenamiento-de-red-con-nfs","title":"Administrar Almacenamiento de red con NFS","text":""},{"location":"01_redhat/01-RH199/01-RH199_C14/#automontaje-de-almacenamiento-de-red","title":"Automontaje de Almacenamiento de Red","text":""},{"location":"01_redhat/01-RH199/01-RH199_C15/","title":"Capitulo 15 - Administraci\u00f3n de Seguridad de Red","text":""},{"location":"01_redhat/01-RH199/01-RH199_C15/#administracion-de-servidor-de-firewalls","title":"Administraci\u00f3n de Servidor de Firewalls","text":""},{"location":"01_redhat/01-RH199/01-RH199_C15/#control-de-etiquetas-labels-de-puertos-selinux","title":"Control de Etiquetas (Labels) de puertos SELinux","text":""},{"location":"01_redhat/01-RH199/01-RH199_C16/","title":"Capitulo 16 - Ejecuci\u00f3n de contenedores","text":""},{"location":"01_redhat/01-RH199/01-RH199_C16/#contenedores-conceptos","title":"Contenedores: Conceptos","text":"<p>Tradicionalmente, el Software es instalado sobre el Sistema Operativo de un servidor dependiendo all\u00ed de librer\u00edas, archivos de configuraci\u00f3n, servicios y mas, ya sea ese SO sobre una m\u00e1quina f\u00edsica o virtual. Los sysadmin de SO son los que administran los paquetes sobre el RHEL validando las dependencias de los mismos, por lo tanto una dependencia de las versiones y librerias de la aplicaci\u00f3n debe ser precisa y mantenerse en el tiempo.</p> <p>Para resolver los anteriores obt\u00e1culos, un camino es desplegar la aplicaci\u00f3n como contenedor. En RHEL   se usan las siguientes tecnolog\u00edas:</p> <ul> <li>Gesti\u00f3n de recursos Control Groups (cgroups)</li> <li>Separar procesos Isolaci\u00f3n por Namespace</li> <li>Fortalecer las bondades de seguridad con SELinux y Seccomp (Secure Computing mode)</li> </ul> <p></p> M\u00e1quinas Virtuales Containers Habilitar muchos SO simultaneamente en ejecuci\u00f3n de 1 solo HW Se ejecuta directamente el el SO del hosts Se usa el hipervisor para dividir virtualmente el HW El Kernel del host se comparte, pero las im\u00e1genes son independientes del resto del sistema Requiere un ambiente completo de SO para soportar la aplicaci\u00f3n Requiere menos recursos de HW que una VM Incluye todas las dependencias"},{"location":"01_redhat/01-RH199/01-RH199_C16/#rootless-rootful","title":"Rootless &amp; Rootful","text":"<p>En un host de contenedores, se puede ejecutar como root o como un usuario regular sin permisos.rootless el contenedor se ejecuta sin permisos de ejecuci\u00f3n de root. rootful es un contenedor con permisos de ejecuci\u00f3n de root</p> <p>### Arquitectura Base de contenedor</p> <p>Los contenedores son creados y dise\u00f1ados para ser portables, moverlos entre ambientes y tener muchas versiones. El contenedor es ef\u00edmero/temporal</p> <p>### Herramientas de gesti\u00f3n de contenedores</p> <p>RHEL tiene varias herramientas entre ellas: podman (gesti\u00f3n de contenedores e im\u00e1genes), skopeo (revisi\u00f3n, copias, eliminar y asignar im\u00e1genes) y buildah (crear imagenes de contenedores)</p>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#imagenes-de-contenedor-registries","title":"Imagenes de contenedor &amp; Registries","text":"<p>Para ejecutar un contenedor debe usarse una imagen de contenedor. Es un archivo con los pasos espec\u00edficos para crear el contenedor que contiene una imagen base, dependencias y librer\u00edas. Son compatibles y creados bajo las especificaciones OCI (Open Container Initiative) la cual definen el formato.</p> <p>Un Container Registry es un repositorio para almacenar las im\u00e1genes. Se cargan o descragan imagenes para crear imagenes personalizadas y cargarlas en el sistema local. existen Registries p\u00fablicos como privados, tambi\u00e9n con im\u00e1genes de terceros.</p> <p>Red Hat distribuye imagenes de contenedores certificadas y se puede acceder a 2 sitios disponibles - registry.redhat.io (para contenedores bsados en productos oficiales RH) - registry.connect.redhat.com  para contenedores basados en productos de 3eros</p> <p>NOTA: La imagen base de Red Hat se llama UBI (Universal Base Image)</p> <p>Para conectarse y luego realizar descarga de imagenes, a contimuaci\u00f3n unos ejemplos:</p> <pre><code>[eocampo@aap ~]$ podman login registry.redhat.io\nUsername: *****\nPassword: *****\nLogin Succeeded!\n\n[eocampo@aap ~]$ podman login registry.redhat.io --username ***** \n\n[eocampo@aap ~]$ echo $PASSWORDVAR podman login --username ***** --password-stdin registry.access.redhat.com\n ```\nPara verificar el login se usa el sigueinet comando: ***podman login registry.access.redhat.com --get-login***\n\n### Configurar Container Registries\n\nEl archivo de configuraci\u00f3n por default est\u00e1 en **/etc/containers/registries.conf**. Se recomienda crear un archivo con un usuario sin privilegios para cada registry en el HOME de ese usuario *$HOME/.config/containers* con el nombre **registries.conf**. Se debe especificar el fqn de la imagen del contenedor usar\u00e1 el por default por ello siempre se reocmienda usar el fqn completo. Ejemplo:\n\n```bash\n[eocampo@aap ~]$ podman pull registry.access.redhat.com/ubi8/ubi:latest\n</code></pre> <p>Para configurar el registry en el archivo utilice la siguiente estructura:</p> <pre><code>[[registry]]\nlocation = \"registry.lab.example.com\"\ninsecure = true\nblocked = false\n</code></pre> <p>Donde location especifica la ubicaci\u00f3 del registry, insecure si desea usar (true) encripci\u00f3n HTTP con cifrado TLS (false si no se desea usar) y blocked para bloquear la descarga de im\u00e1genes, ejemplo:</p>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#archivos-de-contenedor-para-construir-imagenes-de-contenedor","title":"Archivos de Contenedor para construir imagenes de contenedor","text":"<p>Un container file e s un archivo de texto con instrucciones  para crear una imagen de contenedor. El resultado ser\u00e1 capas de solo lectura donde cada capa representa una instrucci\u00f3n</p> <pre><code>FROM registry.access.redhat.com/ubi8/ubi:latest\nRUN dnf install -y python3\nCMD [\"/bin/bash\", \"-c\", \"echo hello\"]\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#gestion-de-escalamiento-de-contenedores","title":"Gesti\u00f3n de escalamiento de contenedores","text":""},{"location":"01_redhat/01-RH199/01-RH199_C16/#despliegue-de-contenedores","title":"Despliegue de Contenedores","text":""},{"location":"01_redhat/01-RH199/01-RH199_C16/#podman","title":"Podman","text":"<p>Podman es una utilidad de ingenier\u00eda con todas las caracter\u00edsticas de los paquetes OCI para construir im\u00e1genes, no se usa como un demonio en en el SO o una funci\u00f3n, y no es necesario tener privilegios de root paea su ejecuci\u00f3n. </p> <p>Comandos:</p> Comando Descripci\u00f3n podman build Construir imagen de contenedor con un archivo podman run Comando para ejecutar un nuevo contenedor podman images Listar todas las imagenes del storage local podman ps Imprimir informaci\u00f3n acerca de los contenedores podman inspect Mostrar la configuraci\u00f3n de un contenedor, imagen, volumen, network, o pod podman pull Descargar imagen del registry podman cp Copiar archivos o directorios entre un contenedor y el sistema local de archivos podman exec Ejecuta un comando en un contenedor en ejecuci\u00f3n podman rm Elimina uno o mas contenedores podman rmi Elimina uno o mas imagenes del storage locak podman search Busca en el registry para una imagen <p>Para mas informaci\u00f3n se puede hacer una llamado al manual de podman (podman-build man). Un contenedor con base RHEL 8 UBI tiene el paquete python-38</p>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#instalar-utilidades-de-contenedores","title":"Instalar utilidades de Contenedores","text":"<p>container-tools es un meta-paquete que contiene las utilidades requeridas para interactuar con contenedores. Descarga, ejcuta y compara contenedores en su SO. Instalarlo con el siguiente comando:</p> <pre><code>[eocampo@aap ~]$ dnf install container-tools\n[eocampo@aap ~]$ dnf info container-tools$\n...output omitted...\nSummary     : A meta-package witch container tools such as podman, buildah,\n            : skopeo, etc.\nLicense     : MIT\nDescription : Latest versions of podman, buildah, skopeo, runc, conmon, CRIU,\n            : Udica, etc as well as dependencies such as container-selinux\n            : built and tested together, and updated.\n...output omitted...\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#desdecarga-de-imagen-de-contendor-desde-el-registry","title":"Desdecarga de imagen de contendor desde el registry","text":"<ol> <li>Primero se debe validar que las herramientas est\u00e1n instaladas </li> <li>Buscar las imagenes disponibles con el nombre</li> <li>Usar skopeo inspect para examinar diferentes formatos de imagenes de contenedores desde el directorio local o el registry remoto</li> <li>Descargar la imagen elegida, en este caso registry.access.redhat.com/ubi8/python-38</li> <li>Validar la lista de im\u00e1genes</li> </ol> <pre><code>[eocampo@aap ~]$ podman info (1)\n[eocampo@aap ~]$ podman search python-38 (2)\n[eocampo@aap ~]$ skopeo inspect docker://registry.access.redhat.com/ubi8/python-38 (3)\n[eocampo@aap ~]$ podman pull registry.access.redhat.com/ubi8/python-38 (4)\n[eocampo@aap ~]$ podman images\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#crear-imagen-de-contenedor-desde-un-archivo-container-file","title":"Crear imagen de contenedor desde un archivo (Container File)","text":"<p>El nombre del archivo ser\u00e1 siempre Containerfile. Utiliza la imagen base del registry de Red Hat, instalar\u00e1 la versi\u00f3n de python36 y luego ejecutar\u00e1 un sleep infinity y su contenido ser\u00e1 asi:</p> <pre><code>FROM registry.access.redhat.com/ubi8/ubi:latest\nRUN dnf install -y python36\nCMD [\"/bin/bash\", \"-c\", \"sleep infinity\"]\n</code></pre> <p>Para crear la imagen se utiliza el comando build </p> <pre><code>[eocampo@aap ~]$ podman build -t NAME:TAG DIR\n</code></pre> <p>NAME: Nombre para la nueva imagen TAG:  Tag para la nueva imagen DIR:  Path de trabajo del directorio. Si el el mismo donde est\u00e1 el archivo se agrega . (punto)</p> <pre><code>[eocampo@aap ~]$  podman build -t python36:1.0 .\nSTEP 1/3: FROM registry.access.redhat.com/ubi8/ubi:latest\nSTEP 2/3: RUN dnf install -y python36\n...output omitted...\nSTEP 3/3: CMD [\"/bin/bash\", \"-c\", \"sleep infinity\"]\nCOMMIT python36:1.0\n--&gt; 35ab820880f\nSuccessfully tagged localhost/python36:1.0\n35ab820880f1708fa310f835407ffc94cb4b4fe2506b882c162a421827b156fc\n</code></pre> <p>La \u00faltima linea del output muestra el ID de la imagen del contenedor. Podman solo muestra los primeros 12 caracteres para referirse a la imagen. Se usa para verificar que la imagen est\u00e9 creada</p> <pre><code>[eocampo@aap ~]$ podman images\n[eocampo@aap ~]$ podman inspect localhost/python36:1.0\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#ejecutar-contenedores","title":"Ejecutar contenedores","text":"Estado Descripci\u00f3n Created Contenedor es creado pero no iniciado Running Contenedor est\u00e1 en ejecuci\u00f3n Stopped Contenedor est\u00e1 detenido Paused Contenedor est\u00e1 en procoso pausado. No soportado para rootless Deleted Contenedor en inactividad <p>Se puede utilizar podman create y al final agregar el ID del contendor de la imagen a utilizar. Luego se utiliza podman start y el nombre del contenedor</p> <pre><code>[eocampo@aap ~]$ podman create --name python36 dd6ca291f097\n[eocampo@aap ~]$ podman ps\n[eocampo@aap ~]$ podman ps -a\n[eocampo@aap ~]$ podman start python36\n</code></pre>"},{"location":"01_redhat/01-RH199/01-RH199_C16/#gestion-de-almacenamiento-storage-de-contenedores-recursos-de-red","title":"Gesti\u00f3n de Almacenamiento (Storage) de Contenedores &amp; Recursos de Red","text":""},{"location":"01_redhat/01-RH199/01-RH199_C16/#administracion-de-contenedores-como-servicio-del-sistema","title":"Administraci\u00f3n de Contenedores como Servicio del Sistema","text":""},{"location":"01_redhat/01-RH199/01-RH199_C2/","title":"Capitulo 2 - Gesti\u00f3n de Archivos desde CLI","text":""},{"location":"01_redhat/01-RH199/01-RH199_C2/#conceptos-de-jerarquia-del-sistema-de-archivos","title":"Conceptos de Jerarqu\u00eda del Sistema de Archivos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C2/#crear-enlaces-entre-archivos","title":"Crear enlaces entre archivos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C2/#match-de-nombres-de-archivos-con-expresiones-shell","title":"Match de Nombres de Archivos con Expresiones Shell","text":""},{"location":"01_redhat/01-RH199/01-RH199_C3/","title":"Capitulo 3 - Gesti\u00f3n de Usuarios Locales &amp; Grupos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C3/#conceptos-de-usuarios-grupos","title":"Conceptos de Usuarios &amp; Grupos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C3/#acceso-de-superusuario","title":"Acceso de superusuario","text":""},{"location":"01_redhat/01-RH199/01-RH199_C3/#gestion-de-cuentas-locales-de-usuario","title":"Gesti\u00f3n de Cuentas Locales de Usuario","text":""},{"location":"01_redhat/01-RH199/01-RH199_C3/#gestion-de-cuentas-locales-de-grupo","title":"Gesti\u00f3n de Cuentas Locales de Grupo","text":""},{"location":"01_redhat/01-RH199/01-RH199_C3/#gestion-de-password-de-usuario","title":"Gesti\u00f3n de Password de Usuario","text":""},{"location":"01_redhat/01-RH199/01-RH199_C4/","title":"Capitulo 4 - Control de Acceso a Archivos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C4/#gestion-de-permisos-en-el-sistema-de-archivos-desde-cli","title":"Gesti\u00f3n de Permisos en el Sistema de Archivos desde ClI","text":""},{"location":"01_redhat/01-RH199/01-RH199_C4/#gestion-default-de-permisos-y-acceso-de-archivos","title":"Gesti\u00f3n Default de Permisos y Acceso de Archivos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C5/","title":"Capitulo 5 - Gesti\u00f3n de Seguridad SELinux","text":""},{"location":"01_redhat/01-RH199/01-RH199_C5/#cambie-el-modo-de-aplicacion-de-selinux","title":"Cambie el modo de aplicaci\u00f3n de SELinux","text":""},{"location":"01_redhat/01-RH199/01-RH199_C5/#control-de-los-contextos-de-archivos-selinux","title":"Control de los contextos de archivos SELinux","text":""},{"location":"01_redhat/01-RH199/01-RH199_C5/#ajustar-la-politica-selinux-con-booleanos","title":"Ajustar la pol\u00edtica SELinux con booleanos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C5/#investigar-y-resolver-problemas-de-selinux","title":"Investigar y resolver problemas de SELinux","text":""},{"location":"01_redhat/01-RH199/01-RH199_C6/","title":"Capitulo 6 - Ajustar Rendimiento del Sistema","text":""},{"location":"01_redhat/01-RH199/01-RH199_C6/#kill-de-procesos","title":"Kill de Procesos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C6/#monitor-de-procesos","title":"Monitor de Procesos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C6/#ajustes-rendimiento-de-perfiles","title":"Ajustes Rendimiento de Perfiles","text":""},{"location":"01_redhat/01-RH199/01-RH199_C6/#influir-en-la-programacion-de-procesos","title":"Influir en la programaci\u00f3n de procesos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C7/","title":"Capitulo 7 -  Programaci\u00f3n de Tareas","text":""},{"location":"01_redhat/01-RH199/01-RH199_C7/#progranar-tareas-frecuentes-de-usuarios","title":"Progranar tareas frecuentes de usuarios","text":""},{"location":"01_redhat/01-RH199/01-RH199_C7/#progranar-tareas-frecuentes-del-sistema","title":"Progranar tareas frecuentes del Sistema","text":""},{"location":"01_redhat/01-RH199/01-RH199_C7/#gestion-de-archivos-temporales","title":"Gesti\u00f3n de Archivos Temporales","text":""},{"location":"01_redhat/01-RH199/01-RH199_C8/","title":"Capitulo 8 - Instalar &amp; Actualizar Paquetes de Software","text":""},{"location":"01_redhat/01-RH199/01-RH199_C8/#sistema-de-registro-para-soporte-de-red-hat","title":"Sistema de registro para soporte de Red Hat","text":""},{"location":"01_redhat/01-RH199/01-RH199_C8/#instalar-actualizar-paquetes-de-software-con-dnf","title":"Instalar &amp; Actualizar Paquetes de Software con DNF","text":""},{"location":"01_redhat/01-RH199/01-RH199_C8/#habilitar-repositorios-dnf-de-software","title":"Habilitar Repositorios DNF de Software","text":""},{"location":"01_redhat/01-RH199/01-RH199_C9/","title":"Capitulo 9 - Gesti\u00f3n B\u00e1sica de Almacenamiento (Storage)","text":""},{"location":"01_redhat/01-RH199/01-RH199_C9/#montar-y-desmontar-sistema-de-archivos","title":"Montar y desmontar sistema de archivos","text":""},{"location":"01_redhat/01-RH199/01-RH199_C9/#agregar-particiones-sistemas-de-archivos-montajes-persistentes","title":"Agregar Particiones, Sistemas de Archivos &amp; Montajes persistentes","text":""},{"location":"01_redhat/01-RH199/01-RH199_C9/#gestion-de-swap","title":"Gesti\u00f3n de Swap","text":""},{"location":"01_redhat/01-RH199/02-RH199/","title":"Red Hat Enterprise Linux 9.0 (RH199)","text":"<p>RHCSA Rapid Track - Edition 6</p>"},{"location":"01_redhat/01-RH199/03-RH199_notes/","title":"Review System Journal Entries","text":"<pre><code>    journalctl\n    journalctl -n 5\n    journalctl -f\n    journalctl -p err\n    journalctl -u sshd.service\n    journalctl --since today\n    journalctl --since \"2024-02-07 14:00\" --until \"2024-02-07 16:00\"\n    journalctl --since \"1 hour\"\n</code></pre>"},{"location":"01_redhat/02-RH294/01-RH294/","title":"RH294 - Red Hat Enterprise Linux Automation with Ansible","text":""},{"location":"01_redhat/02-RH294/02-RHELAA_notes/","title":"Notas de pr\u00e1ctica","text":""},{"location":"01_redhat/02-RH294/02-RHELAA_notes/#comandos","title":"Comandos","text":"<pre><code>dnf install ansible-core\nansible --version\n\ndnf install ansible-navigator\nansible-navigator --version\n\npodman login registry.redhat.io\npodman pull registry.redhat.io/ansible-automation-platform-22/ee-supported-rhel8:latest\n\nansible-navigator images\n\nansible-navigator inventory\nansible-navigator inventory -m stdout --host fqdn_host\nansible-navigator inventory -m stdout --list\nansible-navigator inventory -m stdout --graph group_name\n\nansible-navigator run  -m stdout name.yml\nansible-navigator run  -m stdout name.yml --syntax-check\nansible-navigator run  -m stdout name.yml --check\n\nansible-navigator doc -l\n\n</code></pre>"},{"location":"01_redhat/02-RH294/02-RHELAA_notes/#archivos-de-configuracion-base-de-proyecto","title":"Archivos de configuraci\u00f3n base de proyecto","text":"<ul> <li>ansible.cfg</li> <li>ansible-navigator.yml</li> </ul> <p>Se configuran 2 tipos de variables en ansible.cfg</p> [defaults] [privilege_escalation] inventory = ./inventory become = true remote_user = user become_method = sudo ask_pass = false become_user = root become_ask_pass = false"},{"location":"01_redhat/02-RH294/02-RHELAA_notes/#modulos","title":"Modulos","text":"Categor\u00eda Modulo Files ansible.builtin.copy: Copy a local file to the managed host. ansible.builtin.file: Set permissions and other properties of files. ansible.builtin.lineinfile: Ensure a particular line is or is not in a file. ansible.posix.synchronize: Synchronize content using rsync. Software ansible.builtin.package: Manage packages using the automatically detected package manager native to the operating system. ansible.builtin.dnf: Manage packages using the DNF package manager. ansible.builtin.apt: Manage packages using the APT package manager. ansible.builtin.pip: Manage Python packages from PyPI. System ansible.posix.firewalld: Manage arbitrary ports and services using firewalld. ansible.builtin.reboot: Reboot a machine. ansible.builtin.service: Manage services. ansible.builtin.user: Add, remove, and manage user accounts. Net Tools ansible.builtin.get_url: Download files over HTTP, HTTPS, or FTP. ansible.builtin.uri: Interact with web services. run command arbitrary ansible.builtin.command ansible.builtin.shell"},{"location":"01_redhat/03-DO467/01-DO467/","title":"Managing Enterprise Automation with Red Hat Ansible Automation Platform","text":""},{"location":"01_redhat/03-DO467/RHAAP_notes/","title":"Notas de estudio","text":""},{"location":"01_redhat/03-DO467/RHAAP_notes/#guias-de-referencia","title":"Gu\u00edas de referencia","text":"<ul> <li>Red Hat Ansible Automation Platform Planning Guide</li> <li>Automation Controller Administration Guide</li> </ul>"},{"location":"01_redhat/03-DO467/RHAAP_notes/#pasos-generales","title":"Pasos generales","text":"<ol> <li>Instalaci\u00f3n de SO</li> <li>Registro de subscripci\u00f3n RHEL</li> <li>Crear Allocation un CDN</li> <li>Crear usuario en registry.io</li> <li>Validaci\u00f3n de Pre-requisitos (este paso se puede automatizar)</li> <li>Evaluar el mecanismo de salida a internet</li> <li>Puertos de Firewall</li> <li>update de SO</li> <li>Validar salida a puertos espec\u00edficos</li> <li>Validar la salida a URL</li> <li>Validar capacidades de disco.</li> <li>Validar capacidades de CPU, RAM y Swap</li> <li>Validar ping por IP y por fqdn completo</li> <li>Instalaci\u00f3n (Desde el controller1 ejecutar)</li> <li>Instalar paquetes base ansible-core y podman</li> <li>Crear carpeta AAP/ansible</li> <li></li> </ol> <p>Todo lo anterior con buenas pr\u00e1cticas aplicadas</p>"},{"location":"01_redhat/03-DO467/RHAAP_notes/#pre-instalacion","title":"Pre-instalaci\u00f3n","text":"<ol> <li>Desde el controller 1 realizar todas las validaciones iniciales</li> </ol> <p>Instalaci\u00f3n de paquetes base</p> <pre><code>   [root@controller1 ~]# dnf install ansible-core\n   [root@controller1 ~]# dnf install podman\n</code></pre> <p>Crear carpeta para repositorio de fuentes</p> <pre><code>    [root@controller1 ~]# mkdir -p AAP/playbooks\n    [root@controller1 ~]# touch AAP/inventory\n</code></pre> <p>Generar inventario y realizar prueba de acceso</p> <pre><code>    [root@controller1 ~]# cat &lt;&lt; 'EOF' &gt; AAP/inventory\n    controller1.lab\n    controller2.lab\n    db.lab\n    ah.lab\n    ed.lab\n    EOF\n    [root@controller1 ~]# ansible all  -i AAP/inventory -m ansible.builtin.ping  -u root -k\n</code></pre> <p>Crear usuario con full permisos en todas las m\u00e1quinas</p> <pre><code>    ---\n    name: Make users\n    hosts: all\n    gather_facts: false\n    become: true\n    vars: \n      useradd: ansible\n\n    tasks:\n      - name: Create user\n        ansible.builtin.user:\n          name: '{{ useradd }}'\n          comment=: 'Ansible Service User Account'\n          state: present\n          password: $1$mysecretpass$1\n          update_password: on_create\n\n      - name: Permisions sudoers\n        ansible.builtin.copy:\n          dest: /etc/sudoers.d/ansible-service-account\n          content: '{{ useradd }} ALL=(ALL) NOPASSWD:ALL'\n          mode: u=rw,g=r,o=r\n          owner: root\n</code></pre> <p>Generar la relaci\u00f3n de confianza con todas las m\u00e1quinas de la soluci\u00f3n</p> <pre><code>[root@controller1 ~]#  su - ansible\n[ansible@controller1 ~]# ssh-keygen -t rsa\n[ansible@controller1 ~]# sudo cp /root/inventory .\n[ansible@controller1 ~]#  for host in $(cat inventory); do ssh-copy-id ansible@$host;done\n[ansible@controller1 ~]# ansible all  -i inventory -m ansible.builtin.ping\n</code></pre> <p>Ejecuci\u00f3n </p> <p>ANSIBLE_BECOME_METHOD='sudo' ANSIBLE_BECOME=True ANSIBLE_HOST_KEY_CHECKING=False ./setup.sh -e @credentials.yml -- --ask-vault-pass</p>"},{"location":"01_redhat/03-DO467/RHAAP_notes/#administracion-de-usuarios","title":"Administraci\u00f3n de usuarios","text":"<p>ANSIBLE_BECOME_METHOD='sudo' ANSIBLE_BECOME=True ANSIBLE_HOST_KEY_CHECKING=False ./setup.sh -e @credentials.yml -- --ask-vault-pass ansible-automation-platform-setup-bundle-2.4-1-x86_64/collections/ansible_collections collections/ansible_collections/ansible/automation_platform_installer/roles/preflight/tasks/main.yml</p> <p>openssl req -new -newkey rsa:2048 -nodes -keyout xxxx.key -out xxxx.com.csr</p>"},{"location":"01_redhat/04-DO374/04-DO374_C7/","title":"Cap\u00edtulo 7, Transformando data con Filtros y Plug-ins","text":"<p>Poblar, manipular y gestionar la data de variables usando filtros y plug-ins</p> <ul> <li>Formatear, analizar y definir los valores de variables usando filtros</li> <li>Poblar variables con data desde fuentes externas usando el plugin-ins lookup</li> <li>Implementar ciclos usando estructuras como simples listas usando el plug-in lookup y filtros</li> <li>Usar filtros para inspeccionar, validar y manipular variables que tienen informaci\u00f3n de red</li> </ul>"},{"location":"01_redhat/04-DO374/04-DO374_C7/#filtros-ansible","title":"Filtros Ansible","text":"<p>Ansible aplica valores de variable a los playbook y templates usando expresiones Jinja2, como es su forma mas simple: el nombre de una variable en llaves dobles <code>{{ variable }}</code>.</p> <p>Algunos filtros estan provistos por el lenguaje Jinja2 y otros incluidos por Red Hat AAP como plug-ins</p> <p>Para el uso inicial de filtros con expresi\u00f3n Jinja2 es agregando el caracter pipe <code>|</code> y luego el nombre o valor escrito como expresi\u00f3n <code>{{ variable | filter }}</code></p>"},{"location":"01_redhat/04-DO374/04-DO374_C7/#provision-de-valores-de-variables-default","title":"Provisi\u00f3n de valores de variables Default","text":"<p>Se puede usar le filtro <code>default</code> para ignorar una variable no definida o proveer un valor a una variable no definida. En ambos casos se utiliza cuando el mensaje es el siguiente:</p> <p><code>FAILED! =&gt; {\"msg\": \"The task includes an option with an undefined variable. The error was: 'dict object' has no attribute 'shell'</code></p> <p>Revisar el siguiente ejemplo:</p> <pre><code>- name: Manage user\n  ansible.builtin.user:\n    name: \"{{ item['name'] }}\"\n    groups: \"{{ item['groups'] | default(omit) }}\"\n    system: \"{{ item['system'] | default(false) }}\"\n    shell: \"{{ item['shell'] | default('/bin/bash') }}\"\n    state: \"{{ item['state'] | default('present') }}\"\n    remove: \"{{ item['remove'] | default(false) }}\"\n  loop: \"{{ user_list }}\"\n</code></pre> Variable Por <code>default</code> el valor ser\u00e1 <code>item['groups'] | default(omit)</code> omitido <code>item['system'] | default(false)</code> <code>false</code> <code>item['shell'] | default('/bin/bash')</code> <code>/bin/bash</code> <code>item['state'] | default('present')</code> <code>present</code> <code>item['remove'] | default(false)</code> <code>false</code> <p>Normalmente el fitro <code>defautl</code> solo provee valor si la variable no est\u00e1 definida, en algunas situaciones se puede proveer un valor si el filtro tiene un string en blanco o una condici\u00f3n de valor Booleano:</p> <pre><code>---\n- name: Default filter examples\n  hosts: localhost\n  tasks:\n    - name: Default filter examples\n      vars:\n        pattern: \"some text\"\n      ansible.builtin.debug:\n        msg: \"{{ item }}\"\n      loop:\n        - \"{{ pattern | regex_search('test') | default('MESSAGE') }}\" \n        - \"{{ pattern | regex_search('test') | default('MESSAGE', true) }}\"\n        - \"{{ pattern | bool | default('MESSAGE') }}\"\n        - \"{{ pattern | bool | default('MESSAGE', true) }}\"\n</code></pre> <p>El filtro <code>regex_search</code> busca en la expresi\u00f3n regular la cadena test, pero como no est\u00e1 regresa el valor vacio, luego en el siguiente loop (2) como est\u00e1 vacio el filtro <code>default</code> regresa el valor true. </p> <p>En el los 3 y 4, en la primera como el filtro es el <code>bool</code> y es false no se utiliza el filtro <code>default</code>. En cambio en el segundo, a pesar de que es booleano y en false, si utiliza el filtro <code>default</code> porque tiene el valor true</p>"},{"location":"01_redhat/04-DO374/04-DO374_C7/#tipos-de-variables","title":"Tipos de variables","text":"Tipo Descripci\u00f3n Strings Secuencia de caracteres Numeros Un numero valor Booleano Valores en True o False Fechas Calendario fecha tipo ISO-8601 Null Variable indefinida Listas de arreglos Colecci\u00f3n ordenada de valores Diccionarios Colecci\u00f3n de parejas de llaves-valor <p>Se puede requerir que convertir un valor a entero <code>int</code> o flotante <code>float</code>. Aca la fecha se le agrega el valor 1 y se almacena como un entero</p> <pre><code>{{ ( ansible_facts['date_time']['hour'] | int ) + 1 }}\n</code></pre> <p>Ejemplo de filtro matematicos, <code>root</code> (raiz cuadrada) y otros <code>log</code>, <code>pow</code>, <code>abs</code> y <code>round</code></p> <p>Existen otros filtros que ayudan a analizar y manipular listas, como <code>max</code>, <code>min</code> o <code>sum</code>.</p> <p>Incluso se puede obtener de una lista cual es el \u00faltimo, el primero o la longitud con <code>length</code> <code>first</code> o <code>last</code>. Incluso se puede agregar el filtro de aleatorio para devolver un valor al azar con <code>random</code></p> <p>Se puede modificar el orden de la lista de ls elementos. El filtro <code>sort</code> regresa una lista ordena naturalmente. El filtro <code>reverse</code> regresa una lista en orden inverso natural y el filtro <code>shuffle</code> regresa una lista en orden aleatorio.</p>"},{"location":"01_redhat/04-DO374/04-DO374_C7/#fusion-o-combinacion-de-listas","title":"Fusi\u00f3n o combinaci\u00f3n  de listas.","text":"<p>En algunos casos es nesario fusionar listas para simplificar la iteraci\u00f3n. Con el filtro <code>flatten</code> toma recursivamente el valor de entrada y le agrega los valores internos de la lista exterior.</p>"},{"location":"01_redhat/04-DO374/practice_collections/","title":"Creacion de collections","text":""},{"location":"01_redhat/04-DO374/practice_collections/#selecionando-el-namespaces","title":"Selecionando el namespaces","text":"<p>EL namespaces es el primer nombre del collection, ejemplo amazon.aws.</p> <p>Para escoger el nombre del collection tener en cuenta:</p> <ul> <li>Si planea publicar sus colecciones en Ansible Galaxy, utilice el nombre de usuario de Ansible Galaxy como namespaces.</li> <li>Si publica sus colecciones en un hub privado. Tenga en cuenta que puede crear un namespace debe tiener los permisos necesarios.</li> <li>Si es un partner de Red Hat y publica sus colecciones en automation hub, utilice el namespaces que Red Hat ha asignado.</li> </ul>"},{"location":"01_redhat/04-DO374/practice_collections/#crear-estructura-de-un-collection","title":"Crear estructura de un collection","text":"<p>Se debe especificar el namespace y el nombre de la collection</p> <pre><code>[user@host ~]$ ansible-galaxy collection init mynamespace.mycollection\n- Collection mynamespace.mycollection was created successfully\n\n[user@host ~]$ tree mynamespace/\nmynamespace/\n\u2514\u2500\u2500 mycollection\n    \u251c\u2500\u2500 docs       (1)\n    \u251c\u2500\u2500 galaxy.yml (2)\n    \u251c\u2500\u2500 plugins    (3)\n    \u2502   \u2514\u2500\u2500 README.md\n    \u251c\u2500\u2500 README.md  (4)\n    \u2514\u2500\u2500 roles      (5)\n\n4 directories, 3 files\n</code></pre> <ol> <li>docs/ almacena documentaci\u00f3n adicional. Puede utilizarlo para proporcionar documentaci\u00f3n detallada sobre sus m\u00f3dulos y plug-ins.</li> <li>galaxy.yml contiene la informaci\u00f3n necesaria para construir y publicar su colecci\u00f3n.</li> <li>plugins/ almacena los m\u00f3dulos, plug-ins y filtros que proporciona la colecci\u00f3n. Estos artefactos se desarrollan en Python.</li> <li>README.md describe su colecci\u00f3n. Normalmente proporciona algunas instrucciones de instalaci\u00f3n y enumera las dependencias necesarias. Las plataformas de distribuci\u00f3n como Ansible Galaxy o private automation hub utilizan ese archivo como portada de su colecci\u00f3n.</li> <li>roles/ almacena los roles.</li> </ol>"},{"location":"01_redhat/04-DO374/practice_collections/#agregar-contenido-al-collection","title":"Agregar contenido al collection","text":"<p>plugins/ Organiza los m\u00f3dulos, plug-ins y filtros desarrollodados en subdirectorios.</p> <ul> <li>Modulos:  plugins/modules/</li> <li>Plugins:  plugins/inventory/</li> <li>Roles: roles/</li> </ul> <p>Para inicializar un role.</p> <pre><code>[user@host ~]$ cd mynamespace/mycollection/roles/\n[user@host roles]$ ansible-galaxy role init myrole\n- Role myrole was created successfully\n[user@host roles]$ ls myrole/\ndefaults  files  handlers  meta  README.md  tasks  templates  tests  vars\n</code></pre>"},{"location":"01_redhat/04-DO374/practice_collections/#actualizar-la-metadata-de-un-collection","title":"Actualizar la metadata de un collection","text":"<p>El fichero galaxy.yml en la ra\u00edz del directorio de la colecci\u00f3n proporciona informaci\u00f3n para que Ansible construya y publique la colecci\u00f3n. El archivo incluye comentarios que describen cada par\u00e1metro. El siguiente archivo galaxy.yml es un ejemplo completo:</p> <pre><code>---\nnamespace: mynamespace\nname: mycollection\nversion: 1.0.0\nreadme: README.md\nauthors:\n  - your name &lt;example@domain.com&gt;\ndescription: Ansible modules to manage my company's custom software\nlicense:\n  - GPL-3.0-or-later\n\nrepository: https://git.example.com/training/my-collection\n\n# The URL to any online docs\ndocumentation: https://git.example.com/training/my-collection/tree/main/docs\n\n# The URL to the homepage of the collection/project\nhomepage: https://git.example.com/training/my-collection\n\n# The URL to the collection issue tracker\nissues: https://git.example.com/training/my-collection/issues\n\ndependencies:\n  community.general: '&gt;=1.0.0'\n  ansible.posix: '&gt;=1.0.0'\n</code></pre> <p>Si se necesita incluir otras collections como dependencias usar este fichero en el apartado dependencies el cual es un diccionario de colecciones. Para cada entrada, la clave es el FQCN de la colecci\u00f3n, y el valor es la versi\u00f3n de la colecci\u00f3n (utilice &gt;=1.0.0 cuando no necesite una versi\u00f3n espec\u00edfica).</p> <p>Para dependencias de python es necesario crear el fichero ./requirements.txt, en la raiz del collection.</p> <p>Ejemplo:</p> <pre><code>botocore&gt;=1.18.0\nboto3&gt;=1.15.0\nboto&gt;=2.49.0\n</code></pre> <p>En algunos casos se requiere instalar paquetes a nivel de SO en el EE. para esto se crea el fichero bindep.txt en la raiz de la collection</p> <p>Diferentes distribuciones pueden tener otros nombres de paquetes para el mismo software. En el archivo anterior, la directiva [platform:centos-8 platform:rhel-8] proporciona el nombre de las distribuciones de Linux. Otra directiva est\u00e1ndar es [platform:rpm], que apunta a todas las distribuciones de Linux que utilizan el sistema de empaquetado RPM.</p> <p>Un ejemplo de bindep.txt</p> <pre><code>rsync [platform:rpm  platform:centos-8 platform:rhel-8]\n</code></pre> <p>Otro fichero importante es meta/runtime.yml, en el cual se define la version de ansible requerida por el collection.</p> <p>Ejemplo del fichero:</p> <pre><code>---\nrequires_ansible: '&gt;=2.10.9'\n</code></pre> <p>IMPORTANTE: El fichero meta/runtime.ym es requerido al publicar el automation hub tanto privado como publico.</p>"},{"location":"01_redhat/04-DO374/practice_collections/#construir-un-collection","title":"Construir un collection","text":"<p>Una vez creado el collection ejecutar el comando <code>ansible-galaxy collection build</code> para preparar la collection.</p> <p>Puede utilizar el archivo .tar.gz resultante para instalar y probar la colecci\u00f3n localmente, para compartir la colecci\u00f3n con miembros del equipo o para publicarla en Ansible Galaxy o un Hub privado.</p>"},{"location":"01_redhat/04-DO374/practice_collections/#validaciones-y-testing-al-collection","title":"Validaciones y testing al collection","text":"<p>El Hub privado utiliza la herramienta ansible-lint para verificar que su colecci\u00f3n se ajusta a las normas y buenas pr\u00e1cticas que establece el equipo de Ansible.</p> <p>al publicar un collection se aprecia el siguiente log:</p> <pre><code>Importing with galaxy-importer 0.4.4\nGetting doc strings via ansible-doc\nFinding content inside collection\nLoading role myrole\nLinting role myrole via ansible-lint...\nroles/myrole/tasks/main.yml:3: fqcn-builtins Use FQCN for builtin actions.\nroles/myrole/tasks/main.yml:3: risky-file-permissions File permissions unset or incorrect.\nCHANGELOG.rst file not found at top level of collection.\nCollection loading complete\n\nDone\n</code></pre>"},{"location":"01_redhat/04-DO374/practice_collections/#publicar-un-collection-al-hub-privado","title":"Publicar un collection al hub privado","text":""},{"location":"01_redhat/04-DO374/practice_collections/#via-web-ui","title":"Via Web UI","text":"<p>Ir a: Collections \u2192 Namespaces  (Select Namespace) \u2192 Upload collection y cargar el .tar.gz generado.</p> <p>Para que el collection este disponible para los usuarios es necesario aprobarla.</p> <p>[Approval] (images/approval.png)</p> <p>Cada vez que se modifique la colecci\u00f3n, Es necesario editar el archivo galaxy.yml y actualizar la versi\u00f3n. De lo contrario, la plataforma de distribuci\u00f3n rechazar\u00e1 tu colecci\u00f3n.</p> <pre><code>[user@host mycollection]$ cat galaxy.yml\n---\nnamespace: mynamespace\nname: **mycollection**\nversion: 2.0.0\nreadme: README.md\nauthors:\n  - your name &lt;example@domain.com&gt;\n...output omitted...\n[user@host mycollection]$ ansible-galaxy collection build\nCreated collection for mynamespace.mycollection at /home/user/mynamespace/mycollection/mynamespace-mycollection-2.0.0.tar.gz\n</code></pre>"},{"location":"01_redhat/04-DO374/practice_collections/#via-cli","title":"Via CLI","text":"<ol> <li>Garantizar la autenticacion al hub.</li> </ol> <p>```shell    [galaxy]    server_list = inbound_mynamespace</p> <p>[galaxy_server.inbound_mynamespace]    url=https://hub.lab.example.com/api/galaxy/content/inbound-mynamespace/    token=    ``` <p>La interfaz web del hub privado muestra la URL de entrada del namespaces, para esto ir a:  Collections \u2192 Namespaces \u2192 View collections  (Seleccionar el namespaces) \u2192 CLI configuration.</p> <p>Para recuperar el token. ir a  Collections \u2192 API token management \u2192 Load token. Actualizar la l\u00ednea token del la section [galaxy_server.namespace ]  en ansible.cfg</p> <ol> <li>Cargar la collection</li> </ol> <p><code>shell    [user@host mycollection]$ ansible-galaxy collection publish mynamespace-mycollection-2.0.0.tar.gz</code></p>"},{"location":"01_redhat/04-DO374/practice_collections/#documentacion","title":"Documentacion","text":"<ul> <li>Developing Collections</li> <li>Collection Galaxy Metadata Structure</li> <li>Python Packages Requirements File Format</li> <li>Introduction to bindep</li> <li>Generating Changelogs and Porting Guide Entries in a Collection</li> </ul>"},{"location":"01_redhat/05-RHSA6/05-RH403_C1/","title":"Capitulo 1 - Planeaci\u00f3n y despliegue de Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C1/#descripcion-de-red-hat-satellite","title":"Descripci\u00f3n de Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C1/#planear-de-despliegue-de-red-hat-satellite","title":"Planear de despliegue de Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C1/#instalacion-red-hat-satellite","title":"Instalaci\u00f3n Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C1/#adminitracion-de-red-hat-satellite-con-hammer","title":"Adminitraci\u00f3n de Red Hat Satellite con Hammer","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C1/#configuracion-de-organizaciones-y-manifiestos-de-contenido","title":"Configuraci\u00f3n de Organizaciones y manifiestos de contenido","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C10/","title":"Capitulo 10 - Automatizar Administraci\u00f3n de Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C10/#query-de-api-red-hat-satellite","title":"Query de API Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C10/#administrar-red-hat-satellite-con-ansible","title":"Administrar Red Hat Satellite con Ansible","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C11/","title":"Mantenimiento de servidor Red Hat Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C11/#delegar-tareas-con-roles-de-usuarios","title":"Delegar Tareas con Roles de Usuarios","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C11/#configurar-backup-operaciones-de-restauracion","title":"Configurar Backup &amp; Operaciones de Restauraci\u00f3n","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C11/#gestion-de-base-de-datos-de-red-hata-satellite","title":"Gesti\u00f3n de Base de Datos de Red Hata Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C11/#importar-exportar-vistas-de-contenido-content-view","title":"Importar &amp; exportar Vistas de Contenido (Content View)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C12/","title":"Capitulo 12 - Integrar Red Hat Satellite con Plataformas H\u00edbridas Cloud","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C12/#ejecucutar-red-hat-satellite-sobre-una-plataforma-cloud","title":"Ejecucutar Red Hat Satellite sobre una Plataforma Cloud","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C12/#administrar-contenido-de-hosts-sobre-aws-content-hosts","title":"Administrar Contenido de Hosts sobre AWS (Content Hosts)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C12/#administrar-contenido-de-hosts-sobre-gcp-content-hosts","title":"Administrar Contenido de Hosts sobre GCP (Content Hosts)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C12/#administrar-contenido-de-hosts-sobre-azure-content-hosts","title":"Administrar Contenido de Hosts sobre AZURE (Content Hosts)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C2/","title":"Capitulo 2 - Administraci\u00f3n de ciclos de contenido de software (SW Lifecycles)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C2/#sincronizar-contenido-red-hat","title":"Sincronizar contenido Red Hat","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C2/#crear-ciclos-de-contenido","title":"Crear ciclos de contenido","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C2/#publicar-y-promover-vistas-de-contenido-content-views","title":"Publicar y promover Vistas de Contenido (Content Views)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C3/","title":"Capitulo 3 - Registro de Hosts","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C3/#registro-y-configuracion-de-ccontenido-de-hosts-content-hosts","title":"Registro y configuraci\u00f3n de cContenido de Hosts (Content Hosts)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C3/#administrar-hosts-con-colecciones-de-hosts-hosts-collections","title":"Administrar Hosts con Colecciones de Hosts (Hosts Collections)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C3/#automatizar-con-llaves-de-activacion-activation-keys","title":"Automatizar con Llaves de Activaci\u00f3n (Activation Keys)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C4/","title":"Capitulo 4 - Desploiegue de Software en los Hosts","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C4/#control-de-software-con-vistas-de-contenido-content-views","title":"Control de Software con Vistas de Contenido (Content Views)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C4/#crear-filtros-de-vistas-de-contenido-content-view","title":"Crear filtros de vistas de contenido (Content View)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C4/#administrar-y-aplicar-errata-en-los-hosts","title":"Administrar y aplicar Errata en los Hosts","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C5/","title":"Capitulo 5 - Desplegar Software Personalizado","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C5/#crear-productos-y-repositorios-personalizados","title":"Crear Productos y Repositorios personalizados","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C5/#crear-productos-con-descubrimiento-de-repositorio","title":"Crear Productos con descubrimiento de Repositorio","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C5/#administrar-poductos-y-repositorios-personalizados","title":"Administrar Poductos y Repositorios personalizados","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C6/","title":"Capitulo 6 - Despligar Capsula de Servidor Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C6/#instalar-capsula-de-servidor-satellite","title":"Instalar Capsula de Servidor Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C6/#configurar-servicios-de-capsula-de-servidor-satellite","title":"Configurar Servicios de Capsula de Servidor Satellite","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C6/#publicar-vistas-de-contenido-desde-satellite-a-servidor-satellite-content-view","title":"Publicar Vistas de Contenido desde Satellite a Servidor Satellite (Content View)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C7/","title":"Capitulo 7 - Ejecuci\u00f3n Remota","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C7/#tareas-de-ejecucion-remota-sobre-hosts-administrados","title":"Tareas de Ejecuci\u00f3n Remota sobre Hosts Administrados","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C7/#configurar-ejecucion-remota-de-ansible","title":"Configurar Ejecuci\u00f3n Remota de Ansible","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C7/#ejecucion-remota-de-jobs-puppet-sobre-hosts-administrados","title":"Ejecuci\u00f3n Remota de Jobs Puppet sobre Hosts Administrados","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C8/","title":"Capitulo 8 - Preparar Recursos de Red para Aprovisionamiento de Hosts (Host Provisioning)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C8/#configurar-servidor-de-satellite-para-aprovisionaimento-de-host-host-provisioning","title":"Configurar Servidor de Satellite para Aprovisionaimento de Host (Host Provisioning)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C8/#preparar-configuracion-de-red-para-aprovisionamiento","title":"Preparar Configuraci\u00f3n de Red para Aprovisionamiento","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C9/","title":"Capitulo 9 - Aprovisionar Contenido de Hosts (Content Hosts)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C9/#configurar-y-aprovisionar-contenido-de-hosts-content-hosts","title":"Configurar y Aprovisionar Contenido de Hosts (Content Hosts)","text":""},{"location":"01_redhat/05-RHSA6/05-RH403_C9/#construir-imagenes-para-aprovisionamiento","title":"Construir Imagenes para Aprovisionamiento","text":""},{"location":"01_redhat/05-RHSA6/RH403_notes/","title":"Notas Red Hat Satellite 6.X","text":""},{"location":"01_redhat/05-RHSA6/RH403_notes/#guias-de-documentacion","title":"G\u00faias de documentaci\u00f3n","text":"<ul> <li>Dpcumentaci\u00f3n de producto 6.15</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_notes/#deployment","title":"Deployment","text":"<ul> <li>Instalaci\u00f3n Satellite Server conectado</li> <li>Instalaci\u00f3n de Capsula</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_notes/#comandos-de-validacion","title":"Comandos de validaci\u00f3n","text":"<p>Apertura de puertos para clientes en RHS</p> <pre><code>    firewall-cmd \\\n    --add-port=\"5647/tcp\" \\\n    --add-port=\"8000/tcp\" \\\n    --add-port=\"9090/tcp\"\n</code></pre> <p>Apertura de servicios en RHS:</p> <pre><code>    firewall-cmd \\\n    --add-service=dns \\\n    --add-service=dhcp \\\n    --add-service=tftp \\\n    --add-service=http \\\n    --add-service=https \\\n    --add-service=puppetmaster\n</code></pre> <p>Creando persitencia en las reglas del FW:</p> <pre><code>    firewall-cmd --runtime-to-permanent\n</code></pre> <p>Validando el estado del FW:</p> <pre><code>    firewall-cmd --list-all\n</code></pre> <p>Validaci\u00f3n de resoluci\u00f3n de ping localmente</p> <pre><code>    ping -c1 localhost\n    ping -c1 `hostname -f`\n</code></pre> <p>Validaci\u00f3n de acceso a URL's</p> <pre><code>cat &lt;&lt; 'EOF' &gt; SITES\n</code></pre> <p>subscription.rhn.redhat.com cdn.redhat.com console.redhat.com api.access.redhat.com cert-api.access.redhat.com e29511.dscb.akamaiedge.net a184-87-197-90.deploy.static.akamaitechnologies.com EOF [root@localhost ~]# for URL in $(cat SITES); do  timeout 3 bash -c \"&lt;/dev/tcp/$URL/443 &amp;&amp; echo Port is open for $URL || echo Port is closed\" for $URL || echo Connection timeout for $URL; done</p>"},{"location":"01_redhat/05-RHSA6/RH403_notes/#configuraciones","title":"Configuraciones","text":"Config Var email user remote execution <ol> <li>Configurar el dominio /infraestructura/dominios</li> <li>Definir los repositorios a descargar /Contenido/Red Hat Repositorios</li> <li>extras</li> <li>optionales</li> <li>RPM's</li> <li>BaseOS</li> <li>AppSteam</li> <li>Elegir los x_86 versi\u00f3n 8 y 9</li> <li>Syncronizar /contenido/Sync Status</li> <li>Config b\u00e1sica /Adminisytrar/usuario</li> <li>Usuario, email, zona horaria, idioma</li> <li>Modificar contrase\u00f1a</li> <li>Prueba de sincronizaci\u00f3n de manifiesto /content/subcription/manage manifest/refresh</li> <li>Crear el Sync Plan con el nombre de los productos basado en las selecci\u00f3n de descargas /contect/products</li> <li>De finir el horario de descarga (diario)</li> <li>Definir el lifecycle<ol> <li>Definir enviroment</li> </ol> </li> <li>Configurar Content View de acuerdo a lso reposotorios selecionados<ol> <li>Publicar la versi\u00f3n y promoverlo</li> <li>Bases RHEL 8</li> <li>Global (HA, resilent storage)</li> </ol> </li> <li>Crear los AK, <ol> <li>Limite de hosts 5</li> <li>En Detalles, cambiarle:<ol> <li>Service Level x premium</li> <li>Usage Type Production</li> <li>Role RHELS </li> <li>Release x 8</li> </ol> </li> <li>En Repository Sets<ol> <li>Limitar por enviroment</li> </ol> </li> <li>Asociar el CV</li> <li>Crear uno global</li> </ol> </li> <li>En general, modificar la opci\u00f3n de recnocer IP</li> <li>Habilitar Cloud connector configure/inventory upload</li> <li>Configurar llave root local <ol> <li>crear el usuario satellite local, copiarle las credenciales y subirle los previlegios de sudo</li> <li>actualizar las configuraciones de execute enviroment, user y pass</li> <li>ssh-copy-id -i ~foreman-proxy/.ssh/id_rsa_foreman_proxy.pub satellite@rhs</li> <li>configure/RHCloud/insights</li> <li>por cada intento fallodo, eliminar el usuario cloud connector que se ha creado</li> </ol> </li> <li>Habilitar SCAP<ol> <li>satellite-installer --enable-foreman-plugin-openscap</li> <li>hammer scap-content bulk-upload --type default</li> <li>Validar en  Administer/politicas SCAP</li> <li>Descargar los paquetes manualmente de SCAP</li> <li>copiar por scp y luego cargarlos</li> </ol> </li> <li>Hbilitar plugin de anisble<ol> <li>satellite-installer --enable-foreman-plugin-ansible --enable-foreman-proxy-plugin-ansible</li> <li>satellite-maintain packages install rhel-system-roles</li> <li>satellite-installer --foreman-proxy-bmc \"true\" -- foreman-proxy-bmc-default-provider \"freeipmi\"</li> </ol> </li> <li>Configurar LDAP<ol> <li>Instalar openldap-clients <ol> <li>satellite-maintain packages install openldap-clients</li> </ol> </li> <li>Buscar en el LDAP<ol> <li>ldapsearch -x -b \"DC=bb,DC=com,DC=mx\" -h IP -D usuarioldap</li> </ol> </li> </ol> </li> </ol> <p>Resilient storage u high availability</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/","title":"Pre-requisitos","text":""},{"location":"01_redhat/05-RHSA6/RH403_prereq/#pre-requisitos-de-instalacion","title":"Pre-requisitos de instalaci\u00f3n","text":""},{"location":"01_redhat/05-RHSA6/RH403_prereq/#descripcion-de-la-plataforma","title":"Descripci\u00f3n de la plataforma","text":"<p>Red Hat Satellite es una soluci\u00f3n de administraci\u00f3n de sistemas que permite implementar, configurar y mantener sus sistemas en entornos f\u00edsicos, virtuales y en la nube. Satellite proporciona aprovisionamiento, administraci\u00f3n remota y monitoreo de m\u00faltiples implementaciones de Red Hat Enterprise Linux con una \u00fanica herramienta centralizada. Red Hat Satellite Server sincroniza el contenido del portal de clientes de Red Hat y otras fuentes, y proporciona funcionalidades que incluyen la gesti\u00f3n detallada del ciclo de vida, el control de acceso basado en roles de usuarios y grupos, la gesti\u00f3n de suscripci\u00f3n integrada, as\u00ed como las interfaces GUI, CLI o API.</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#arquitectura-del-sistema","title":"Arquitectura del Sistema","text":""},{"location":"01_redhat/05-RHSA6/RH403_prereq/#sistema-operativo-base","title":"Sistema Operativo Base","text":"<ul> <li>Red Hat Enterprise Linux 8 x86_64, en el release m\u00e1s reciente disponible. RHEL 9 a\u00fan no es soportado.</li> <li>Recursos de hardware m\u00ednimos: 4 cores o vCPUs, 20 GB de memoria RAM, 4 GB de partition SWAP y 360GB de disco.</li> <li>Credenciales en el portal de clientes de Red Hat con acceso a todas las suscripciones de la cuenta.</li> <li>Instalaci\u00f3n m\u00ednima de sistema operativo, s\u00f3lo el grupo de paquetes @Core, sin software adicional ni procedimientos de hardening aplicados.</li> <li>En caso de requerirse un aseguramiento de la plataforma o del sistema operativo, este deber\u00e1 realizarse posterior a la instalaci\u00f3n y puesta en marcha de la plataforma.</li> <li>Resoluci\u00f3n directa y reversa de DNS para el nombre FQDN del servidor Satellite, registrado en la infraestructura DNS interna del cliente. Este nombre puede contener \u00fanicamente letras min\u00fasculas, n\u00fameros, puntos y guiones (-). El uso del archivo /etc/hosts no es recomendado.</li> <li>El nombre DNS tiene que resolver a la IP de servicio, no de administraci\u00f3n u otras.</li> <li>El servidor de Red Hat Satellite debe tener habilitado IPv6.</li> <li>Suscripciones de Red Hat Satellite vigentes.</li> <li>Acceso root o equivalente al servidor Red Hat Satellite.</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#distribucion-del-almacenamiento","title":"Distribuci\u00f3n del Almacenamiento","text":"Volumen Tipo M\u00ednimo Recomendado (GB) /boot Partici\u00f3n (/dev/sda1) 1 / XFS 10 /usr XFS 5 /tmp XFS 5 /var XFS 5 /var/log XFS 10 /var/lib/pgsql XFS 20 /var/lib/pulp XFS 300* swap XFS 4 <p>NOTA 1: Todas las particiones deben ir sobre LVM, con excepci\u00f3n del boot</p> <p>NOTA 2 (300'*'): Espacio estimado para un entorno con los repositorios Red Hat Enterprise Linux 7,8 y 9 sincronizados. Preferiblemente use discos SSD para un rendimiento \u00f3ptimo de la plataforma.</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#conectividad-requerida-por-la-plataforma","title":"Conectividad requerida por la plataforma:","text":"<p>Desde las m\u00e1quinas que se utilicen para instalar y/o administrar Satellite, hacia el servidor Satellite, se requieren los siguientes puertos:</p> <p>Mayor detalle sobre los puertos de red requeridos puede obtenerse en el siguiente enlace: https://access.redhat.com/solutions/1193673  3/6</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#puertos-administracion-y-gestion","title":"Puertos Administraci\u00f3n y gesti\u00f3n","text":"<ul> <li>22 TCP (SSH)</li> <li>80 TCP (HTTP)</li> <li>443 TCP (HTTPS)</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#puertos-desde-el-servidor-satellite-a-los-clientes","title":"Puertos desde el servidor Satellite a los clientes:","text":"<ul> <li>22 TCP (SSH3)</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#puertos-desde-los-clientes-al-servidor-satellite","title":"Puertos desde los clientes al servidor Satellite:","text":"<ul> <li>80 TCP (HTTP)</li> <li>443 TCP (HTTPS)</li> <li>5000 TCP (Docker Registry - Opcional)</li> <li>5646 TCP</li> <li>5647 TCP (Katello)</li> <li>8000 TCP</li> <li>8140 TCP (Puppet)</li> <li>9090 TCP</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#puertos-habilitados-en-el-servidor-satellite","title":"Puertos habilitados en el servidor Satellite:","text":"<ul> <li>25 / 587 (SMTP/SMTPS) al servidor de correo electr\u00f3nico (para notificaciones)</li> <li>53 UDP (DNS) al servidor DNS interno</li> <li>123 UDP (NTP) al servidor NTP interno</li> <li>389 UDP / 636 TCP (LDAP/LDAPS)</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#datos-de-servidor-de-mensajeria","title":"Datos de servidor de mensajer\u00eda","text":"<ul> <li>SMTP Address</li> <li>Usuario y password SMTP </li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#datos-de-configuracion-de-usuarios-externos-ldap","title":"Datos de configuraci\u00f3n de usuarios externos LDAP","text":"<ul> <li>Usuario y password de conexi\u00f3n</li> <li>IP y FQDN del servidor LDAP</li> <li>Grupos y su pertenecia a las Unidades organizativas (OU) que se tendr\u00e1n acceso</li> </ul>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#acceso-urls-de-internet-en-el-servidor-satellite","title":"Acceso URL's de Internet en el servidor Satellite","text":"<ul> <li>subscription.rhn.redhat.com:443 [https]</li> <li>subscription.rhsm.redhat.com:443 [https]</li> <li>cdn.redhat.com:443 [https]</li> <li>cert-api.access.redhat.com:443 [https] - Requerido para Insights</li> <li>api.access.redhat.com:443 [https] - Requerido para Insights</li> <li>.akamaiedge.net:443 [https] (Todo subdominio de akamaiedge.net*)</li> <li>.akamaitechnologies.com:443 [https] (Todo subdominio de akamaitechnologies.com*)</li> </ul> <p>Esta comunicaci\u00f3n del servidor Satellite hacia Internet puede ser directa o a trav\u00e9s de proxy. </p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#requisitos-de-proxy","title":"Requisitos de Proxy","text":"<ul> <li>Direcci\u00f3n IP</li> <li>FQDN</li> <li>Usuario y contrase\u00f1a para navegaci\u00f3n (si aplica) </li> </ul> <p>El proxy no puede realizar suplantaci\u00f3n de los certificados digitales de la p\u00e1gina de Red Hat. Esto es debido a que Satellite autentica mediante certificados digitales con el portal web de Red Hat.</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#firewall","title":"Firewall","text":"<p>El Firewall debe quedar habilitado y validado los permisos de cada puerto habilitado</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#ejecucion-de-comandos-remotos","title":"Ejecuci\u00f3n de Comandos Remotos","text":"<p>Es requerido contar con un usuario regular que tenga acceso mediante SSH a cada uno de los servidores/clientes que ser\u00e1n gestionados por Red Hat Satellite. Satellite utilizar\u00e1 este usuario para gestionar el software y las dem\u00e1s tareas propias de la plataforma. Se recomienda que este usuario se nombre como \u201csatellite\u201d para f\u00e1cil identificaci\u00f3n.</p> <p>El usuario debe tener privilegios de root mediante sudo en cada servidor sin requerir contrase\u00f1a. Esto se puede lograr creando el archivo /etc/sudoers.d/satellite.conf con el siguiente contenido:</p> <pre><code>    satellite ALL=(ALL) NOPASSWD: ALL\n</code></pre> <p>NOTA: Se solicita el puerto 22, que es el puerto SSH por defecto, pero si el servicio de SSH de los servidores se ejecuta en un puerto diferente, este puerto es el que se requerir\u00e1.</p> <p>Para mayor informaci\u00f3n sobre accesos requeridos desde Red Hat Satellite hacia Internet, consultar el enlace: https://access.redhat.com/solutions/65300</p> <p>Dado que Satellite accede usando un par de llaves SSH, por razones de seguridad se recomienda deshabilitar el acceso por contrase\u00f1a de dicho usuario al finalizar la integraci\u00f3n del cliente en Satellite, ejecutando el siguiente comando en el cliente:</p> <pre><code>    # passwd -l satellite\n</code></pre>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#maquinas-de-prueba","title":"M\u00e1quinas de Prueba","text":"<p>Con el fin de verificar el \u00f3ptimo funcionamiento de la plataforma, se recomienda entregar m\u00e1quinas de prueba preferiblemente virtuales, con una instalaci\u00f3n por defecto de cada uno de los sistemas operativos y correspondientes arquitecturas que se vayan a administrar mediante Satellite (Ej.: una VM RHEL8 y otra RHEL9).</p> <p>Dichas m\u00e1quinas deben ser destinadas \u00fanica y exclusivamente para las pruebas de Red Hat Satellite, de modo que no genere fallas o p\u00e9rdidas de informaci\u00f3n en el caso del da\u00f1o de las mismas.</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#instalacion-de-virt-who-si-aplica","title":"Instalaci\u00f3n de Virt-who (si aplica)","text":"<p>El servicio de virt-who es requerido cuando posee suscripciones que permiten ejecutar m\u00e1quinas virtuales RHEL ilimitadas en un mismo host (Ej.: suscripciones Virtual Datacenter). Puede usar suscripciones host-based en las siguientes plataformas de virtualizaci\u00f3n:</p> <ul> <li>Red Hat Virtualization</li> <li>Red Hat Enterprise Linux Virtualization (KVM)</li> <li>Red Hat OpenStack Platform</li> <li>VMware vSphere</li> <li>Microsoft Hyper-V</li> </ul> <p>Virt-who puede ser desplegado en el mismo servidor de Red Hat Satellite o en un servidor independiente. Para la mayor\u00eda de casos, es usual desplegar el servicio en el mismo servidor Red Hat Satellite, salvo que la arquitectura y/o sizing de la soluci\u00f3n recomienden lo contrario.</p> <p>Virt-who requiere de lo siguiente para poder operar correctamente:</p> <ul> <li> <p>Comunicaci\u00f3n desde el servidor donde se encuentra desplegado, hacia la API de la plataforma de virtualizaci\u00f3n:</p> <ul> <li>Para RHEV / RHV y vCenter hacia el puerto TCP/443.</li> <li>Para Hyper-V, puertos 5985 TCP y 5986 TCP de los hipervisores (no SCVMM).</li> </ul> </li> <li> <p>Credenciales de acceso a la plataforma de virtualizaci\u00f3n con privilegios correctos seg\u00fan la pataforma y configuraci\u00f3n requerida para el acceso:</p> <ul> <li>RHEV / RHV: Se requiere un usuario de s\u00f3lo lectura para acceder la plataforma o en defecto, el admin@internal: https://access.redhat.com/solutions/545013</li> <li>VMware: https://access.redhat.com/solutions/495683</li> <li>Hyper-V: https://access.redhat.com/solutions/2023883</li> </ul> </li> </ul> <p>En caso que la plataforma de virtualizaci\u00f3n sea Hyper-V, se requiere realizar en cada hipervisor de esta plataforma la configuraci\u00f3n especificada en el documento:https://access.redhat.com/solutions/2023883</p>"},{"location":"01_redhat/05-RHSA6/RH403_prereq/#portal-de-clientes-de-red-hat","title":"Portal de Clientes de Red Hat","text":"<p>Para poder instalar la plataforma, se requiere de las credenciales con acceso al portal de clientes de Red Hat: https://access.redhat.com/. Dichas credenciales requieren lo siguiente:</p> <ul> <li>Suscripci\u00f3n vigente de Red Hat Satellite.</li> <li>La cuenta debe tener los permisos suficientes para:         - Gestionar casos de soporte.         - Descargar software y actualizaciones. \u25cb Ver y asociar suscripciones.         - Registrar nuevos sistemas al portal.</li> </ul> <p>Para mayor informaci\u00f3n sobre los requerimientos anteriores, referirse al enlace: https://access.redhat.com/documentation/en-us/red_hat_satellite/6.14/html/installing_satellite_ser ver_in_a_connected_network_environment/preparing_your_environment_for_installation_satellite</p>"},{"location":"01_redhat/06-DO180/01-DO180/","title":"Red Hat OpenShift Administration I","text":"<ul> <li>Containers and Kubernetes</li> <li>Red Hat OpenShift Components and Editions</li> <li>Navigate the OpenShift Web Console</li> <li>Console</li> <li>Monitor an OpenShift Cluster</li> </ul>"},{"location":"01_redhat/06-DO180/06-DO180_C1/","title":"Capitulo 1 - Introducci\u00f3 a Kubernetes y OpenShift","text":""},{"location":"01_redhat/06-DO180/06-DO180_C1/#contenedores-y-kubernetes","title":"Contenedores y Kubernetes","text":""},{"location":"01_redhat/06-DO180/06-DO180_C1/#componentes-de-openshift-y-ediciones","title":"Componentes de OpenShift y Ediciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C1/#navegar-en-la-consola-web-de-openshift","title":"Navegar en la consola Web de OpenShift","text":""},{"location":"01_redhat/06-DO180/06-DO180_C1/#monitoreo-de-cluster-de-openshift","title":"Monitoreo de Cluster de OpenShift","text":""},{"location":"01_redhat/06-DO180/06-DO180_C2/","title":"Capitulo 2 - Interface de Linea de Comandos y APIs de Kubernetes y OpenShift (CLI)","text":""},{"location":"01_redhat/06-DO180/06-DO180_C2/#interfaces-de-linea-de-comandos-en-kubernetes-y-openshift","title":"Interfaces de L\u00ednea de Comandos en Kubernetes y OpenShift","text":""},{"location":"01_redhat/06-DO180/06-DO180_C2/#examinar-recursos-de-kubernetes","title":"Examinar Recursos de Kubernetes","text":""},{"location":"01_redhat/06-DO180/06-DO180_C2/#evaluar-estado-health-de-cluster-de-openshift","title":"Evaluar estado (Health) de Cluster de OpenShift","text":""},{"location":"01_redhat/06-DO180/06-DO180_C3/","title":"Capitulo 3 - Ejecuci\u00f3n de Aplicaciones sobre Contenedores y Pods","text":""},{"location":"01_redhat/06-DO180/06-DO180_C3/#crear-contenedores-linux-y-pods-de-kubernetes","title":"Crear Contenedores Linux y Pods de Kubernetes","text":""},{"location":"01_redhat/06-DO180/06-DO180_C3/#buscar-y-examinar-imagenes-de-contenedores","title":"Buscar y examinar Imagenes de Contenedores","text":""},{"location":"01_redhat/06-DO180/06-DO180_C3/#solucion-de-problemas-en-contenedores-y-pods-troubleshooting","title":"Soluci\u00f3n de problemas en Contenedores y Pods (Troubleshooting)","text":""},{"location":"01_redhat/06-DO180/06-DO180_C4/","title":"Capitulo 4 - Despliegue de aplicaciones gestionadas y en red en Kubernetes","text":""},{"location":"01_redhat/06-DO180/06-DO180_C4/#despligue-de-aplicaciones-desde-imagenes-y-plantillas-templates","title":"Despligue de Aplicaciones desde Imagenes y Plantillas (Templates)","text":""},{"location":"01_redhat/06-DO180/06-DO180_C4/#gestion-de-aplicaciones-de-larga-y-corta-duracion-mediante-api-de-carga-de-trabajo-de-kubernetes-workload-api","title":"Gesti\u00f3n de aplicaciones de larga y corta duraci\u00f3n mediante API de carga de trabajo de kubernetes (Workload API)","text":""},{"location":"01_redhat/06-DO180/06-DO180_C4/#pod-de-kubernetes-servicios-de-red","title":"Pod de Kubernetes &amp; Servicios de Red","text":""},{"location":"01_redhat/06-DO180/06-DO180_C4/#escalar-y-exponer-aplicaciones-para-acceso-externo","title":"Escalar y exponer Aplicaciones para acceso externo","text":""},{"location":"01_redhat/06-DO180/06-DO180_C5/","title":"Capitulo 5 - Gesti\u00f3n de Almacenamiento (Storage) para configurar Aplicaciones y Data","text":""},{"location":"01_redhat/06-DO180/06-DO180_C5/#exponer-configuracion-de-aplicaciones","title":"Exponer Configuraci\u00f3n de Aplicaciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C5/#aporvisionamiento-persistente-de-volumenes","title":"Aporvisionamiento Persistente de Volumenes","text":""},{"location":"01_redhat/06-DO180/06-DO180_C5/#seleccionar-tipos-de-almacenamiento-storage-class-para-una-aplicacion","title":"Seleccionar Tipos de Almacenamiento (Storage Class) para una Aplicaci\u00f3n","text":""},{"location":"01_redhat/06-DO180/06-DO180_C5/#gestion-de-almacenamiento-no-compartido-con-stateful-sets","title":"Gesti\u00f3n de Almacenamiento no compartido con Stateful Sets","text":""},{"location":"01_redhat/06-DO180/06-DO180_C6/","title":"Capitulo 6 - Configurar Aplicaciones para Disponibilidad","text":""},{"location":"01_redhat/06-DO180/06-DO180_C6/#sensores-de-estado-de-aplicaciones","title":"Sensores de Estado de Aplicaciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C6/#reservas-de-capacidad-de-computo-para-aplicaciones","title":"Reservas de Capacidad de Computo para Aplicaciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C6/#limites-de-capacidad-de-computo-para-aplicaciones","title":"L\u00edmites de Capacidad de Computo para Aplicaciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C6/#autoescalamiento-de-aplicaciones","title":"Autoescalamiento de Aplicaciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C7/","title":"Capitulo 7 - Gesti\u00f3n de Actualizaciones de Aplicaciones","text":""},{"location":"01_redhat/06-DO180/06-DO180_C7/#identidad-de-contenedor-de-imagenes-y-etiquetas-tags","title":"Identidad de Contenedor de Imagenes y Etiquetas (Tags)","text":""},{"location":"01_redhat/06-DO180/06-DO180_C7/#actualizacion-y-configuracion-de-imagenes-de-aplicacion","title":"Actualizaci\u00f3n y configuraci\u00f3n de Im\u00e1genes de Aplicaci\u00f3n","text":""},{"location":"01_redhat/06-DO180/06-DO180_C7/#regeneracion-y-despliegue-con-imagens-de-openshift-stream","title":"Regeneraci\u00f3n y despliegue con Imagens de OpenShift Stream","text":""},{"location":"01_redhat/06-DO180/06-DO180_C7/#actualizaciones-automaticas-con-triggers-de-cambio-de-imagenes-de-openshift","title":"Actualizaciones Automaticas con Triggers de cambio de Imagenes de OpenShift","text":""},{"location":"01_redhat/06-DO180/DO180_notes/","title":"Notas Administraci\u00f3n OCP 4","text":""},{"location":"01_redhat/06-DO180/DO180_notes/#guias-de-documentacion","title":"Gu\u00edas de documentaci\u00f3n","text":"<ul> <li>Product Documentation for OpenShift Container Platform 4.X y 3X</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#getting-started-v415","title":"Getting Started v.4.15","text":"<ul> <li>Getting Started</li> <li>Release Notes</li> <li>Architecture</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#install-v415","title":"Install v.4.15","text":"<ul> <li>Installing</li> <li>Installing OpenShift Container Platform with the Assisted Installer </li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#configure-v415","title":"Configure v.4.15","text":"<ul> <li>Authentication and authorization</li> <li>Networking</li> <li>Registry</li> <li>Postinstallation configuration</li> <li>Storage</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#manage-v415","title":"Manage v.4.15","text":"<ul> <li>Backup and restore</li> <li>Web console</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#reference-v415","title":"Reference v.4.15","text":"<ul> <li>CLI tools</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#yq-tool","title":"yq tool","text":"<ul> <li>yq tool </li> <li>yqlang</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#cri-o-documentation","title":"CRI-O documentation","text":"<ul> <li>CRI-O Container Engine</li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#algunos-conceptos","title":"Algunos conceptos:","text":"<ul> <li>Pods (pod) Represent a collection of containers that share resources, such as IP addresses and persistent storage volumes. It is the primary unit of work for Kubernetes.</li> <li>Services (svc) Define a single IP/port combination that provides access to a pool of pods. By default, services connect clients to pods in a round-robin fashion.</li> <li>ReplicaSet (rs) Ensure that a specified number of pod replicas are running at any given time.</li> <li>Persistent Volumes (pv) Define storage areas for Kubernetes pods to use.</li> <li>Persistent Volume Claims (pvc) Represent a request for storage by a pod. PVCs link a PV to a pod so that its containers can use the provisioned storage, usually by mounting the storage into the container's file system.</li> <li>ConfigMaps (cm) and Secrets Contain a set of keys and values that other resources can use. ConfigMaps and Secrets centralize configuration values that several resources use. Secrets differ from ConfigMaps in that the values of Secrets are always encoded (not encrypted), and their access is restricted to fewer authorized users.</li> <li> <p>Deployment (deploy) A representation of a set of containers that are included in a pod, and the deployment strategies to use. A deployment object contains the configuration to apply to all containers of each pod replica, such as the base image, tags, storage definitions, and the commands to execute when the containers start. Although Kubernetes replicas can be created stand-alone in OpenShift, they are usually created by higher-level resources such as deployment controllers.</p> <p>Red Hat OpenShift Container Platform (RHOCP) adds the following main resource types to Kubernetes:</p> </li> <li> <p>BuildConfig (bc) Defines a process to execute in the OpenShift project. The OpenShift Source-to-Image (S2I) feature uses a BuildConfig to build a container image from application source code that is stored in a Git repository. A bc works together with a dc to provide an extensible continuous integration and continuous delivery workflows.</p> </li> <li> <p>DeploymentConfig (dc) OpenShift 4.5 introduced the Deployment resource concept to replace the DeploymentConfig default configuration for pods. Both concepts represent a set of containers that are included in a pod, and the deployment strategies to use.</p> <p>The Deployment object serves as the improved version of the DeploymentConfig object. Some functional replacements between both objects are as follows:</p> <ul> <li> <p>Deployment objects no longer support automatic rollback or lifecyle hooks.</p> </li> <li> <p>Every change in the pod template that Deployment objects use triggers a new rollout automatically.</p> </li> <li> <p>The deployment process of a Deployment object can be paused at any time without affecting the deployer process.</p> </li> <li> <p>A Deployment object can have as many active replica sets as the user wants, and can scale down previous replicas. In contrast, the DeploymentConfig object can have only two active replication sets at a time.</p> </li> </ul> <p>Although Deployment objects are the default replacement of the deprecated DeploymentConfig objects in OpenShift 4.12 and later versions, you can still use DeploymentConfig objects if you need a specific feature that they provide, but they are not recommended for new installations. In this case, you must specify the type of object when creating a new application by including the --as-deployment-config flag.</p> </li> </ul>"},{"location":"01_redhat/06-DO180/DO180_notes/#comandos","title":"Comandos","text":"<p>Conectarse a la granja:</p> <pre><code>    oc login -u &lt;usuario&gt; -p &lt;password&gt;  https://api.ocp4.example.com:6443\n    oc login -u admin -p redhatocp\n</code></pre> <p>Mostrar la URL de la consola:</p> <pre><code>    oc whoami --show-console\n</code></pre> <p>Descargar kubectl e instalarla en uno de los nodos master incluso en la m\u00e1quina desktop si hay conexi\u00f3n</p> <pre><code>   curl -LO \"https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\"\n</code></pre> <p>Crear un nuevo proyecto:</p> <pre><code>   oc new-project myapp\n</code></pre> <p>Otras validaciones:</p> <pre><code>   oc cluster-info\n   oc api-versions\n   oc get clusteroperator\n</code></pre> <p>Operaciones </p> <pre><code>   oc get pod\n   oc get all\n   oc get nodes\n   oc get clusteroperator\n   oc get clusteroperators dns -o yaml\n   oc get pods -n openshift-apiserver\n\n   oc describe mysql-openshift-1-xxxxx\n   oc create -f pod.yaml\n   oc status\n   oc delete pod quotes-ui\n\n   oc api-versions\n   oc api-resources\n   oc api-resources --namespaced=true --api-group apps --sort-by name\n</code></pre> <p>Ayuda</p> <pre><code>  oc help\n  oc create --help\n  oc version\n  oc explain services\n</code></pre> <p>Operaciones con pods:</p> <pre><code>  oc get pod --selector group=developers\n  oc get pods -o yaml\n  oc get pods -o yaml | yq r - 'items[0].status.podIP'\n  oc get pods -o json\n  oc get pods -o json | jq '.items[0].status.podIP'\n\n  oc get pods \\\n  -o custom-columns=PodName:\".metadata.name\",\\\n  ContainerName:\"spec.containers[].name\",\\\n  Phase:\"status.phase\",\\\n  IP:\"status.podIP\",\\\n  Ports:\"spec.containers[].ports[].containerPort\"\n\n  oc get pods  \\\n  -o jsonpath='{range .items[]}{\"Pod Name: \"}{.metadata.name}\n  {\"IP: \"}{.status.podIP}\n  {\"Ports: \"}{.spec.containers[].ports[].containerPort}{\"\\n\"}{end}'\n</code></pre> <p>Operaciones con api's</p> <pre><code>  oc api-resources --namespaced=false -o name | wc -l\n  oc api-resources --api-group ''\n</code></pre> <p>Examinando:</p> <pre><code>  oc adm top pods -A --sum\n  oc adm top pods etcd-master01 -n openshift-etcd --containers\n  oc get events -n openshift-kube-controller-manager\n  oc get all -n openshift-monitoring --show-kind\n  oc logs alertmanager-main-0 -n openshift-monitoring\n  oc cluster-info\n  oc get node master01 -o jsonpath=\\\n  *'{\"Allocatable:\\n\"}{.status.allocatable}{\"\\n\\n\"}{\"Capacity:\\n\"}{.status.capacity}{\"\\n\"}'\n  oc get node master01 -o json | jq '.status.conditions'\n  oc adm node-logs master01 -u crio --tail 1\n  oc debug \n  oc debug node/node-name\n  oc debug job/test --as-user=1000000\n  oc debug node/master01\n  oc get node master01 -o jsonpath='{.status.allocatable.pods}{\"\\n\"}'\n\n  oc logs pod-name -c container-name\n\n  oc adm must-gather --dest-dir /home/student/must-gather\n  tar cvaf mustgather.tar must-gather/\n\n  oc adm inspect clusteroperator/openshift-apiserver \\\n  clusteroperator/kube-apiserver\n\n  oc adm inspect clusteroperator/openshift-apiserver --since 10m\n</code></pre> <p>Examinando en el nodo:</p> <pre><code>  sh-4.4# chroot /host\n  sh-4.4# for SERVICES in kubelet crio; do echo ---- $SERVICES ---- ;systemctl is-active $SERVICES ; done\n  systemctl status kubelet\n</code></pre> <p>Creando Kubernetes y pods</p> <pre><code>  oc run RESOURCE/NAME --image IMAGE --command -- cmd arg1 ... argN\n\n  oc run -it my-app \\\n  --image registry.access.redhat.com/ubi9/ubi \\\n  --restart Never --command -- date\n</code></pre> <p>Creando containers y Pods</p> <pre><code>  oc run RESOURCE/NAME --image IMAGE [options]\n  kubectl run web-server --image registry.access.redhat.com/ubi8/httpd-24\n  oc run RESOURCE/NAME --image IMAGE --command -- cmd arg1 ... argN\n  oc run -it my-app --image registry.access.redhat.com/ubi9/ubi --command -- /bin/bash\n</code></pre> <p>Con opci\u00f3n de restart [Always/OnFailure/Never]</p> <pre><code>  oc run -it my-app --image registry.access.redhat.com/ubi9/ubi --restart Never --command -- date\n</code></pre> <p>Con opci\u00f3n de delete</p> <pre><code>  kubectl run -it my-app --rm --image registry.access.redhat.com/ubi9/ubi --restart Never --command -- date\n</code></pre> <p>Asignaci\u00f3n de ID a usuarios y grupos</p> <pre><code>  oc describe project my-app\n</code></pre> <p>Ejecutando comandos en pods en ejecuci\u00f3n</p> <pre><code>  oc exec my-app -- date\n  kubectl exec my-app -c ruby-container -- date\n  oc exec my-app -c ruby-container -it -- bash -il\n  kubectl exec my-app -c ruby-container -it -- bash -il\n</code></pre> <p>Logs de contenedores</p> <p>opciones:</p> <pre><code>  -l or --selector=''\n  --tail=\n  -c or --container=\n  -f or --follow\n  -p or --previous=true\n\n  oc logs postgresql-1-jw89j --tail=10\n  oc attach my-app -it\n</code></pre> <p>Comandos de borrado</p> <pre><code>  kubectl delete pod -l app=my-app\n  oc delete pod -f ~/php-app.json\n  cat ~/php-app.json | kubectl delete -f -\n  oc delete pod php-app --grace-period=10\n  kubectl delete pod php-app --force\n  kubectl delete pods --all\n  oc delete project my-app\n</code></pre> <p>CRI-O Engine commands</p> <pre><code>  crictl pods\n  crictl image\n  crictl inspect    \n  crictl exec    \n  crictl logs   \n  crictl ps\n\n  kubectl get pods -o wide\n  oc get pod postgresql-1-8lzf2 -o jsonpath='{.spec.nodeName}{\"\\n\"}'\n  oc debug node/master01\n  crictl ps --name postgresql\n  crictl ps --name postgresql -o json | jq .containers[0].id\n\n  crictl inspect -o json 27943ae4f3024 | jq .info.pid #Show $id\n  lsns -p $id\n  nsenter -t $id -p -r ps -ef\n  nsenter -t $id -a ps -ef\n</code></pre> <p>Red Hat Ecosystem Catalog</p> <p>Inspecting and Managing Container Images</p> <pre><code>  sudo dnf -y install skopeo\n  skopeo login quay.io\n  skopeo list-tags docker://registry.access.redhat.com/ubi9/httpd-24\n  skopeo inspect --config docker://registry.access.redhat.com/ubi9/httpd-24\n\n  skopeo copy docker://quay.io/skopeo/stable:latest docker://registry.example.com/skopeo:latest\n  skopeo delete docker://registry.example.com/skopeo:latest\n  skopeo sync --src docker --dest docker registry.access.redhat.com/ubi8/httpd-24 registry.example.com/httpd-24\n\n  skopeo inspect docker://registry.redhat.io/rhel8/httpd-24\n  skopeo inspect docker://registry.access.redhat.com/ubi8:latest\n\n  skopeo login registry.redhat.io\n\n  oc image info registry.access.redhat.com/ubi9/httpd-24:1-233 --filter-by-os amd64\n</code></pre> <p>images command</p> <pre><code>  oc image append\n  oc image extract\n  oc image mirror\n</code></pre> <p>Troubleshooting kb</p> <ul> <li>kubectl describe: Display the details of a resource.</li> <li>kubectl edit: Edit a resource configuration by using the system editor.</li> <li>kubectl patch: Update a specific attribute or field for a resource.</li> <li>kubectl replace: Deploy a new instance of the resource.</li> <li>kubectl cp: Copy files and directories to and from containers.</li> <li>kubectl exec: Execute a command within a specified container.</li> <li>kubectl explain: Display documentation for a specified resource.</li> <li>kubectl port-forward: Configure a port forwarder for a specified container.</li> <li>kubectl logs: Retrieve the logs for a specified container.</li> </ul> <p>Troubleshooting oc</p> <ul> <li>oc status: Display the status of the containers in the selected namespace.</li> <li>oc rsync: Synchronize files and directories to and from containers.</li> <li>oc rsh: Start a remote shell within a specified container.</li> </ul> <p>Editing</p> <pre><code>  oc describe pod dns-default-lt13h\n  oc edit pod mongo-app-sw88b\n  oc patch pod valid-pod --type='json' -p='[{\"op\": \"replace\", \"path\": \"/spec/containers/0/image\", \"value\":\"http://registry.access.redhat.com/ubi8/httpd-24\"}]'\n</code></pre> <p>Copy</p> <pre><code>  oc cp apache-app-kc82c:/var/www/html/index.html /tmp/index.bak\n  oc cp /tmp/index.html apache-app-kc82c:/var/www/html/\n  oc exec -it apache-app-kc82c -- ls /var/www/html\n  oc rsync apache-app-kc82c:/var/www/ /tmp/web_files\n</code></pre> <p>Remote container access</p> <pre><code>  oc port-forward nginx-app-cc78k 8080:80\n  oc rsh tomcat-app-jw53r\n</code></pre> <p>Execute command in a Container</p> <pre><code>  oc exec POD | TYPE/NAME [-c container_name] -- COMMAND [arg1 ... argN]\n  oc exec -it mariadb-lc78h -- ls /\n  oc exec mariadb-lc78h -- ls /\n</code></pre> <p>Events &amp; logs</p> <pre><code>  oc logs BIND9-app-rw43j\n  oc get events\n</code></pre> <p>Templates</p> <pre><code>  oc process -f mysql-template.yaml -o yaml\n  oc process -f mysql-template.yaml --parameters\n  oc new-app --template mysql-persistent\n</code></pre> <p>Jobs</p> <pre><code>  oc create job date-job --image registry.access.redhat.com/ubi8/ubi -- /bin/bash -c \"date\"\n  oc create cronjob date-cronjob --image registry.access.redhat.com/ubi8/ubi --schedule \"*/1 * * * *\" -- date 4\n</code></pre> <p>Deployments</p> <pre><code>  oc create deployment my-deployment --image registry.access.redhat.com/ubi8/ubi --replicas 3\n\n  oc delete pod -l environment=testing\n</code></pre> <p>Creating Secrets</p> <pre><code>  oc create secret generic secret_name --from-literal key1=secret1 --from-literal key2=secret2\n  kubectl create secret generic ssh-keys --from-file id_rsa=/path-to/id_rsa --from-file id_rsa.pub=/path-to/id_rsa.pub\n  oc create secret tls secret-tls --cert /path-to-certificate --key /path-to-key\n</code></pre> <p>Creating Configuration Maps</p> <pre><code>  kubectl create configmap my-config --from-literal key1=config1 --from-literal key2=config2\n  oc create cm my-config --from-literal key1=config1 --from-literal key2=config2\n</code></pre> <p>Using Secrets and Configuration Maps as Volumes</p> <pre><code>  oc create secret generic demo-secret --from-literal user=demo-user --from-literal root_password=zT1KTgk\n  oc create secret generic demo-secret --from-file user=/tmp/demo/user --from-file root_password=/tmp/demo/root_password\n  oc set volume deployment/demo --add --type secret --secret-name demo-secret --mount-path /app-secrets\n\n  oc create configmap demo-map --from-file=config-files/httpd.conf\n  oc set volume deployment/demo --add --type configmap --configmap-name demo-map --mount-path /app-secrets\n  oc set volume deployment/demo\n  oc set env deployment/demo --from secret/demo-secret --prefix MYSQL_\n</code></pre> <p>Updating Secrets and Configuration Maps</p> <pre><code>  oc extract secret/demo-secrets -n demo --to /tmp/demo --confirm\n  oc set data secret/demo-secrets -n demo --from-file /tmp/demo/root_password\n</code></pre> <p>Persistent Volumes</p> <p>configMap The configMap volume externalizes the application configuration data. This use of the configMap resource ensures that the application configuration is portable across environments and can be version-controlled.</p> <p>emptyDir An emptyDir volume provides a per-pod directory for scratch data. The directory is usually empty after provisioning. emptyDir volumes are often required for ephemeral storage.</p> <p>hostPath A hostPath volume mounts a file or directory from the host node into your pod. To use a hostPath volume, the cluster administrator must configure pods to run as privileged. This configuration grants access to other pods in the same node.</p> <p>Red Hat does not recommend the use of hostPath volumes in production. Instead, Red Hat supports hostPath mounting for development and testing on a single-node cluster. Although most pods do not need a hostPath volume, it does offer a quick option for testing if an application requires it.</p> <p>iSCSI Internet Small Computer System Interface (iSCSI) is an IP-based standard that provides block-level access to storage devices. With iSCSI volumes, Kubernetes workloads can consume persistent storage from iSCSI targets.</p> <p>local You can use Local persistent volumes to access local storage devices, such as a disk or partition, by using the standard PVC interface. Local volumes are subject to the availability of the underlying node, and are not suitable for all applications.</p> <p>NFS An NFS (Network File System) volume can be accessed from multiple pods at the same time, and thus provides shared data between pods. The NFS volume type is commonly used because of its ability to share data safely. Red Hat recommends to use NFS only for non-production systems.</p> Access mode Abbreviation Description ReadWriteOnce RWO A single node mounts the volume as read/write ReadOnlyMany ROX Many nodes mount the volume as read-only ReadWriteMany RWX Many nodes mount the volume as read/write Volume type RWO ROX RWX configMap Yes No No emptyDir Yes No No hostPath Yes No No iSCSI Yes Yes No local Yes No No NFS Yes Yes Yes"},{"location":"01_redhat/07-DO280/07-DO280_C1/","title":"Capitulo 1 - Gesti\u00f3n Declarativa de recursos","text":"<p>Desplegar y actualizar aplicaciones desde manifiestos de recursos y parametrizados para diferentes ambientes</p> <ul> <li>Desplegar y actualizar aplicaciones desde manifiestos de recursos que se alojan como archivos YAML</li> <li>desplegar y actualizar aplicaciones desde manifiestos de recursos que se realizan desde Kustomize</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#manifiesto-de-recursos","title":"Manifiesto de recursos","text":"<p>Una aploicaci\u00f3n de K8S es un conjunto de m\u00faltiples recurtsos que trabajan en conjunto. Cada recursos tiene una definici\u00f3n y una configuraci\u00f3n. Muchos recusos comparten configuraci\u00f3n com\u00fan de atributos para que operen correctamente. Los comandos de configuraci\u00f3n se ejecutan en un solo momento de tiempo para ejecutar correctamente. El comando imperativo configura una al tiempo.</p> <p>El modo imperativo tiene varias desventajas: - Deficiencia al reproducir - No se puede controlar las versiones - No tiene soporte para GitOps</p> <p>Por ello la forma declarativa en flujos es la opci\u00f3n mas recomendada para desplegar y actulizar aplicaciones de K8S.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#flujos-imperativos","title":"Flujos imperativos","text":"<p>Son utilizados para desarrollo y pruebas, como el siguiente ejemplo:</p> <pre><code>kubectl create deployment db-pod --port 3306 --image registry.ocp4.example.com:8443/rhel8/mysql-80\n</code></pre> <p>En esta opci\u00f3n <code>kubectl set env deplyment</code> se pueden enviar par\u00e1metros de configuranci\u00f3n dentro del pod en ejecuci\u00f3n. Estos cambios son enviados como variables extras para que el pod inicie si los valores no los tiene y resolver el problema de funcionamiento y iniciar el pod correctamente.</p> <pre><code>kubectl set env deployment/db-pod \\\nMYSQL_USER='user1' \\\nMYSQL_PASSWORD='mypa55w0rd' \\\nMYSQL_DATABASE='items'\n</code></pre> <p>Usando los comandos imperativos se pueden agregar componentes como services, routes, montaje de volumenes, y claim de vol\u00famenes persistentes. Esto sirve mucho como experimentaci\u00f3n y testing, sin embargo, trabajar con demasiadas lineas se fragmenta el trabajo.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#usando-comando-declarativo","title":"Usando comando declarativo","text":"<p>Esta forma pemirte tomar el estado previsto de la sucuencia y llevarlo a un archivo de manifiesto. El modo declarativo usa un archivo o un conjunto de archivos manifiesto.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#creando-manifiestos-de-k8s","title":"Creando manifiestos de K8S","text":"<p>Crear un manifiesto de K8S puede tomar mucho tiempo si se quiere hacer desde cero todo su contenido, sin embargo existen t\u00e9cnicas para proveer ese inicio de un manifiesto</p> <ul> <li>Usar la vista YAML de un recurso desde la consola Web</li> <li>Usando el comandos imperaticos con la opci\u00f3n <code>--dry-run=client</code> para generar el manifiesto de acuerdo a los comandos generados, as\u00ed:</li> </ul> <pre><code>kubectl create deployment hello-openshift -o yaml \\\n--image registry.ocp4.example.com:8443/redhattraining/hello-world-nginx:v1.0 \\\n--save-config \\\n--dry-run=client \\\n&gt; ~/my-app/example-deployment.yaml\n</code></pre> opci\u00f3n explicaci\u00f3n <code>--save-config</code> Con esta opci\u00f3n se graba las configuraciones del recurso en <code>kubectl.kubernetes.io/last-applied-configuration</code> <code>--dry-run=client</code> Se evita que los recursos sean creados en el cluster <p>ejmplo muestra lo m\u00ednimo de un manifiesto de un deplyment, no productivo</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: resource-manifests\n  labels:\n    app: hello-openshift\n  name: hello-openshift\nspec:\n  replicas: 2\n  selector:\n    matchLabels:\n      app: hello-openshift\n  template:\n    metadata:\n      labels:\n        app: hello-openshift\n    spec:\n      containers:\n      - image: quay.io/redhattraining/hello-world-nginx:v1.0\n        name: hello-world-nginx\n        ports:\n        - containerPort: 8080\n          protocol: TCP\n</code></pre> <p>Se puede crear un manifiesto para cada recurso que se gestiona, como alternativa, se puede cerar un solo manifiesto y all\u00ed usando <code>---</code> se puede separar en partes cada manifiesto:</p> <pre><code>---\napiVersion: apps/v1\nkind: Deployment\nmetadata:\n  namespace: resource-manifests\n  annotations:\n  ...output omitted...\n\n---\napiVersion: v1\nkind: Service\nmetadata:\n  namespace: resource-manifests\n  labels:\n    app: hello-openshift\n  name: hello-openshift\nspec:\n...output omitted...\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#flujos-declarativos","title":"Flujos declarativos","text":"<p>Y se puede crear el recurso de acuerdo a la ubicaci\u00f3n de los archivos yml en el cliente de kbctl</p> <pre><code>kubectl create -f path-to-yaml # puede ser la URL del yml\n\nkubectl create -R -f ~/mi-applicacion\ndeployment.apps/hello-openshift created\nservice/hello-openshift created        \n\ntree mi-aplicacion\nmi-aplicacion\n\u251c\u2500\u2500 example_deployment.yaml\n\u2514\u2500\u2500 service\n    \u2514\u2500\u2500 example_service.yaml\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#actualizando-recursos","title":"Actualizando recursos","text":"<p>Los recursos ya creados se pueden actualizar con la opci\u00f3n <code>kubectl apply</code></p> <pre><code>kubectl apply -f ~/my-app/example-deployment.yaml --dry-run=server --validate=true\n</code></pre> <p>Ejecutar <code>kubectl create -f</code> cuando el recurso est\u00e1 running sale error, en cambio con el comando <code>kubectl apply -f</code> al ser declarativo tiene en cuenta el estado del recurso en el cl\u00faster y el estado en el manifiesto</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#validacion-de-yaml","title":"Validaci\u00f3n de YAML","text":"<p>Antes de aplicaer los cambios en un recurso, se puede aplicar el argumento <code>--dry-run=server</code> y <code>--validate=true</code> para revisar posibles errores</p> opci\u00f3n explicaci\u00f3n <code>--dry-run=server</code> Env\u00eda solicitud al servidor sin mantener el recurso <code>--validate=true</code> opci\u00f3mn utilizada p\u00e1ra validar el input y si el request no es v\u00e1lido falla <p>Ejemplo:</p> <pre><code>kubectl apply -f ~/my-app/example-deployment.yaml --dry-run=server --validate=true\ndeployment.apps/hello-openshift created (server dry-run)\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#comparacion-de-recursos","title":"Comparaci\u00f3n de recursos","text":"<p>Con el comando <code>kubectl diff</code> se puede revisar las diferencias entre los objetos activos y los objetos en el manifiesto</p> <pre><code>kubectl diff -f example-deployment.yaml\n...output omitted...\ndiff -u -N /tmp/LIVE-2647853521/apps.v1.Deployment.resource...\n--- /tmp/LIVE-2647853521/apps.v1.Deployment.resource-manife...\n+++ /tmp/MERGED-2640652736/apps.v1.Deployment.resource-mani...\n@@ -6,7 +6,7 @@\n     kubectl.kubernetes.io/last-applied-configuration: |\n       ...output omitted...\n   creationTimestamp: \"2023-04-27T16:07:47Z\"\n-  generation: 1 1\n+  generation: 2\n</code></pre> <p>NOTA Si hay cambios en el recurso, es necesario reiniciar los pod's por medio de un rollout, o bajando las r\u00e9plicas a una menor expresi\u00f3n (1) y luego volverlas a subir</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#parchado-de-recursos-kubernetes","title":"Parchado de recursos Kubernetes","text":"<p>Es la modificaci\u00f3n a partir de una parte o un archivo json/yml a un recurso en OCP. Se utiliza el comando <code>oc patch</code>. Se utiliza el argumento <code>-p</code> para agregar el la parte necesaria:</p> <pre><code>oc patch deployment hello -p '{\"spec\":{\"template\":{\"spec\":{\"resources\":{\"requests\":{\"cpu\": \"100m\"}}}}}}'\n</code></pre> <p>O utilizando el archivo completo:</p> <pre><code>oc patch deployment hello --patch-file ~/volume-mount.yaml\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#kustomize-overlays","title":"Kustomize Overlays","text":"<ul> <li>Desplegar aplicaciones desde un manifiesto de recursos que son ampliados por Kustomize</li> </ul> <p>Cuando se usa K8S, multiples equipos usan ambientes para desarrollo, staging, testing y producci\u00f3n para desplegar aplicaciones, Cada ambiente tiene peque\u00f1os cambios en su configuraci\u00f3n, por ejemplo: el n\u00famero de r\u00e9plicas para cargas de trabajo en producci\u00f3n es menor en un ambiente de testing y es ac\u00e1 donde Kustomize soporta estos diferentes casos.</p> <p>El comando <code>oc</code> como el comando <code>kubectl</code> soportan la herramienta kustomize</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#estructura-de-archivos-kustomize","title":"Estructura de archivos Kustomize","text":"<p>Se trabaja con un directorio de archivos que contiene el archivo <code>kustomization.yaml</code> al igual que los archivos de service, deployment y secret.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#base","title":"Base","text":"<p>En directorio base contiene el archivo <code>kustomization.yaml</code> el cual tiene una lista de campos de recursos que incluye todos los archivos de recursos, as\u00ed:</p> <pre><code>base\n\u251c\u2500\u2500 configmap.yaml\n\u251c\u2500\u2500 deployment.yaml\n\u251c\u2500\u2500 secret.yaml\n\u251c\u2500\u2500 service.yaml\n\u251c\u2500\u2500 route.yaml\n\u2514\u2500\u2500 kustomization.yaml\n</code></pre> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nresources:\n- configmap.yaml\n- deployment.yaml\n- secret.yaml\n- service.yaml\n- route.yaml\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#overlays","title":"Overlays","text":"<p>Es la capacidad de sobreponer los artefactos YAML que son declarativos o parches sobre las configuraciones generales sin modificar los archivos originales, con las sguiente estrutura ejemplo:</p> <p></p> <pre><code>base\n\u251c\u2500\u2500 configmap.yaml\n\u251c\u2500\u2500 deployment.yaml\n\u251c\u2500\u2500 secret.yaml\n\u251c\u2500\u2500 service.yaml\n\u251c\u2500\u2500 route.yaml\n\u2514\u2500\u2500 kustomization.yaml\noverlay\n\u2514\u2500\u2500 development\n  \u2514\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 testing\n  \u2514\u2500\u2500 kustomization.yaml\n\u2514\u2500\u2500 production\n  \u251c\u2500\u2500 kustomization.yaml\n  \u2514\u2500\u2500 patch.yaml\n</code></pre> <p>Ejemplo del contenido de un archivo <code>kutomization.yaml</code> de un ambiente de desarrollo en el directorio <code>overlay/deplyment</code>:</p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: dev-env\nresources:\n- ../../base\n</code></pre> <p>Otro ejemplo, se usa el <code>../../base</code> para la aplicaci\u00f3n <code>frontend-app/overlay/development/kustomization.yaml</code> para crear los recursos en el namespace dev_env.</p> <p>Los siguientes campos tendr\u00e1n los valores para todos los recursos en el archivo kustomization:</p> Campo Descripci\u00f3n, para todos los recusos <code>namespace</code> Se especifica el namespace <code>namePrefix</code> Se adiciona el nombre prefijo <code>nameSuffix</code> Se adiciona nombre de sufijo <code>commonLabels</code> Se adicionan etiquetas y a los selectors <code>commonAnnotations</code> Se adiciona anotacionesy a los selectors <p>Uno puede personalizar para m\u00faltiples ambientes usando overlays &amp; patching. Los parches utilizan 2 elementos: <code>patch</code> y <code>target</code>.</p> <p>NOTA:  Las llaves PatchesJson6902 &amp; PatchesStrategicMerge estan deprecadas desdela versi\u00f3n Kustomize 5, fueron reeplazados con 1 sola llave</p> <p>Ejemplo de un archivo <code>kustomize.yaml</code> de un directorio <code>overlays/testing</code></p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: test-env\npatches:\n- patch: |-\n    - op: replace\n      path: /metadata/name\n      value: frontend-test\n  target:\n    kind: Deployment\n    name: frontend\n- patch: |-\n    - op: replace\n      path: /spec/replicas\n      value: 15\n  target:\n    kind: Deployment\n    name: frontend\nresources:\n- ../../base\ncommonLabels:\n  env: test\n</code></pre> <p>Se puede ver la lista de parches a actualizar, en el primero se realiza cambio en el nombre por <code>frontend-test</code>. Los campos del <code>target</code> el tipo y nombre del recurso a aplicar el parche por <code>frontend-test</code>. Tambi\u00e9n se aplica un cambio en el n\u00famero de r\u00e9licas. Al final, en <code>resources</code> tiene el path de el archivo <code>kustomization.yaml</code> con el cual se trabaja y se desplegarn los recursos y a continuaci\u00f3n este es un ejemplo de ese archivo:</p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: prod-env\npatches:\n- path: patch.yaml\n  target:\n    kind: Deployment\n    name: frontend\n  options:\n    allowNameChange: true\nresources:\n- ../../base\ncommonLabels:\n  env: prod\n</code></pre> <p>En este ejemplo anterior, se ve como en el campo de <code>allowNameChange</code> habilita el update para usar en el patch.</p> <p>Por \u00faltimo, un ejemplo de como ser\u00eda el contenido un archivo <code>patch.yaml</code> donde se aplica el update a un deplyment con el nombre <code>frontend-prod</code> y se especifica ek n\u00famero de r\u00e9plicas a 5</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name:`frontend-prod\nspec:\n  replicas: 5\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#vista-y-desplegar-recursos-usando-kustomize","title":"Vista y desplegar Recursos usando Kustomize","text":"<p>Visualizar los manifiestos sin aplicar los cambios en el cluster</p> <pre><code>kubectl kustomize overlay/production\n</code></pre> <p>Aplicar los cambios en el cl\u00faster:</p> <pre><code>kubectl apply -k overlay/production\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#eliminar-recursos-usando-kustomize","title":"Eliminar recursos usando Kustomize","text":"<pre><code>oc delete -k overlay/production\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#generadores-kustomize","title":"Generadores Kustomize","text":"<p>Los <code>ConfigMap</code> tienen data no confidencial usando llaves-valor. Los <code>secrets</code> en cambio si son llaves-valor con data confidencial. Kustomize tiene los campos <code>configMapGenerator</code> y <code>secretGenerator</code> que generan ambos tipoos de recursos. Estos generadores pueden incluir archivos externor por lo que se puede utilizar archivos generados por otras herramientas o que est\u00e1n en sistemas diferentes y pueden ayudar a gestionar esre contenido.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#configmap-generator","title":"ConfigMap Generator","text":"<p>Kustomize tiene un campo llamadao <code>configMapGenerator</code> que crea el mapa de configuraci\u00f3n. La generaci\u00f3n de estos mapas con Kustomize permite agregar un hash al name, y cualquier cambio (<code>trigger</code>) y genera un <code>rolling update</code>.</p> <p>Ejemplo de un archivo <code>kustomization.yaml</code> con la descriipci\u00f3n anterior:</p> <pre><code>apiVersion: kustomize.config.k8s.io/v1beta1\nkind: Kustomization\nnamespace: hello-stage\nresources:\n- ../../base\nconfigMapGenerator:\n- name: hello-app-configmap\n  literals:\n    - msg=\"Welcome!\"\n    - enable=\"true\"\n</code></pre> <p>Y del archivo del deployment.yaml:</p> <pre><code>apiVersion: apps/v1\nkind: Deployment\nmetadata:\n  name: hello\n  labels:\n    app: hello\n    name: hello\nspec:\n...output omitted...\n    spec:\n      containers:\n      - name: hello\n        image: quay.io/hello-app:v1.0\n        env:\n        - name: MY_MESSAGE\n          valueFrom:\n            configMapKeyRef:\n              name: hello-app-configmap\n              key: msg\n        - name: MSG_ENABLE\n          valueFrom:\n            configMapKeyRef:\n              name: hello-app-configmap\n              key: enable\n</code></pre> <p>Para visualizar y aplicar el despliegue en todos los recursos y personalizar este archivo Kustomize lo define en eel directorio</p> <pre><code>kubectl kustomize overlays/staging\n\nkubectl apply -k overlays/staging\n\noc get all\n</code></pre> <p>Anteriormente, con el <code>apply -k</code> se aplica la confiuraci\u00f3n y Kustomize agrega un nuevo atributo al ConfigMap. Se puede generar un nuevo ConfigMap usando archivos llave: <code>.properties</code> o <code>.env</code> usando el campo envs para su llamado.Incluso se puede generar escribiendo literakmente los campos</p> <p>Ejemplo para generar diferentes tipo de ConfigMap:</p> <pre><code>.\n.\n.\nconfigMapGenerator:\n- name: configmap-1\n  files:\n    - application.properties\n- name: configmap-2\n  envs:\n    - configmap-2.env\n- name: configmap-3\n  literals:\n    - name=\"configmap-3\"\n    - description=\"literal key-value pair\"\n</code></pre> <p>Ejemplo de un archivo <code>application.properties</code> del ejemplo anterior:</p> <pre><code>Day=Monday\nEnable=True\n</code></pre> <p>Y el ejemplo del contenido del un <code>configmap-1</code></p> <pre><code>Greet=Welcome\nEnable=True\n</code></pre> <p>Se puede utlizar el comnando <code>kubectl kustomize .</code> para ver los detalles de los recursos personalizados</p>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#secret-generator","title":"Secret Generator","text":"<p>Asi como la creaci\u00f3n del ConfigMap, tambi\u00e9n se pueden crear secretos de la misma manera:</p> <pre><code>.\nsecretGenerator:\n- name: secret-1\n  files:\n    - password.txt\n- name: secret-2\n  envs:\n    - secret-mysql.env\n- name: secret-3\n  literals:\n    - MYSQL_DB=mysql\n    - MYSQL_PASS=root\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#opciones-adicionales-para-el-generator","title":"Opciones adicionales para el Generator","text":"<p>Existen opciones que cuando se aplica cambios en los ConfigMap y secrets generan cambios que en algunos caso pueden desencadenar en un rollout ya que hay casos donde que los generadores agregar un atru\u00bfibutos que al momento de actualizarse el configmap o secret el nombre del recuros cambia. Por ello se pueden agregar opciones que desactivan acciones, o agregar etiquetas y anotaciones usando el campo <code>generatorOptions</code></p> <p>Ejemplo:</p> <pre><code>.\n.\n.\nconfigMapGenerator:\n- name: my-configmap\n  literals:\n    - name=\"configmap-3\"\n    - description=\"literal key-value pair\"\ngeneratorOptions:\n  disableNameSuffixHash: true\n  labels:\n    type: generated-disabled-suffix\n  annotations:\n    note: generated-disabled-suffix\n</code></pre> <p>Y la vista es la siguiente:</p> <pre><code>kubectl kustomize .\n\napiVersion: v1\ndata:\n  description: literal key-value pair\n  name: configmap-3\nkind: ConfigMap\nmetadata:\n  annotations:\n    note: generated-disabled-suffix\n  labels:\n    type: generated-disabled-suffix\n  name: my-configmap\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C1/#documentacion","title":"Documentaci\u00f3n","text":"<ul> <li>Declarative Management of Kubernetes Objects Using Kustomize</li> <li>Your Guide to Continuous Delivery with OpenShift GitOps and Kustomize</li> <li>Customization of Kubernetes YAML Configurations</li> <li>JavaScript Object Notation (JSON) Patch</li> <li>Notes on the Strategic Merge Patch</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C2/","title":"Capitulo 2 - Despliegue de aplicaciones empaquetadas","text":"<p>Desplegar aplicaciones desde manifiestros de recursos que se empaquetan para compartir y distribuir</p> <ul> <li>Desplegar apps y sus dependencias desde manifiestos que se almacenan como templates en OCP </li> <li>Despligue y actualizaci\u00f3n de apps desde manifiestos que se empaquetan como Helm charts</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#openshift-templates","title":"Openshift Templates","text":"<p>Es un recurso personalizado de configuraciones recursos de k8s. Los templates tiene par\u00e1metros. Un recurso template es una extensi\u00f3n en Kubernetes que es proporcianado por Red Hat para OCP. Existen templates disponibles en el namespace <code>openshift</code> y durante la instalaci\u00f3n se pueden adicionar. Tambi\u00e9n se puede crear plantillas desde cero o tomar una plantilla para adaptarla para una necesidad de un proyecto.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#descrubiendo-los-templates","title":"Descrubiendo los Templates","text":"<p>Listar las plantillas ejemplo del cluster de OCP del namespace <code>openshift</code></p> <pre><code>$ oc get templates -n openshift\nNAME                     DESCRIPTION           PARAMETERS   OBJECTS\ncache-service            Red Hat Data Grid...  8 (1 blank)  4\ncakephp-mysql-example    An example CakePHP... 21 (4 blank) 8\ncakephp-mysql-persistent An example CakePHP... 22 (4 blank) 9\n.\n.\n.\n</code></pre> <p>Si se quiere revisar el contenido de un template</p> <pre><code>\n[user@host ~]$ oc describe template cache-service -n openshift\nName: cache-service\nNamespace: openshift\nCreated: 2 months ago\nLabels: samples.operator.openshift.io/managed=true\ntemplate=cache-service\nDescription: Red Hat Data Grid is an in-memory, distributed key/value store.\nAnnotations: iconClass=icon-datagrid\n.\n.\n.\n\nParameters:\n    Name: APPLICATION_NAME\n    Display Name: Application Name\n    Description: Specifies a name for the application.\n    Required: true\n    Value: cache-service\n\n.\n.\n.\n\n    Name: APPLICATION_PASSWORD\n    Display Name: Client Password\n    Description: Sets a password to authenticate client applications.\n    Required: false\n    Generated: expression\n    From: [a-zA-Z0-9]{16}\nObject Labels: template=cache-service\n\nMessage: &lt;none&gt;\n\nObjects:\n    Secret ${APPLICATION_NAME}\n    Service ${APPLICATION_NAME}-ping\n    Service ${APPLICATION_NAME}\n    StatefulSet.apps ${APPLICATION_NAME}\n</code></pre> <p>Ver solamente los parametros que usa un template:</p> <pre><code>oc process --parameters cache-service -n openshift\noc process --parameters -f  my-cache-service.yaml\noc get template cache-service -o yaml -n openshift\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#uso-de-templates","title":"Uso de Templates","text":"<p>El comando <code>oc new-app</code> con el argumento <code>--template</code> puede desplegar un template directamente en el proyecto <code>openshift</code>, como el siguiente ejemplo:</p> <pre><code>oc new-app --template=cache-service -p APPLICATION_USER=my-user\n</code></pre> <p>Se puede utilizar la opci\u00f3n <code>oc process</code> para aplicar los par\u00e1metros de un template en producci\u00f3n.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#crear-una-aplicacion-a-partir-del-template","title":"Crear una aplicaci\u00f3n a partir del template:","text":"<p>Los siguientes ejemplos muestran c\u00f3mo se puede crear aplicaciones utilizando la data de templates, ya que todos deben al final enviar la salida a un manifiesto final para luego aplicarlo:</p> <pre><code>## With process directly\noc process my-cache-service -p APPLICATION_USER=user1 -o yaml &gt; my-cache-service-manifest.yaml\n\n## With a file\noc process -f my-cache-service.yaml -p APPLICATION_USER=user1 -o yaml &gt; my-cache-service-manifest.yaml\n\noc process my-cache-service -o yaml \\\n  -p TOTAL_CONTAINER_MEM=1024 \\\n  -p APPLICATION_USER='cache-user' \\\n  -p APPLICATION_PASSWORD='my-secret-password' \\\n  &gt; my-cache-service-manifest.yaml\n\n## With *.env to variables\ncat my-cache-service-params.env\nTOTAL_CONTAINER_MEM=1024\nAPPLICATION_USER='cache-user'\nAPPLICATION_PASSWORD='my-secret-password'\n\noc process my-cache-service -o yaml --param-file=my-cache-service-params.env &gt; my-cache-service-manifest.yaml\n</code></pre> <p>NOTA Normalmente un manifiesto no se requiere  para el uso del template por lo que se puede aoplicar directamente por medio de un filtro <code>| oc apply -f -</code></p> <pre><code>oc process my-cache-service --param-file=my-cache-service-params.env | oc apply -f -\n</code></pre> <pre><code>oc new-app --template=cache-service -p APPLICATION_USER=my-user\n\noc process my-cache-service -p APPLICATION_USER=user1 -o yaml &gt; my-cache-service-manifest.yaml\n\noc process -f my-cache-service.yaml -p APPLICATION_USER=user1 -o yaml &gt; my-cache-service-manifest.yaml\n\noc process my-cache-service -o yaml \\\n-p TOTAL_CONTAINER_MEM=1024 \\\n-p APPLICATION_USER='cache-user' \\\n-p APPLICATION_PASSWORD='my-secret-password' \\\n&gt; my-cache-service-manifest.yaml\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#update-de-aplicaciones-desde-templates","title":"Update de aplicaciones desde Templates","text":"<p>Como se utiliza <code>oc apply</code>, despues de desplegar, se puede procesar el template despues para aplicar actualizaciones, pero no todos los workloads de updates permites esta acci\u00f3n, entonce se debe comparar con <code>oc diff -f -</code> agregando comop filtro para validar la diferncia entre \u00f1ps parametros aplicados:</p> <pre><code>oc process my-cache-service -o yaml --param-file=my-cache-service-params-2.env | oc diff -f -\n.\n.\n.\n\n- generation: 1\n+ generation: 2\n  labels:\n    application: cache-service\n    template: cache-service\n      timeoutSeconds: 10\n  resources:\n    limits:\n      - memory: 1Gi\n      + memory: 2Gi\n  requests:\n    cpu: 500m\n      - memory: 1Gi\n      + memory: 2Gi\n terminationMessagePath: /dev/termination-log\n terminationMessagePolicy: File\n volumeMounts:\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#gestion-de-templates","title":"Gesti\u00f3n de Templates","text":"<p>Para producci\u00f3n, realice una copia del contenido del manifiesto del template, de esta forma podr\u00e1 perosnalizar los valores que quiere aplicar, como:</p> <ul> <li>Renombrar el archivo manifiesto </li> <li>Modificar los valores de los par\u00e1metros</li> <li>Eliminar el namespace</li> </ul> <pre><code>oc get template cache-service -o yaml -n openshift &gt; my-cache-service.yaml\n\noc create -f my-cache-service.yaml\n\noc create -f my-cache-service.yaml -n shared-templates\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#graficos-de-helm","title":"Gr\u00e1ficos de Helm","text":"<ul> <li>Desplegar y actualizar apps desde manifiestos de recursos que son empaquetadas como gr\u00e1ficos Helm</li> </ul> <p>Helm aplicaci\u00f3n open source que ayuda a gestionar el lifecycle de las apps de K8S a trav\u00e9s del concepto de gr\u00e1ficos, describiendo un conjunto de recursos a implementar. Algunas organizaciones distribuyen Helm Chart para desplegar apps. Importante resaltar que esto no cubre todas las necesidades de la gesti\u00f3n de algunas aplicaciones.</p> <p>Helm Charts define los recursos que se pueden desplegar, es una colecci\u00f3n de archivos definidos en una estructura los cuales contienen la metadata, definici\u00f3n de recursos y material de soporte. Algunos desarrolladores de este suelen utilizar lenguaje Go para definir recursos</p> <ul> <li>Estructura b\u00e1sica de archivos Helm</li> </ul> <pre><code>ejemplo_chart/\n\u251c\u2500\u2500 Chart.yaml\n\u251c\u2500\u2500 templates\n| |\u2500\u2500 example.yaml\n\u2514\u2500\u2500 values.yaml\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#usando-helm-charts","title":"Usando Helm Charts","text":"<p>Como tal es una app CLI con comandos interactivos con las siguientes identidades</p> Identidad Descripci\u00f3n Charts Apps empaquetadas que despliegan con el comando  <code>helm</code> Releases El resultado de la implementaci\u00f3n de un Chart. Se puede desplegar un * Cada implemenatci\u00f3n es un Release* diferente y puede hacerlo n veces en el mismo cl\u00faster Versions Un chart puede tener muchas versiones"},{"location":"01_redhat/07-DO280/07-DO280_C2/#inspeccion-de-helm-chart","title":"Inspecci\u00f3n de Helm Chart","text":"<p>Se usa el comando <code>helm show</code> para visualizar la infoemaci\u00f3n acerca de un chart. Con el argumetnto <code>chart</code> muestra la informaci\u00f3n general y con el argumento <code>values</code> muestra los valores por defecto del chart</p> <pre><code>helm show chart chart-reference\nhelm show values chart-reference\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#instalacion-de-helm-charts","title":"Instalaci\u00f3n de Helm Charts","text":"<p>Despues de realizar la inspecci\u00f3n se puede desplegar los recursos chart usando <code>helm install</code>. Siempre se debe revisar la documentaci\u00f3n del chart antes de iniciar la instalaci\u00f3n, para conocer los prerequisitos y pasos extra u otra informaci\u00f3n.</p> <p>Para instalar un chart se deben definir los siguientes par\u00e1metros:</p> <ul> <li>Namaspace del deployment</li> <li>Valores a reemplazar</li> <li>Nombre del release</li> </ul> <p>Los Helm charts pueden ser de muchos tipos de recursos de K8s y pueden tener o no un namespace. La mayor\u00eda al desplegarse no crean un namespace. Normalmente cuando se despliega un chart que tiene esta estructura crea namespace. Una ves definido el namespace puede definirse los valores los cuales pueden ser desde un YAML</p>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#render-de-manifiest-desde-un-chart","title":"Render de Manifiest desde un Chart","text":"<p>Con el argumento <code>--dry-run</code> se pre-visualiza los efectos de installar un chart</p> <pre><code>helm install release-name chart-reference  --dry-run --values values.yaml\nNAME: release-name\nLAST DEPLOYED: Tue May 30 13:14:57 2023\nNAMESPACE: current-namespace\nSTATUS: pending-install\nREVISION: 1\nTEST SUITE: None\nHOOKS:\nMANIFEST:\n---\n# Source: chart/templates/serviceaccount.yaml\napiVersion: v1\nkind: ServiceAccount\nmetadata:\n  name: my-release-sa\n  labels:\n.\n.\n.\n\nNOTES:\nThe application can be accessed via port 1234.\n.\n.\n.\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#release","title":"Release","text":"<p>Cuando la instalaci\u00f3n finaliza correctamente, a parte de crear los recursos se crear un versionamiento o release la cuaql reside en el store como un secret <code>helm.sh/release.v1</code></p>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#inspeccionando-releases","title":"Inspeccionando Releases","text":"<p>Se utiliza el comando <code>helm list</code> para validar los releases en el cluster. Y similar al comando de <code>kubectl</code> que se ayuda con el argumento de <code>--all-namespaces</code> sin embargo este comando trabaja sin \u00e9l</p>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#rolling-back-upgrades-de-helm","title":"Rolling Back Upgrades de Helm","text":"<p>Helm se apoya en los logs del upgrade del release, se revisa los comabios y se regresa al release previo, con <code>history</code> se visulizan los logs y luego </p> <pre><code>helm history release_name\n\nhelm rollback release_name revision\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#repositorios-helm","title":"Repositorios Helm","text":"<p>Los Charts pueden ser distribuidos como archivos, carpetas o im\u00e1genes de contenedor o por repositorios. Con el comando <code>helm repo</code> y algunos subcomandos se pueden trabajar, como</p> Subcomando Descripci\u00f3n <code>add</code> URL_REPOSITORIO Agrega el repositorio <code>list</code> Lista los repositorios <code>update</code> Actualiza los repositorios <code>remove</code> NOMBRE_REPOSITORIO Elimina repositorios <p>Ejemplo:</p> <pre><code>helm repo add openshift-helm-charts https://charts.openshift.io/\n</code></pre> <p>Tambi\u00e9n se \u00b4puede buscar un repositorio con <code>helm search repo</code></p>"},{"location":"01_redhat/07-DO280/07-DO280_C2/#documentacion","title":"Documentaci\u00f3n","text":"<ul> <li>Using Helm</li> <li>Helm Charts</li> <li>Helm Chart Repository Guide</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C3/","title":"Capitulo 3 - Autenticaci\u00f3n y Autorizaci\u00f3n","text":"<p>Configurar autenticaci\u00f3n con un proveedor de identidad HTPasswd y asignar roles a ususario/grupos</p> <ul> <li>Configurar un proveedor de identidades HTPAsswd para la autenticaci\u00f3n de OCP</li> <li>Definir controles de acceso basados en roles y aplicar permisos a usuarios.</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#configurar-proveedor-de-identidades","title":"Configurar Proveedor de Identidades","text":"<p>Muchos de lso recursos de OCP se relacionan con autenticaci\u00f3n y autorizaci\u00f3n. La siguiente lista muestra los tipos de recursos primarios y otras definiciones:</p> Tipo de Recurso  Primario Descripci\u00f3n user El recurso tipo usuarios son indentidades en OCP que interact\u00faan con el API Server y representa un actor en el sistema. Se asigna permisos por roles directamente a \u00e9l o a un grupo al que pertenece identity El recurso de identidades ayuda a mantener el registro de los intentos de autenticaci\u00f3n de un usuario de alg\u00fan proveedor de identidades. todo dato se almacena Service Account El recursos cuenta de servicio es para cominicar las aplicaciones con la API independientemente cuando las credenciales de usuario no son necesarias. Ejemplo: la credenciales de usuario no se comparten y se pasan las cuentas de servicio Group El recurso grupos repesenta un conjunto de usuarios. Los usuarios se asignan a grupos. OCP provee grupos de sistema o virtuales aprovisionados automaticamente por el cl\u00faster Role El recurso role define las operaciones API que el usuario puede hacer en un recurso determinado. Los roles se pueden asignar a usuarios grupos y cuentas de servicio"},{"location":"01_redhat/07-DO280/07-DO280_C3/#authenticating-api-requests","title":"Authenticating API Requests","text":"<p>La autenticaci\u00f3n y la autorizaci\u00f3n son capas de seguridad habilitadas para un usuario interactuar en un cl\u00faster.</p> <p></p> <p>El API de OCP tiene 2 mpetodos para las solicitudes de autenticaci\u00f3n</p> <ul> <li>Accesos de token OAuth</li> <li>Certificados cliente X.509</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#operador-de-autenticacion","title":"Operador de Autenticaci\u00f3n","text":"<p>OCP tiene o provee el operador de Autenticaci\u00f3n que se ejecuta en un servidor de OAuth. Este provee tokens de acceso a los usuarios que intentan autenticar y el debe estar configurado con un proveedo de identidades.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#proveedor-de-identidades","title":"Proveedor de identidades","text":"<p>Un servidor OCP OAuth se puede configurar con muchos proveedores de identidades, entre ellos:</p> Proveedor de Identidades Descripci\u00f3n HTPasswd Validaci\u00f3n de usuario/password contra un secret que los tiene almacenados con el comando <code>htpasswd</code> Keystone Autenticaci\u00f3n compartida habilitada con servidor OpenStack Keystone v3 LDAP Proveedor LDAP de usuarios/passwords de un server con LDAPv3 usando autenticaci\u00f3n bind GitHub or GitHub Enterprise Se puede configurar GitHub como proveedor de identidades OpenID Connect Se puede integrar usando Autorizaci\u00f3n Code Flow"},{"location":"01_redhat/07-DO280/07-DO280_C3/#autenticando-como-admin-cluster","title":"Autenticando como Admin Cl\u00faster","text":"<p>Antes de iniciar la configuraci\u00f3n con con un proveedor de identidades, se debe acceder al cl\u00faster de OCP como administrador. Una instalaci\u00f3n nueva tiene 2 opciones de autenticaci\u00f3n por solicitud al API. La primera es a traves de el archivo <code>kubeconfig</code> el cual incluye un certificado x509 que nunca expira. El otro camino es a traves de <code>kubeadmin</code> desde un servidor virtual. Una correcta autenticaci\u00f3n otorga un token con acceso</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#autenticando-con-certificado-x509","title":"Autenticando con certificado X.509","text":"<p>Durante del proceso de instalaci\u00f3n de OCP se crea un archivo \u00fanico <code>kubeconfig</code> en el directorio <code>auth</code>. Este archivo tiene en detalle los par\u00e1metros para relaizar una conexi\u00f3n CLI como cliente hacia el API del server, e incluye el certificado X.509.</p> <p>Los logs de instalaci\u00f3n est\u00e1 la ruta, es tipo info</p> <pre><code>INFO Run 'export KUBECONFIG=/root/auth/kubeconfig' to manage the cluster with 'oc'.\n</code></pre> <p>Para acceder a la granja de OCP, se exporta el path de del <code>kubeconfig</code> tal como se ve en el LOG y luego puede ejecutar un <code>oc get nodes</code> para verificar. Como alternativa puede usar el argumento <code>--kubeconfig</code> para describir el path, as\u00ed:</p> <pre><code>oc --kubeconfig /home/user/auth/kubeconfig get nodes\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#autenticando-con-usuario-vitual-kubeadmin","title":"Autenticando con usuario vitual <code>kubeadmin</code>","text":"<p>Despues de una completa instalaci\u00f3n, OCP crea un usuario virtual <code>kubeadmin</code>. El secret esta tipo hash. El proceso de instalador genea un password aleatorio y unico para la administraci\u00f3n del cl\u00faster y en los logs de instalaci\u00f3n se puede el usuario, el password y la URL de acceso a la consola</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#eliminando-el-usuario-virtual","title":"Eliminando el usuario virtual","text":"<p>Luego de definir un proveedor de identidad, cerar usuario y asignarle el role de admin cl\u00faster, se puede eliminar el usuario <code>kubeadmin</code></p> <pre><code>oc delete secret kubeadmin -n kube-system\n</code></pre> <p></p> <p>Si antes de eliminar no se cuenta con un usuario con role Admin o no se tiene una copia del archivo <code>kubeconfig</code> la alternativa de acceso es destruir y reinstalar el cluster</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#gestionando-usuarios-con-el-proveedor-de-identidad-htpasswd","title":"Gestionando usuarios con el proveedor de identidad HTPasswd","text":"<p>Gestionar las credenciales de un usuario con el proveedor de identidades requiere la creaci\u00f3n de un archivo temporal  <code>HTPasswd</code> el cual se modifica y luego se aplica los cambios.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#creando-el-archivo-htpasswd","title":"Creando el archivo HTPasswd","text":"<pre><code>htpasswd -c -B -b /tmp/htpasswd eocampo myp4ssw0rd\n</code></pre> <p>La opci\u00f3n <code>-c</code> reempaza el contenido del archivo si este ya existe. Con la opci\u00f3n <code>-b</code> se actualiza el password y con solo la opci\u00f3n <code>-D</code> se eliminan las credenciales</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#creando-el-secret-de-htpasswd","title":"Creando el secret de HTPasswd","text":"<p>Cuando se usa el proveedor HTPasswd, se debe crear un secret que contenga los datos del archivo <code>htpasswd</code>. </p> <pre><code>oc create secret generic htpasswd-secret --from-file htpasswd=/tmp/htpasswd -n openshift-config\n</code></pre> <p>NOTA Un secret que tiene el IdP (Identity Provider) HTPasswd debe tener el prefijo <code>htpasswd=</code> antes de especificar la rurta del archivo</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#extrayendo-los-datos-del-secret","title":"Extrayendo los datos del secret","text":"<p>Cuando se agregan o remueven usuarios se tiliza el comando <code>oc extract</code> para recuperar el secret. Por defecto el comando guarda cada llave del secret en un archivo separado, sin embargo se puede reubicar la salida de todos las llaves a un solo archivo, asi:</p> <pre><code>oc extract secret/htpasswd-secret -n openshift-config --to /tmp/ --confirm\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#actualizandoel-secret-del-htpasswd","title":"Actualizandoel secret del HTPasswd","text":"<p>El secret se debe actualizar luego de adicionar, modificar o incluso eliminar un usuario y se puejde hacer con el comando <code>oc set data secret</code> para actualizar. A menos que el nombre del archivo no sea <code>htpasswd</code> se debe especificar, asi:</p> <pre><code>oc set data secret/htpasswd-secret --from-file htpasswd=/tmp/htpasswd -n openshift-config\n</code></pre> <p>Una ves actualizado el secret el operador OAuth re-despliega los pods del namespace <code>openshift-authentication</code>. Se puede monitorrear asi:</p> <pre><code>watch oc get pods -n openshift-authentication\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#configurando-el-idp-htpasswd","title":"Configurando el IdP HTPasswd","text":"<p>El IdP valida los usuarios contra un secret que contiene los nombres de usuario y contrase\u00f1as y solo el Admin del Cl\u00faster puede modifcar los datos.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#configurando-el-recurso-oauth-tipo-personalizado","title":"Configurando el recurso OAuth tipo personalizado","text":"<p>Para usar el IdP HTPasswd, la personalizaci\u00f3n del recurso OAuth debe editarse para agregar una entrada a la matriz de <code>.spec.identityProviders</code></p> <pre><code>apiVersion: config.openshift.io/v1\nkind: OAuth\nmetadata:\n  name: cluster\nspec:\n  identityProviders:\n  - name: my_htpasswd_provider\n    mappingMethod: claim\n    type: HTPasswd\n    htpasswd:\n      fileData:\n        name: htpasswd-secret\n</code></pre> entry explicaci\u00f3n - name: my_htpasswd_provider Nombre del IdP mappingMethod: claim La opci\u00f3n <code>claim</code> no permite el inicio de sesi\u00f3n con diferentes IdP name: htpasswd-secret secret existente que contiene los datos"},{"location":"01_redhat/07-DO280/07-DO280_C3/#actulizando-el-recurso-personalizadode-oauth","title":"Actulizando el recurso personalizadode OAuth","text":"<p>Primero se exporta el contenido a un yaml con el comando <code>get</code> . En el output generado se edita para modificar los cambios del IdP y sus configuraciones y al completarse se guardan los cambios y luego se reemplaza con el comando <code>replace</code> as\u00ed:</p> <pre><code>oc get oauth cluster -o yaml &gt; oauth.yaml\n\noc replace -f oauth.yaml\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#eliminando-usuarios-e-idp","title":"Eliminando usuarios e IdP","text":"<ul> <li>Elimiando un usuario del <code>httpsswd</code></li> </ul> <pre><code>htpasswd -D /tmp/htpasswd manager\n</code></pre> <ul> <li>Actualizar el secret eliminando que queda del password del recurso del usuario</li> </ul> <pre><code>oc set data secret/htpasswd-secret --from-file htpasswd=/tmp/htpasswd -n openshift-config\n</code></pre> <ul> <li>Eliminar el usuario</li> </ul> <pre><code>oc delete user manager\n</code></pre> <ul> <li>IdP, se busca el IdP en el cl\u00faster y luego se elimina:</li> </ul> <pre><code>oc get identities | grep manager\n\noc delete identity my_htpasswd_provider:manager\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#asignacion-de-privilegios-de-administracion","title":"Asignaci\u00f3n de privilegios de administraci\u00f3n","text":"<pre><code>adm policy add-cluster-role-to-user cluster-admin eocampo\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#documentacion","title":"Documentaci\u00f3n","text":"<ul> <li>Understanding Identity Provider Configuration</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C3/#definir-y-aplicar-permisos-con-rbac","title":"Definir y aplicar permisos con RBAC","text":""},{"location":"01_redhat/07-DO280/07-DO280_C4/","title":"Capitulo 4 - Seguridad de Redes","text":""},{"location":"01_redhat/07-DO280/07-DO280_C4/#proteccion-externa-de-trafico-con-tls","title":"Protecci\u00f3n Externa de Tr\u00e1fico con TLS","text":""},{"location":"01_redhat/07-DO280/07-DO280_C4/#configurar-politicas-de-redes","title":"Configurar Politicas de Redes","text":""},{"location":"01_redhat/07-DO280/07-DO280_C4/#proteccion-interna-de-trafico-con-tls","title":"Protecci\u00f3n Interna de Tr\u00e1fico con TLS","text":""},{"location":"01_redhat/07-DO280/07-DO280_C5/","title":"Capitulo 5 - Exposici\u00f3n de aplicaciones que no son HTTP/SNI","text":""},{"location":"01_redhat/07-DO280/07-DO280_C5/#servicio-de-balanceador-de-carga","title":"Servicio de Balanceador de Carga","text":""},{"location":"01_redhat/07-DO280/07-DO280_C5/#redes-secundarias-multus","title":"Redes Secundarias Multus","text":""},{"location":"01_redhat/07-DO280/07-DO280_C6/","title":"Capitulo 6 - Habilitaci\u00f3n de autoservicio de desarrollo","text":""},{"location":"01_redhat/07-DO280/07-DO280_C6/#quotas-en-proyectos-y-cluster","title":"Quotas en Proyectos y Cluster","text":""},{"location":"01_redhat/07-DO280/07-DO280_C6/#limites-de-recursos-por-proyecto-limit-range","title":"L\u00edmites de Recursos por proyecto (Limit Range)","text":""},{"location":"01_redhat/07-DO280/07-DO280_C6/#template-de-proyecto-y-role-de-autoaprovisionamiento","title":"Template de Proyecto y Role de Autoaprovisionamiento","text":""},{"location":"01_redhat/07-DO280/07-DO280_C7/","title":"Capitulo 7 - Gesi\u00f3n de Operador de Kubernetes","text":"<p>Instalar y actualizar operadore del ciclo de vida y operadores de versi\u00f3n del cluster</p> <ul> <li>Explicar operadores y sus enfoques para instalar y actualizar</li> <li>Instalar y actualizar operadores por medio de la consola Web y el ciclo de vida</li> <li>Instalar y actualizar operadores mediante API del ciclo de vida </li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#operador-de-kubernetes-el-administrador-del-ciclo-de-vida-de-operadores","title":"Operador de Kubernetes &amp; el Administrador del Ciclo de vida de Operadores","text":"<p>Desplegar Workloads para K8S con recursos como deplyments, replica sets, stateful sets, daemon sets, jobs y cron jobs. Cada uno de los recursos desplegados cumplen una funcion en particular, por ejemplo: los jobs ejecutan una tarea \u00fanica; los cron jobs ejecutan tareas peri\u00f3dicamente y los dem\u00e1s recursos crean Workloads persistentes. Los recursos como los deployment, los stateful sets o los daemon sets difieren en la forma en que se distribuye la carga de trabajo en un cl\u00faster.</p> <p>Aqui las cargar pueden estar representadas por los diferentes modelos que existen para implementar en un cl\u00faster, sin embargo grandes Workloads pueden requerir diferentes componentes como un servidor de DB un servidor de backend o frontend. Las Workloads necesitan tareas de mantenimiento que se pueden automatizar </p> <p>Un operador tiene recursos personalizados (CRs Custom Resources). Los CRs del operador contienen la informaci\u00f3n necesaria para imnplementar y gestionar las Workloads. Un operador observa el cl\u00faster buscando instancias de CRs y luego crea los Workloads necesarios. </p>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#implementacion-de-operadores","title":"Implementaci\u00f3n de operadores","text":"Tipo de Operador Descripci\u00f3n Operadores de Cl\u00faster Servicios de plataforma OCP (servidor Web y OAth) Operadores Complementarios (OLM - Operator Lifecycle Manager), Ayuda a instalar y actualizar los operadores en el cl\u00faster Otros operadores Desde los proveedores de SW dise\u00f1an y distrubuyen SW como manifiestos, chart de Helm y otro mecanismo de distribuci\u00f3n"},{"location":"01_redhat/07-DO280/07-DO280_C7/#operadores-de-cluster","title":"Operadores de Cl\u00faster","text":"<p>EL CVO (Cluster Version Operator) instala y actualiza los operadores del cl\u00faster como parte de los procesos de instalaci\u00f3n y actualizaci\u00f3n de OCP. El CVO provee informaci\u00f3n e inspecciona los recursos del cl\u00faster para examinar todo su estado. Esto incluye condiciones para identificar problemas </p> <pre><code>oc get clusteroperator\n</code></pre> <p>Tambien se p\u00faede ir a Administration &gt; Cluster Settings y luego en la pesta\u00f1a ClusterOperators</p>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#administrador-del-ciclo-de-vida-de-operadores-y-operatorhub","title":"Administrador del ciclo de vida de operadores y OperatorHub","text":"<p>Los admin pueden utilizar el OLM para instalar y actualizar operadores. Se usa la interfaz Web para interactuar con el OLM y proporciona CR para gestionar los operadores con el API de K8S. El OLM utiliza cat\u00e1logos para encontrar los que est\u00e1n disponibles para instalar que son im\u00e1genes de contenedores con info de los operadores y sus versiones disponibles. Los cat\u00e1logos disponibles son:</p> Cat\u00e1logo Descripci\u00f3n Red Hat Operadores soportados por Red Hat Certified Operadores soportados por SW de terceros Community Operadores sin soporte oficial Marketplace Operadores con opci\u00f3n de comprar en le Red Hat Marketplace <p>El OLM crea un recurso tipo PackageManifest para cada operador que est\u00e9 disponible que tambi\u00e9n se pueden ver por el entorno Web. </p> <p>La implementaci\u00f3n de operadores de compone de una definici\u00f3n de CR y Workloads de K8S. NOTA:  Un cl\u00faster contiene 2 Workloads por cada operador:  1. Operador de Workloads. Gestiona el OLM.  2. Los Workloads estan asociados con el CR y el gestor de im\u00e1genes. </p> <p>Se implementan operadores para automatizar cualquier tarea manual de K8S que se ajuste al patron del operador. Los SDK proporcionan componentes y marcos para el desarrollo de operadores.</p> <ul> <li>Operador SDK contiene herramientas para desarrollar operadores con el lenguaje de programaci\u00f3n Go y Ansible. Tambi\u00e9n contiene tools para empaquetar chats de Helm.</li> <li>Operador de Java SDK contiene herramientas para desarrollar operadores con el lenguaje Java. Tiene una extensi\u00f3n de Quarkus.</li> </ul>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#documentacion","title":"Documentaci\u00f3n","text":"<p>Operadores en la documentaci\u00f3n de OCP </p> <p>SDK de operadores </p> <p>SDK de operadores Java </p> <p>SDK de operadores Quarkus </p>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#instalacion-de-operadores-con-la-consola-web","title":"Instalaci\u00f3n de operadores con la consola web","text":"<p>La consola Web de OCP proporciona una interfaz gr\u00e1fica para el administrador de OLM. La p\u00e1gina de OperatorHub muestra los operadores disponibles y c\u00f3mo instalarlos, mientras los de la p\u00e1gina Installed Operators muestra los que ya est\u00e1n instalados.</p> <p></p> <p>En Operators &gt; OperatorHub mueestra los operadores disponibles, tiene filtros que ayudan a la b\u00fasqueda por categor\u00eda, source, proveedor o suscripci\u00f3n requerida. Se hace click en Install para iniciar el asistente de instalar el operador con las siguientes opciones</p> Opci\u00f3n Descripci\u00f3n Update channel Elegir el canal de actualizaci\u00f3n mas adecuado Installation mode Por defecto ( All namespaces on the cluster ), es el sugerido y mas adecuado para la mayor\u00eda de operadores. Los usuarios pueden crear recursos personalizados en sus namespaces. Los AdminCluster se ayudan para combinar aciones basadas en acceso por roles y pol\u00edticas de red Installed namespace OLM instala el workload del operador en un namespace, algunos se instalan por defecto en openshift-operator . Solo los AdminCluster requieren acceso al workload Update approval OLM actualiza los operadores automaticamente cuando hay nuevas versiones disponibles. Se pueden elegir las actualizaciones manuales. <p>Si un operador incluye monitoreo en su definici\u00f3, el asistente mostrar\u00e1 una opci\u00f3n para habilitar el monitoreo. Se debe revisar la documentaci\u00f3n del operador para conocer las opciones admitidas. Una ves configurada la instalaci\u00f3n, en la opci\u00f3n Install instalar\u00e1 los recursos del operador.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#visualizacion-de-operadores-instalados","title":"Visualizaci\u00f3n de operadores instalados","text":"<p>En View Operator muestra la lista de detalles de ese operador instalado. Tambi\u00e9n puede a traves de Operators &gt; Installed Operators. all\u00ed se muestra con la versi\u00f3n  y cada uno tiene un CSV el cual es usado por el OLM para instalar el operador. El CSV queda con la informaci\u00f3n actualizada una ves cambia el status.</p>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#solucion-de-problemass","title":"Soluci\u00f3n de problemass","text":"<p>Si el OLM no instala o actualiza los operadores, se utiliza el CSV para identificar la causa del error, por lo general son pueden ser problemas del operador en espec\u00edfico</p>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#instalacion-de-operadores-con-cli","title":"Instalaci\u00f3n de operadores con CLI","text":""},{"location":"01_redhat/07-DO280/07-DO280_C7/#pasos-para-instalacion","title":"Pasos para instalaci\u00f3n","text":"<ol> <li>Buscar el operador a instalar</li> <li>Revisar el ooperador y su documentaci\u00f3n (conocer pre-requisitos y opciones disponibles)</li> <li>Definir el canal de actualizaci\u00f3n a utilizar</li> <li>Definir el modo de instalaci\u00f3n. en la mayor\u00eda de operadores se disponen para todos los namaspace</li> <li>Definir el workload del operador en un namesapce existente o uno nuevo</li> <li>Crear grupo de operadores, depende del modo de instalaci\u00f3n, si aplica</li> <li>Crear el namaspace, si aplica</li> <li>Crear la suscripci\u00f3n del operador</li> <li>Revisar y validar la instalaci\u00f3n</li> </ol>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#recursos-del-operador","title":"Recursos del operador","text":"Tipos de recursos Descripci\u00f3n Catalog source Cada recurso de este tipo hace referencia a un repositorio. OLM cada cierto tiempo examina las fuentes y recupera la informaci\u00f3n de los operadores Package manifest OLM crea un manifiesto para c/operador y este contiene la info necesaria para instalar un operador (por ejemplo los canales) Operator group Definen como el OLM presenta los namespaces Subscription Los admincluster crear suscripciones para instalar operadores Operator OLM crea recursos para guardar informaci\u00f3n de los operadores Install plan OLM crea estos planes como parte del proceso de instalaci\u00f3n y updates, al momento de aprobaciones los admincluster lo aprueban Cluster service version (CSV) Cada versi\u00f3n de un operador le corresponde uno que contiene la informaci\u00f3n  que el OLM requiere para instalar el operador"},{"location":"01_redhat/07-DO280/07-DO280_C7/#examinando-los-operadores-disponibles","title":"Examinando los operadores disponibles","text":"<p>En el namespace openshift-marketplace contiene los origenes del cat\u00e1logos disponibles</p> <pre><code>oc get catalogsource -n openshift-marketplace\noc get packagemanifests\noc describe packagemanifest lvms-operator -n openshift-marketplace\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#instalacion","title":"Instalaci\u00f3n","text":"<p>Una ves revisado y examindo el manifiesto del paquete se revisa la documentaci\u00f3n del operador para validar los procedimientos para la instalaci\u00f3n de ese operador. Al decidir instalar el workload del operador en un namespace nuevo crear el namespace. Algunos operadores recomiendan instalar el operador en el namespace openshift-operators  o a veces requiere uno especpifico.</p> <p>Es necesario validar si se requiere crear operator group. Los operadores utilizan el grupo en este namesapce los cuales monitorean los recursos. El namspace openshift-operators contiene un operator group llamado global-operator. Si este operator group no es el indicado puede crearse uno nuevo.</p> <p>Ejemplo YAML que describe la estructura de un operator group:</p> <pre><code>apiVersion: operators.coreos.com/v1\nkind: OperatorGroup\nmetadata:\n  name: name\n  namespace: namespace\nspec:\n  targetNamespaces:\n  - namespace\n</code></pre> <p>Luego de crear el namaspace o el operator group necesarios, se crea la suscripci\u00f3n, como el siguiente ejemplo:</p> <pre><code>apiVersion: operators.coreos.com/v1alpha1\nkind: Subscription\nmetadata:\n  name: lvms-operator\n  namespace: openshift-storage\nspec:\n  channel: stable-4.14\n  name: lvms-operator\nsource: do280-catalog-cs\ninstallPlanApproval: Automatic\nsourceNamespace: openshift-marketplace\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#instalar-plans","title":"Instalar Plans","text":"<p>El OLM crea un Resource Plan para representar el proceso para instalar o actualizar un operador. Y en el campo status.components.refs se puede ver la referencia:</p> <pre><code>oc describe operator file-integrity-operator\nName: file-integrity-operator.openshift-file-integrity\nNamespace:\nLabels: &lt;none&gt;\nAnnotations: &lt;none&gt;\nAPI Version: operators.coreos.com/v1\nKind: Operator\n...output omitted...\nStatus:\n  Components:\n  ...output omitted...\n  Refs:\n    API Version: operators.coreos.com/v1alpha1\n    Kind: InstallPlan\n    Name: install-pmh78\n    Namespace: openshift-file-integrity\n    API Version: operators.coreos.com/v1alpha1\n    Conditions:\n      Last Transition Time: 2024-01-26T17:53:27Z\n      Message: all available catalogsources are healthy\n      Reason: AllCatalogSourcesHealthy\n      Status: False\n      Type: CatalogSourcesUnhealthy\n      Last Transition Time: 2024-01-26T17:53:49Z\n      Reason: RequiresApproval\n</code></pre> <p>Se utiliza oc patch para aprobar un plan de instalaci\u00f3n cuando est\u00e1 establecido en Manual</p> <pre><code>oc patch installplan install-pmh78 --type merge -p '{\"spec\":{\"approved\":true}}' -n openshift-file-integrity\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#uso-de-operadores","title":"Uso de operadores","text":"<p>Hay definiciones personalizadas de recursos de las cuales se pueden crear recursos personalizados Puede validar cadad una de las definiciones</p> <pre><code>oc get csv metallb-operator.v4.14.0-202401151553 -o jsonpath=\"{.spec.customresourcedefinitions.owned[*].name}{'\\n'}\"\n</code></pre>"},{"location":"01_redhat/07-DO280/07-DO280_C7/#troubleshooting-de-operadores","title":"Troubleshooting de operadores","text":"<p>Alguno operadores requieren pasos adicionales para installar o ser actualizados. Debe revisarse la documentaci\u00f3n del operador para comprobar todos los pasos necesarios.</p> <p>Es posible que el OLM instale un operador y puede suceder que no funcione correctamente. Los operadores tiene 2 workloads:  - WorkLoad del Operador (revisa los recursos custom)  - WorkLoads de instancias custom </p> <p><code>bash spec.install.spec.deployments</code> en su CSV contiene implementaciones que el OLM crea al instalar</p>"},{"location":"01_redhat/07-DO280/07-DO280_C8/","title":"Capituolo 8 - Seguridad de aplicaciones","text":""},{"location":"01_redhat/07-DO280/07-DO280_C8/#control-de-permisos-de-aplicaciones-con-restricciones-del-contexto-de-seguridad","title":"Control de permisos de aplicaciones con restricciones del contexto de seguridad","text":""},{"location":"01_redhat/07-DO280/07-DO280_C8/#permiso-de-acceso-de-aplicaciones-a-las-apis-de-kubernetes","title":"Permiso de acceso de aplicaciones a las APIs de Kubernetes","text":""},{"location":"01_redhat/07-DO280/07-DO280_C8/#mantenimiento-de-clusteres-y-nodos-con-tareas-cron-de-kubernetes","title":"Mantenimiento de cl\u00fasteres y nodos con tareas Cron de Kubernetes","text":""},{"location":"01_redhat/07-DO280/07-DO280_C9/","title":"Capitulo 9 - Actualizaciones OpenShift","text":""},{"location":"01_redhat/07-DO280/07-DO280_C9/#proceso-de-actualizacion-del-cluster","title":"Proceso de actualizaci\u00f3n del Cluster","text":""},{"location":"01_redhat/07-DO280/07-DO280_C9/#deteccion-del-uso-de-las-api-de-kubernetes-obsoletas","title":"Detecci\u00f3n del uso de las API de Kubernetes obsoletas","text":""},{"location":"01_redhat/07-DO280/07-DO280_C9/#actualice-los-operadores-con-el-olm","title":"Actualice los operadores con el OLM","text":""},{"location":"01_redhat/07-DO280/DO280_notes/","title":"Red Hat OpenShift Administration II: Configurando un cl\u00faster de PDN","text":""},{"location":"01_redhat/07-DO280/DO280_notes/#objetivos","title":"Objetivos","text":"<ul> <li>Configurar y administrar OCP cluster con seguridad y disponibilidad para todas las aplicaciones</li> <li>Configuraci\u00f3n de autenticaci\u00f3n</li> <li>Proteger la red con pol\u00edticas TLS</li> <li>Publicar aplicaciones con HTTPS y TLS</li> <li>Administrar cl\u00faster de OC, updates y updattes de operador de K8S</li> <li></li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/","title":"Capitulo 1, Descripci\u00f3n del proceso de Instalaci\u00f3n de OCP","text":""},{"location":"01_redhat/08-DO322/08-DO322_C1/#obejetivos","title":"Obejetivos:","text":"<ul> <li>Describir y comparar los m\u00e9todos de instalaci\u00f3n automatica full-stack.</li> <li>Identificar instalador OCP y sus archivos</li> <li>Describir las diferencias emtre un cl\u00faster autogestinado y los servicios hosted de OCP</li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#metodos-de-instalacion","title":"M\u00e9todos de instalacion","text":"<p>Debido a que el instalar OCP 3 era bastante complejo, se crea una mejora en la versi\u00f3n 4 la cual permite una instalaci\u00f3n desplegar un cl\u00faster con las opciones necesarias.</p> <p>Se denomina \"D\u00eda 2\" a una fase de la instalaci\u00f3n donde se puede personalizar y ampliar las funcionalidades del cluster, a parte de las siguientes ventajas:</p> <ul> <li>Automatizaci\u00f3n de la instalaci\u00f3n</li> <li>Menos errores humanos en la instalaci\u00f3n</li> <li>Se aplica buenas pr\u00e1cticas recomendadas para OCP 4</li> <li>Facilita la integraci\u00f3n m\u00e1s adelante de:</li> <li>OCP Assisted Installer</li> <li>RH Advanced Cluster Managment for K8S (ACM)</li> <li>Pipelines (CI/CD)</li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#achivos-de-configuracion-ignition","title":"Achivos de configuraci\u00f3n Ignition","text":"<p>Para instalar un cl\u00faster de OCP se debe utilizar el comando <code>openshift-install</code> al cual se conoce como el instalador de OCP. El instalador genera 3 archivos de configuraci\u00f3n de inicio o de startup (ignition):</p> <ul> <li>bootstrap</li> <li>Control plane nodes</li> <li>Compute nodes</li> </ul> <p>Ingnition es una tool de aprovisionamiento en el primer boot de sistemas RHCOS (Red Hat Enterprise Linux CoreOS) el cual usa un archivo .ign en formato JSON donde se declara el estado para el sistemas RHCOS y aplioca la configuraci\u00f3n requerida en el startup inicial. Este proceso consta de:</p> <ul> <li>Boot de Linux</li> <li>Ejecuci\u00f3n en nodos f\u00edsicos, nodos virtuales o instancias en Cloud</li> <li>Funciones unificadas con el kickstart y cloud-init del sistema RHCOS</li> <li>Se ejecuta en el paso initramfs del proceso de boot RHCOS</li> <li>Configura Storage, unidades systemd, certificados, usuarios</li> <li>Consume los archivos de configuraci\u00f3n  generados por el comando  y instalador y el MCO (Operador Machine Config)<ul> <li><code>openshift-install</code>  usa los archivos de configuraci\u00f3n del startup para configurar el estado de cada nodo</li> <li>el MCO aplica los cambios despues de la instalaci\u00f3n</li> </ul> </li> </ul> <p>El startup carga los archivos desde 3 posibles fuentes: disco local, metadas Cloud o por red con HTTP/HTTPS:</p>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#ejemplo-de-archivo-de-configuracion","title":"Ejemplo de archivo de configuraci\u00f3n:","text":"<p>Validar que en el SO donde se edita el archivo este instalada la librer\u00eda jq</p> <pre><code>{\n  \"ignition\": {\n    \"version\": \"3.1.0\"\n  },\n  \"passwd\": {\n    \"users\": [\n      {\n        \"name\": \"core\",\n        \"sshAuthorizedKeys\": [\n          \"ssh-rsa AAA...hlw== lab@utility.lab.example.com\\n\",\n          \"ssh-rsa AAA...3DR\\n\"\n        ]\n      }\n    ]\n  },\n  \"storage\": {\n    \"files\": [\n      {\n ...output omitted...\n       {\n         \"overwrite\": false,\n         \"path\": \"/etc/motd\",\n         \"user\": {\n           \"name\": \"root\"\n       },\n       \"append\": [\n         {\n            \"source\": \"data:text/plain;charset=utf-8;base64,VGh...lCg==\"\n         }\n       ],\n       \"mode\": 420\n    },\n ...output omitted...\n  \"systemd\": {\n    \"units\": [\n      {\n        \"contents\": \"[Unit]\\nDescription=Bootstrap a Kubernetes cluster\\nRequires=crio-configure.service\\nWants=kubelet.service\\nAfter=kubelet.service crio-configure.service\\nConditionPathExists=!/opt/openshift/.bootkube.done\\n\\n[Service]\\nWorkingDirectory=/opt/openshift\\nExecStart=/usr/local/bin/bootkube.sh\\n\\nRestart=on-failure\\nRestartSec=5s\\n\",\n        \"name\": \"bootkube.service\"\n      },\n ...output omitted...\n      }\n    ]\n  }\n}\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#solucionando-problemas","title":"Solucionando problemas:","text":"<ul> <li>Los datos de startup (ignition) est\u00e1n codificados en base64 para revisar se puede decodificar utilizando el comando <code>base64 -d</code></li> </ul> <pre><code>[user@demo ~]$ echo \"VGh...lCg==\" | base64 -d\nThis is the bootstrap node; it will be destroyed when the master is fully up.\nThe primary services are release-image.service followed by bootkube.service. To\n watch their status, run e.g.\n\n  journalctl -b -f -u release-image.service -u bootkube.service\n</code></pre> <ul> <li>Validar despues de boot de RHCOS la configuraci\u00f3n de startup</li> </ul> <pre><code>[root@bootstrap ~]$ cat /boot/ignition/config.ign\n{\"ignition\":{\"version\":\"3.1.0\"},\"passwd\":{\"users\":\n[{\"name\":\"core\",\"sshAuthorizedKeys\":[\"ssh-rsa...]}}\n</code></pre> <ul> <li>Validar registros de encendido</li> </ul> <pre><code>[root@bootstrap ~]# journalctl -t ignition\n</code></pre> <ul> <li>Se puede editar el archivo <code>install-config.yaml</code> para personalizar la isntalaci\u00f3n de OCP</li> <li>Se ejecuta <code>openshift-installer</code> para crear los manifiestos de K8S desde el archivo YAML</li> <li>Luego se ejecuta <code>openshift-installer</code> para crear los archivos startup (ignition) </li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#ejecucion-del-instalador","title":"Ejecuci\u00f3n del instalador","text":"<p>El proceso de instalaci\u00f3n se puede explicar en 11 pasos en secuencia:</p> <ul> <li>Paso 1 Ejecuci\u00f3n del instalador. Este solicita informaci\u00f3n sobre el cl\u00faster y luego crea el archivo de configuraci\u00f3n <code>install-config.yaml</code>.</li> <li>Paso 2 Con el yml de configuraci\u00f3n, el instalador de OCP crea los manifiestos de K8S con las instrucciones necesarias para compilar los recursos de la instalaci\u00f3n.</li> <li>Paso 3 Con el contenido de los manifiestos, el proceso de instalci\u00f3n de OCP crea los archivos de startup (ignition) poara el nodo bootstrap bootstart.ing, los nodos de control o master.ing y los nodos de procesamiento o workers.ing</li> </ul> <p> Proceso de instalaci\u00f3n - Etapa de configuraci\u00f3n archivos Ignition</p> <ul> <li>Paso 4 En el node bootstrap, realiza el boot y obtiene los recursos remotos del startup inicial. Aqui el API de K8S est\u00e1 ejecutandose en el nodo boot</li> <li>Paso 5 Los control node inician y obtienen sus recursos.</li> <li>Paso 6 el node bootstrap inicia e instala temporalmete el operador etcd</li> <li>Paso 7 el operator etcd ejecutandose en el node bootstrap escala el cluster a 3 instancias usando 2 control node</li> <li>Paso 8 en el temporal control bootstart programa el control plane de PDN. Transferencia de cl\u00faster etcd</li> <li>Paso 9 el temporal control plane termina e inicia el control plane de PDN. El API de K8S ejecutandose en el control plane de PDN</li> <li>Paso 10 Cuando la instalaci\u00f3n es Auto full-stack se apaga el node bootstrap ya que no es necesario</li> <li>Paso 11 el control plane PDN despliega los recursos remotos del cl\u00faster</li> </ul> <p>NOTAS </p> <ul> <li>Si se utiliza la isntalaci\u00f3n de infra preesxistente, la instalaci\u00f3n puede instalar los worker</li> <li>Red Hat solo soporta 3 control plane nodes</li> <li>Red Hat a pprobado m\u00e1ximo 2000 compute nodes</li> <li>Red Hat recomienda al menos 2 compute nodes para HA</li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#metodos-de-instalacion_1","title":"M\u00e9todos de instalaci\u00f3n","text":"M\u00e9todos de instalaci\u00f3n Descripci\u00f3n Crear  Red Config  Balanceador Config  DNS Deploy  HW o VM Install  SO Config  Startup  Ignition Soporte  SO  Control  plane Soporte  SO  worker Config  Storage  persistente Config  Storage  Provider Config  provisioning  node  auto-scaling Full-stack Automation Instalaci\u00f3n manual m\u00ednima  OCP Installer desliega el cl\u00faster en la infraestructura que el Installer aprovisiona y el cl\u00faster mantiene Instalador Instalador Instalador Instalador Instalador Instalador Instalador  RHCOS Instalador  RHCOS (1) Instalador (2) Instalador (2) Instalador Pre-existeing Infraestructure Instalacion flexible  Usan el Instaler para desplegar un cl\u00faster en la infraestructura que usted mantiene y prepara usuario usuario usuario usuario usuario instalador usuario:  RHCOS usuario:  RHCOS  RHEL 7 usuario usuario Solo  providers  OCP  Machine  API <p>NOTAS:</p> <ol> <li>Ambas m\u00e9todos soportan la adici\u00f3n de compute nodes por el usuario como parte del d\u00eda de operaci\u00f3n 2</li> <li>Las instalaci\u00f3n son en tipo bare-metal menos en Full-stack</li> <li>Diferencia entre UPI CI (Cloud Integration) y UPI BM (Bare Metal)</li> <li>CI el provider se integra con OCP</li> <li>BM si no hay soporte del proveedor no hay auto-scaling de nodos</li> </ol>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#requisitos-generales","title":"Requisitos Generales","text":"<ul> <li>Aprovisionar host bastion</li> <li>SSH key del bastion</li> <li>Download &amp; Install <code>openshift-install</code> en el bastion</li> <li>Download &amp; Install <code>oc</code> en bastion</li> <li>Obtener pull-secret del registry</li> <li>Acceso a NTP en los nodos del cl\u00faster</li> <li>Reglas de FW habilitadas para el cl\u00faster</li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#requisitos-de-full-stack","title":"Requisitos de Full-stack","text":"<ul> <li>Validar permisos de infarestructura y quotas</li> <li>En Cloud, account de Cloud con permisos y quotas necesarios</li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#requisitos-de-pre-existente","title":"Requisitos de Pre-existente","text":"<ul> <li>Configurar servicios de red</li> <li>Aprovisionar HW (sea VM o f\u00edsico) para los nodos del cl\u00faster</li> <li>Instalar RHCOS en los nodos del cl\u00faster</li> </ul> <p> Proceso de instalaci\u00f3n - Installaci\u00f3n Full-stack</p> <p> Proceso de instalaci\u00f3n - Installaci\u00f3n Pre-existente</p>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#validacion-de-servicios-de-dns-de-ocp","title":"Validaci\u00f3n de servicios de DNS de OCP","text":"<p>Con el m\u00e9todo de instalaci\u00f3n de infra pre-existente, se debe configurar el servicio DNS con registros de la zona directa DNS de la siguiente manera</p> <p><code>&lt;componente&gt;.&lt;cluster_name&gt;.&lt;base_domain</code> ejemplo: <code>componente.ocppdn4.eocampo.lab</code></p> <p>Es requerido tambi\u00e9n que la zona reversa con los registros o punteros PTR est\u00e9n diligenciados corretamente. Estos son los registros requeridos:</p> Componente Registro Descripci\u00f3n K8S API api.ocppdn4.eocampo.lab (A/AAAA o CNAME y PTR)  Identifica balanceador de carga de API para los control plane K8S API api-int.ocppdn4.eocampo.lab (A/AAAA o CNAME y PTR)  Identifica balanceador de carga de API para los control plane Routes *.apps.ocppdn4.eocampo.lab (A/AAAA o CNAME y PTR)  Identifica balanceador de carga del Ingress  que apunta a los control plane Cl\u00faster Nodes hostsocp01.ocppdn4.eocampo.lab (A/AAAA o CNAME y PTR)  Identifica cada host del cl\u00faster <p>Las rutas utilizadas para almacenar la configuraci\u00f3n de instalaci\u00f3n son:</p> <pre><code>cat /etc/named.conf\n...output omitted...\nzone \"example.com\" {\n    type master;\n    file \"example.com.db\";\n    allow-update { none; };\n};\n...output omitted...\n\ncat /var/named/example.com.db\n$TTL 1D\n@ IN SOA dns.ocp4.example.com. root.example.com. (\n           2019022400 ; serial\n           3h ; refresh\n           15 ; retry\n           1w ; expire\n           3h ; minimum\n         )\n         IN NS dns.ocp4.example.com.\ndns.ocp4 IN A 192.168.50.254\napi.ocp4 IN A 192.168.50.254\napi-int.ocp4 IN A 192.168.50.254\n*.apps.ocp4 IN A 192.168.50.254\nbootstrap.ocp4 IN A 192.168.50.9\nmaster01.ocp4 IN A 192.168.50.10\nmaster02.ocp4 IN A 192.168.50.11\nmaster03.ocp4 IN A 192.168.50.12\nworker01.ocp4 IN A 192.168.50.13\nworker02.ocp4 IN A 192.168.50.14\n\ncat /var/named/example.com.reverse.db\n$TTL 1D\n@ IN SOA dns.ocp4.example.com. root.example.com. (\n           2019022400 ; serial\n           3h ; refresh\n           15 ; retry\n           1w ; expire\n           3h ; minimum\n         )\n         IN NS dns.ocp4.example.com.\n254 IN PTR api.ocp4.example.com.\n254 IN PTR api-int.ocp4.example.com.\n9 IN PTR bootstrap.ocp4.example.com.\n10 IN PTR master01.ocp4.example.com.\n11 IN PTR master02.ocp4.example.com.\n12 IN PTR master03.ocp4.example.com.\n13 IN PTR worker01.ocp4.example.com.\n14 IN PTR worker02.ocp4.example.com.\n</code></pre> <p>Se utiliza el comando <code>dig</code> para validar la configuraci\u00f3n de DNS antes de proceder con la instalaci\u00f3n:</p> <pre><code>dig @dns.ocp4.example.com api.ocp4.example.com\n...output omitted...\n;; ANSWER SECTION:\napi.ocp4.example.com. 86400 IN A 192.168.50.254\n...output omitted...\n\ndig @dns.ocp4.example.com api-int.ocp4.example.com\n...output omitted...\n;; ANSWER SECTION:\napi-int.ocp4.example.com. 86400 IN A 192.168.50.254\n...output omitted...\n\ndig @dns.ocp4.example.com -x 192.168.50.254\n...output omitted...\n;; ANSWER SECTION:\n254.50.168.192.in-addr.arpa. 86400 IN PTR api.ocp4.example.com.\n254.50.168.192.in-addr.arpa. 86400 IN PTR api-int.ocp4.example.com.\n...output omitted...\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#validacion-de-servicios-de-firewall","title":"Validaci\u00f3n de servicios de Firewall","text":"<p>Los puertos de red debes estar abiertos antes de ejecutar la instalaci\u00f3n y debe garantizarse la conectividad entre todos los nodos del cl\u00faster y una correcta resoluci\u00f3n de nombres entre todos.</p> <p>De todos los nodos a todos los nodos:</p> Protocolo Puerto Descripci\u00f3n ICMP N/D Pruebas de Ping TCP 9000-9999 Servicios de Host TCP 10250-10259 Los puertos de reserva K8S TCP 10256 openshift-sdn UDP 4789 VXLAN y Geneve UDP 6081 VXLAN y Geneve UDP 9000-9999 Servicios de Host TCP/UDP 30000-32767 Node Ports K8S <p>De todos los nodos a todos los control plane:</p> Protocolo Puerto Descripci\u00f3n TCP 2379-2380 etcd server, peer, y puertos de m\u00e9trica TCP 6443 API de K8S <p>Del Balanceador de carga de API:</p> Protocolo Back-end  nodes Acceso  Interno Acceso  Externo Descripci\u00f3n 6443 Bootstrap temp &amp; nodos control plane SI SI K8S APi Server 22623 Bootstrap temp &amp; nodos control plane SI NO Maquina Config server <p>Del Balanceador de carga del ingress:</p> Protocolo Back-end  nodes Acceso  Interno Acceso  Externo Descripci\u00f3n 443 Nodos del cl\u00faster donde se ejecuta el router ingress de los pods SI SI Tr\u00e1fico  HTTPS 80 Nodos del cl\u00faster donde se ejecuta el router ingress de los pods SI SI Tr\u00e1fico  HTTP"},{"location":"01_redhat/08-DO322/08-DO322_C1/#modos-de-instalacion-ocp","title":"Modos de Instalaci\u00f3n OCP","text":"Conectado Desconectado Los nodos del clpuster tienen acceso a internet para descargar las im\u00e1genes desde quay.io y a registry.redhat.io. esta modo es soportado cuando se usa la instalaci\u00f3n autom\u00e1tica full-stack o una instalaci\u00f3n pre-existente Este tipo de instalaci\u00f3n es cuando no se tiene acceso a internet. el instaldor de OCP utiliza un registry local para realiezar el pull de im\u00e1genes <p>La instalaci\u00f3n de ambientes desconectados tienen algunas restricciones ue deben tenerse en cuenta:</p> <ul> <li>Copia de las im\u00e1genes con especificaci\u00f3n API <code>schema2</code> en el registry local.</li> <li>Acceso a internet para descargar las im\u00e1gnes desde los registries haceia el registry lacal</li> <li>Copia de las im\u00e1genes requeridas para la instalaci\u00f3n en el registry local</li> </ul> <p>Se debe obtener aparte de todas las imagenes necesarias para instalar en el registry local, la data de la versi\u00f3n de OCP: <code>imageContentSource</code>. Se debe copiar todo el siguiente contenido en el registry local:</p> <ul> <li>Repositorio de im\u00e1genes de OCP (provee im\u00e1genes que se usan durante la instalaci\u00f3n o el upgrade)</li> <li>Provee las imagenes durante el proceso de instalaci\u00f3n o upgrade de OCP</li> <li>Tiene ejemplos de OCP Container Platform</li> </ul> <p>La mayor\u00eda de im\u00e1genes de importancia del namespace <code>openshift</code> usa imagenes locales de registry.redhat.io de Red Hat, la principal r\u00e9lica de estas im\u00e1genes</p> <ul> <li>Or\u00edgenes remotos de OperatorHub</li> <li>Or\u00edgenes remotos de Operator Hub</li> </ul> <p>En un cl\u00faster desconectado el OLM no tiene acceso al los origenes del proveedor Operator Hub en quay.io por ello se debe hacer descarga localmente</p>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#personalizando-las-instalaciones-personalizadas","title":"Personalizando las instalaciones personalizadas","text":"<p>Despues de descargar localmente las im\u00e1genes al registry local, se inicia el proceso de instalaci\u00f3n. Se puede modificar el archivos <code>install-config.yaml</code> para personalizar el proceso de instalaci\u00f3n</p> <p>Ejemplo YAML de instalaci\u00f3n conectada </p> <pre><code>cat ${HOME}/ocp4-cluster/install-config.yaml\n\napiVersion: v1\nbaseDomain: example.com\n#proxy:\n# httpProxy: http://&lt;username&gt;:&lt;pswd&gt;@&lt;ip&gt;:&lt;port&gt;\n# httpsProxy: http://&lt;username&gt;:&lt;pswd&gt;@&lt;ip&gt;:&lt;port&gt;\n# noProxy: example.com\ncompute:\n- hyperthreading: Enabled\n  name: worker\n  replicas: 2\ncontrolPlane:\n  hyperthreading: Enabled\n  name: master\n  replicas: 3\nmetadata:\n  name: ocp4\nnetworking:\n  clusterNetwork:\n  - cidr: 10.128.0.0/14\n    hostPrefix: 23\n  networkType: OpenShiftSDN\n  serviceNetwork:\n  - 172.30.0.0/16\nplatform:\n  none: {}\nfips: false\npullSecret: |\n  {\"auths\":...output omitted...}\nsshKey: |\n  ssh-rsa AA...output omitted...\n</code></pre> <p>Ejemplo de YAML instalaci\u00f3n desconectada</p> <pre><code>cat ${HOME}/ocp4-cluster/install-config.yaml\napiVersion: v1\nbaseDomain: example.com\ncompute:\n- hyperthreading: Enabled\n  name: worker\n  replicas: 2\ncontrolPlane:\n  hyperthreading: Enabled\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C1/#urls-de-documentacion","title":"URL's de documentaci\u00f3n","text":"<ul> <li>Config Files starup Ignition </li> </ul>"},{"location":"01_redhat/08-DO322/08-DO322_C2/","title":"Capitulo 2, Ejecutando la instalaci\u00f3n de OCP","text":""},{"location":"01_redhat/08-DO322/08-DO322_C2/#binario-de-instalacion","title":"Binario de instalaci\u00f3n","text":"<p>Independiente del m\u00e9todo, se debe utilizar el binario de la instalaci\u00f3n <code>openshift-instal</code> para iniciar el proceso.</p> <p>Los siguientes pasos son el resumen del proceso de instlaci\u00f3n:</p> <ol> <li>Tener todos los prerequisitos de instalaci\u00f3n</li> <li>Crear el directorio de instalaci\u00f3n</li> <li>Crear el archivo de instalaci\u00f3n <code>install-config.yaml</code></li> <li>Crear los manifiestos de K8S</li> <li>Crear los archivos de confoguraci\u00f3n ignition o startup</li> <li>Desplegar el cl\u00faster de OCP</li> <li>Validar el estado de salubridad del cl\u00faster de OCP</li> </ol>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#crear-el-directorio-de-instalacion","title":"Crear el directorio de instalaci\u00f3n","text":"<pre><code>INSTALLDIR=ocp4-cluster\nmkdir ${HOME}/$INSTALLDIR\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#crear-el-archivo-de-instalacion-install-configyaml","title":"Crear el archivo de instalaci\u00f3n <code>install-config.yaml</code>","text":""},{"location":"01_redhat/08-DO322/08-DO322_C2/#ejemplo-en-aws","title":"Ejemplo en AWS","text":"<pre><code>openshift-install create install-config --dir=${HOME}/$INSTALLDIR\n? SSH Public Key /home/user/.ssh/ocp4-cluster.pub\n? Platform aws\nINFO Credentials loaded from the \"default\" profile in file \"/home/user/.aws/\ncredentials\"\n? Region us-east-2\n? Base Domain mydomain.com\n? Cluster Name ocp4\n? Pull Secret [? for help] +++++\nINFO Install-Config created in: /home/user/ocp4-cluster\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#ejemplo-instalacion-onpremises","title":"Ejemplo instalaci\u00f3n onpremises","text":"<pre><code>cat ${HOME}/$INSTALLDIR/install-config.yaml\n\napiVersion: v1\nbaseDomain: mydomain.com\ncompute:\n- architecture: amd64\n  hyperthreading: Enabled\n  name: worker\n  platform: {}\n  replicas: 3\ncontrolPlane:\n  architecture: amd64\n  hyperthreading: Enabled\n  name: master\n  platform: {}\n  replicas: 3\nmetadata:\n  creationTimestamp: null\n  name: ocp4\nnetworking:\nclusterNetwork:\n  - cidr: 10.128.0.0/14\n    hostPrefix: 23\n  machineNetwork:\n  - cidr: 10.0.0.0/16\n  networkType: OpenShiftSDN\n  serviceNetwork:\n  - 172.30.0.0/16\nplatform:\n  aws:\n    region: us-east-2\npublish: External\npullSecret: |\n  {\"auths\":...}\nsshKey: |\n  ssh-rsa AA...\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#crear-los-manifiestos-de-k8s","title":"Crear los manifiestos de K8S","text":"<pre><code>openshift-install create manifests --dir=${HOME}/$INSTALLDIR\nfind ${HOME}/$INSTALLDIR/manifests\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#ejemplo-manifiesto-agregando-loglevel-7","title":"Ejemplo manifiesto agregando loglevel 7","text":"<pre><code>cat cat &lt;&lt; EOF &gt; ${HOME}/$INSTALLDIR/manifests/openshift/99-openshift-machineconfig-master-kargs.yaml\napiVersion: machineconfiguration.openshift.io/v1\nkind: MachineConfig\nmetadata:\n  labels:\n    machineconfiguration.openshift.io/role: master\n  name: 99-openshift-machineconfig-master-kargs\nspec:\n  kernelArguments:\n    - 'loglevel=7'\nEOF\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#crear-los-archivos-de-confoguracion-ignition-o-startup","title":"Crear los archivos de confoguraci\u00f3n ignition o startup","text":"<pre><code>openshift-install create ignition-configs  --dir=${HOME}/$INSTALLDIR\nfind ${HOME}/$INSTALLDIR -name '*.ign' | xargs ls -lrt\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#desplegar-el-cluster-de-ocp","title":"Desplegar el cl\u00faster de OCP","text":"<pre><code>openshift-install create cluster  --dir=${HOME}/$INSTALLDIR --log-level=debug\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#desplegar-lo-faltante-en-unq-instalacion-pre-existente","title":"Desplegar lo faltante en unq instalaci\u00f3n pre-existente","text":"<p>No se puede ejecutar el <code>openshift-install create cluster</code> porque este ya existe, lo que se hace es la ejecuci\u00f3n del bootstrap y completar la instalaci\u00f3n</p> <pre><code>openshift-install wait-for bootstrap-complete --dir=${HOME}/$INSTALLDIR --log-level=debug\nopenshift-install wait-for install-complete  --dir=${HOME}/$INSTALLDIR --log-level=debug\n</code></pre>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#monitoreando-la-instalacion","title":"Monitoreando la instalaci\u00f3n","text":"<p>Primero se debe configurar el archivo KUBECONFIG para que apunte al ambiente y para empezar a usar el comando <code>oc</code> con cualquiera de os 2 m\u00e9todos:</p> <ul> <li><code>kubeconfig</code></li> </ul> <pre><code>export KUBECONFIG=${HOME}/ocp4-cluster/auth/kubeconfig\n</code></pre> <ul> <li>Usando <code>kubeadmin</code></li> </ul> <p> Tener presente respaldae el archivo del <code>kubeadmin</code> es un lugar seguro.</p> <p>Una ves ingresado al cluster, podemos validar inicialmente algunos estados:</p> <pre><code>watch 'oc get clusterversion; oc get clusteroperators;  oc get pods --all-namespaces | grep -v -E \"Running|Completed\"; oc get nodes'\n</code></pre> <p>El comando <code>watch</code> puede visualizar en tiempo real  como el CVO instala los operadores. Con <code>oc get events -A -w</code> se puede ver en tiempo real los mensajes de eventos de OCP, para ver tambi\u00e9n los proceso de isntalaci\u00f3n en background</p>"},{"location":"01_redhat/08-DO322/08-DO322_C2/#troubleshooting-de-la-instalacion-de-ocp","title":"Troubleshooting de la instalaci\u00f3n de OCP","text":"<p>Existen 3 estapas del proceso de despliegue de un cl\u00faster de OCP:</p> Stage Descripci\u00f3n Bootstrap (Bootkube) Bootstrap (Temporary Control Plane) Production Control Plane"},{"location":"02_finops/01_finops_practitioner/","title":"FinOps Certified Practitioner Introduction","text":""},{"location":"02_finops/01_finops_practitioner/#getting-started","title":"Getting Started","text":""},{"location":"02_finops/01_finops_practitioner/#introduction-to-finops","title":"Introduction to FinOps","text":"<p>FinOps is an evolving cloud financial management discipline and cultural practice that enables organizations to get maximum business value by helping engineering, finance, technology and business teams to collaborate on data-driven spending decisions.</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-finops-book","title":"Cloud FinOps Book","text":"<p>Anyone working in engineering, finance, procurement, product ownership, or leadership in a company running\u2014or aspiring to run\u2014in the public cloud will benefit from this book. As an organization understands the personas in FinOps, it can map them to relevant teams across the business. </p> <p>This book is not required to pass the test or complete the course, however, it is a good companion reference and includes additional stories and context.</p>"},{"location":"02_finops/01_finops_practitioner/#finops-terminology","title":"FinOps Terminology","text":"<p>There are lots of terms and tools specific to FinOps. Utilize the terminology resources below throughout the course to support your learning.</p> <ul> <li>FinOps Terminology: A list of terminology and examples for Cloud Cost Management, Public Cloud, Software Development &amp; Operations, and Finance &amp; Accounting categories. FinOps Terms</li> <li>Multi-Cloud Tools &amp; Terminology: A matrix of tools available to help FinOps practitioners learn and practice efficient utilization of cloud resources as well as terminology and additional resources. Multi-Cloud Terms</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#organization-information","title":"Organization Information","text":"<p>Gather information about your organization's cloud use and cloud challenges to use throughout this course. Below are some key questions to help you get started. </p> <ul> <li>What are the organization\u2019s goals in using the cloud?</li> <li>What have been the challenges in accomplishing these goals?</li> <li>What accomplishments can be attributed to the cloud that could not have happened otherwise?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#be-the-finops-lead","title":"Be the FinOps Lead","text":"<p>Throughout this course, we encourage you to think of yourself in the position of a FinOps lead at your organization. This is the person who will be leading the company's cloud journey. At the end of each module, check-in to see how your knowledge is evolving and how you will address each topic at your organization. </p>"},{"location":"02_finops/01_finops_practitioner/#finops-foundation-overview","title":"FinOps Foundation Overview","text":""},{"location":"02_finops/01_finops_practitioner/#about-the-finops-foundation","title":"About the FinOps Foundation","text":"<p>The FinOps Foundation is a program of the The Linux Foundation dedicated to advancing people who practice the discipline of cloud financial management through best practices, education, and standards. The FinOps Foundation includes 5300+ individual members, representing more than 1500 companies. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#mission-of-the-finops-foundation","title":"Mission of the FinOps Foundation","text":"<p>To advance every individual who manages the value of cloud wherever they are.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#get-involved","title":"Get Involved","text":"<p>If you are new to FinOps, there are lots of ways to get involved! </p> <ul> <li>Join our Slack and ask your question on #ask-a-question</li> <li>Learn from others via real world member stories and the FinOps Podcast</li> <li>Find help adopting FinOps</li> <li>Gain insights on encouraging engineers to take action</li> <li>Learn about vendors in our community</li> <li>Still need help finding what you need? Let us know at hello@finops.org</li> <li>Questions about training? Contact us at training@finops.org# Cloud Changes IT</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#devops-cloud","title":"DevOps &amp; Cloud","text":""},{"location":"02_finops/01_finops_practitioner/#devops-cloud-have-broken-traditional-procurement","title":"DevOps &amp; Cloud have broken traditional procurement","text":"<p>DevOps allows companies to accelerate technology delivery to meet customer demand using cloud. This shift has put purchasing power in the hands of developers in ways that have broken traditional procurement processes. DevOps and cloud have forced the removal of constraints that has led to the need for a new operating model. This new model allows for collaborative decision making and gives companies the ability to continue to maximize the value of IT investment. This is the premise that led to the development of FinOps. </p>"},{"location":"02_finops/01_finops_practitioner/#devops-cloud-allow-for-all-costs-to-be-attributed-to-owners","title":"DevOps &amp; Cloud allow for all costs to be attributed to owners","text":"<p>The cost of goods sold for our IT-enabled products and the cost per user of support systems, have always relied upon data centers and infrastructure whose cost is unchangeable. Product owners now have the ability to consume IT services in the exact mix and at the exact times when needed. Product owners can also build in such a way that all of the costs can be examined and taken into account in the pricing, support, and agile development processes. The cloud gives us the ability to develop applications on architectures that scale appropriately to demand, matching IT supply and demand more effectively than ever possible in the data center. All the while, improving our ability to buy incremental small systems and scale to massive heights.</p>"},{"location":"02_finops/01_finops_practitioner/#devops-cloud-offer-unprecedented-opportunities","title":"DevOps &amp; Cloud offer unprecedented opportunities","text":"<p>Procurement and finance now have the ability to see spending in real-time as well as granularity and attribution. Technology leaders who previously needed to face product demand, changes in technology trends, and data center infrastructure challenges, now have the ability to build incrementally. DevOps engineers, once constrained to whatever the infrastructure team had previously purchased within the confines of the data center, are now free to consider using a wide \u2013 and ever growing \u2013 selection of technologies to solve a range of customer needs. And, more importantly to the organization, DevOps engineers have the right to buy and use only what they need at any given moment.</p> <p>How do we develop the ability to tackle these challenges and take advantage of these new opportunities?</p>"},{"location":"02_finops/01_finops_practitioner/#finops","title":"FinOps","text":""},{"location":"02_finops/01_finops_practitioner/#the-new-operating-model-for-the-cloud","title":"The New Operating Model for the Cloud","text":"<p>For many organizations, FinOps is the new operating model for the cloud. FinOps is the practice of bringing technology, business, and finance together to master the unit economics of cloud for competitive advantage. It brings financial accountability to the variable spend model of cloud.</p> <p>Cloud FinOps is an evolving cloud financial management discipline and cultural practice.</p> <ul> <li> <p>FinOps enables organizations to get maximum business value......by helping engineering, finance, and business teams...to collaborate on data-driven spending decisions.</p> <p></p> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#creating-a-culture-of-accountability","title":"Creating a Culture of Accountability","text":"<p>FinOps creates a culture of accountability by supporting product, finance, and business teams to collaborate and make real-time decisions related to tradeoffs between cost, speed, and quality. This drives decisions that increase business value to enhance efficiency and better align costs to business needs as well as improving forecasting of cloud costs.</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-usage-goals","title":"Cloud Usage &amp; Goals","text":"<p>Before moving on... </p> <ul> <li>Think about why your organization is using or moving to the cloud</li> <li>Consider what you are trying to achieve by using the cloud</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#the-challenge-of-cloud","title":"The Challenge of Cloud**","text":""},{"location":"02_finops/01_finops_practitioner/#traditional-technology-consumption","title":"Traditional Technology Consumption","text":"<p>Traditionally, companies had a platform team who dreamed of getting some hardware to build their application so they went to procurement. Procurement reviewed their complex business case and if sufficient, gave them access to the money.</p>"},{"location":"02_finops/01_finops_practitioner/#in-this-model","title":"In this model...","text":"<ul> <li>DevOps, or developers, are the requesters</li> <li>Finance are the gatekeepers, the approvers</li> <li>Spend is predictable and static, with known costs</li> <li>There are long procurement cycles</li> <li>The infrastructure purchased is usually intentionally oversized and not certain to be correct</li> <li>There is high risk of some level of failure at a high cost</li> </ul> <p>To complicate things further, in a DevOps world, there are many teams working at once and technology requests are becoming more complex. Now, introduce the world of cloud and automation where procurement can't keep up or is not needed to make purchases. This leads to companies where engineers with automation go directly to the money. Procurement and finance are losing control of the investment and the ability to track it over time. This means they cannot do their fiduciary duty to the company to control and correctly report on costs!</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-changes-the-dynamic","title":"Cloud changes the dynamic...","text":"<ul> <li>Engineers now have the power to spend company money with code</li> <li>Finance has less visibility into spend until after the fact and cannot do their fiduciary duty to the company</li> <li>Spend is dynamic and changes daily</li> <li>There is agile experimentation and some waste</li> <li>Overall, there is a lack of communication</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#state-of-finops","title":"State of FinOps","text":"<p>Below are the biggest unresolved pain points for organizations, gathered from 1,056 responses on the 2022 State of FinOps Survey.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#state-of-finops-survey","title":"State of FinOps Survey","text":"<p>The State of FinOps data can be found at data.FinOps.org. This data will be referenced throughout the course to illustrate points and to provide a way to dig into practitioner content. We see from our 2022 survey that several of the challenges reported as difficult for FinOps practitioners are these we've been discussing: organizational adoption, aligning teams, accounting for cloud costs. We'll talk about the other challenges later in the course.# What is FinOps</p> <p>At its core, FinOps is a cultural practice. It\u2019s the way for teams to manage their cloud costs, where everyone takes ownership of their cloud usage supported by a central best-practices group. Cross-functional teams in Engineering, Finance, Product, etc. work together to enable faster product delivery, while at the same time gaining more financial control and predictability.</p> <p>80% of organizations will overshoot IaaS budgets due to a lack of cloud cost optimization governance and misguided upfront spend commitments. DevOps.com</p> <p>You are not alone.</p> <p>Budget overruns often stem from a lack of cost governance and not understanding what the organization is committing to spend, how it is committing to spending, and what it is spending that money on.  FinOps helps address this reality. </p>"},{"location":"02_finops/01_finops_practitioner/#lets-recap","title":"Let's Recap","text":"<p>Cloud FinOps is an evolving cloud financial management discipline and cultural practice.</p> <p></p> <p>FinOps enables organizations to get maximum business value...by helping engineering, finance and business teams...to collaborate on data-driven spending decisions.</p>"},{"location":"02_finops/01_finops_practitioner/#the-new-cloud-reality-for-it","title":"The New Cloud Reality for IT","text":"<ul> <li> <p>Decentralized: Buying centers are siloed and more decentralized than before. They can no longer be run through centralized IT or procurement.</p> </li> <li> <p>Material: There is a 24% year-over-year increase in public cloud spend. These cloud costs are now material and are a large percentage of the company's spend. They are becoming much more visible to top company executives, and much more important to be able to deconstruct for CIOs and CIO finance teams.</p> </li> <li> <p>Variable: Spending is variable. Spending is up and down and will move in unpredictable ways or ways that look unpredictable to finance teams that are not used to looking at IT spend in public cloud. Spending can be runaway when developers have the ability to launch services without regard to their costs. There is a large possibility for dramatic overspending. </p> </li> <li> <p>Inefficiency: There is a lot of inefficiency that will need to be drawn out from spending. Macroeconomic instability is going to push us more toward efficiency. Efficiency steps in the cloud pay off in dollars not spent. Whereas efficiency in the data center world, where costs were fixed and capped were not as effective. Inefficiency is a big indicator in the new cloud economy.</p> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#finops-changing-the-model","title":"FinOps: Changing the Model","text":"<p>FinOps allows us to bring DevOps and IT Finance back into alignment, allowing for visibility into spending and collaborative control.</p>"},{"location":"02_finops/01_finops_practitioner/#in-this-model_1","title":"In this model...","text":"<ul> <li>Engineering and finance can work together in what has been called \u201cthe FinOps Hug\u201d</li> <li>The company can leverage the \"Infrastructure as Code\" instant procurement the cloud offers</li> <li>Experimentation is enabled, can be managed, and is more predictable (which is good for the business)</li> <li>Lower risk and cost of failing to buy exactly the right hardware upfront and can change it as needed</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#adopting-finops","title":"Adopting FinOps","text":""},{"location":"02_finops/01_finops_practitioner/#where-to-begin","title":"Where to Begin","text":"<p>If you haven\u2019t started to do FinOps or have started to use cloud but not formed a team yet, then you may need to begin by building the awareness and support for a FinOps practice. The FinOps Foundation has resources available to help you get started and begin to use the FinOps framework effectively.</p> <p>Adopting FinOps</p>"},{"location":"02_finops/01_finops_practitioner/#impacts-of-cloud-adoption","title":"Impacts of Cloud Adoption","text":"<p>Once an organization has recognized the need to use cloud to effectively build and manage IT value, there will be next steps to take. FinOps teams can have the biggest impact by enabling the whole organization to understand and gain visibility into the impacts of cloud.</p> <p> </p> <ul> <li>Technical aspects of cloud adoption will be managed by the engineering teams.</li> <li>Governance aspects of cloud adoption will be managed by architecture, security, platform, and infrastructure teams.</li> <li>Financial Changes to the procurement and accounting processes related to the purchase of IT services will change as we move from an ownership-based IT model to the consumption-based IT model in cloud.</li> <li>Cultural changes accompanying the adoption of cloud are often left untouched for longer periods of time as other tactical issues are addressed. These will be the areas where the FinOps team can best help the organization to adapt.</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#models-of-adoption","title":"Models of Adoption","text":"<p>Select each information icon in the graphic below to learn more.</p> <p> </p>"},{"location":"02_finops/01_finops_practitioner/#resources","title":"Resources","text":""},{"location":"02_finops/01_finops_practitioner/#adopting-finops-getting-started","title":"Adopting FinOps - Getting Started","text":"<p>A starter guide to help you build a presentation to inform other teams, teammates, and stakeholders about the benefits of building a FinOps practice. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#adopting-finops-pitfalls-to-avoid","title":"Adopting FinOps - Pitfalls to Avoid","text":"<p>This article is about what to invest and what to avoid, together with some stories that can help inspire the FinOps journey you are about to make. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#finops-framework-principles","title":"FinOps Framework &amp; Principles","text":""},{"location":"02_finops/01_finops_practitioner/#the-finops-framework","title":"The FinOps Framework","text":""},{"location":"02_finops/01_finops_practitioner/#finops-framework","title":"FinOps Framework","text":"<p>The FinOps Framework describes the principles that drive FinOps practices, the personas that FinOps supports as stakeholders, the best practices and process models used to accomplish this, and the domains of activity FinOps practitioners will perform as they build a FinOps team and drive the cultural change that FinOps brings into their organizations.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#finops-maturity","title":"FinOps Maturity","text":"<p>A \u201cCrawl, Walk, Run\u201d approach to performing FinOps enables organizations to start small and grow in scale, scope, and complexity. Taking quick action at a small scale and limited scope allows FinOps teams to assess the outcomes of their actions and gain insights into the value of taking further action in a larger, faster, or more granular ways.</p> <p>Start at a Crawl and mature the capabilities that provide your company strategic value. There is no need to try to do all capabilities at once.</p> <p>There is no value judgement here. Every organization does not need to be at the same level and each capability can be at a different level of maturity as well.</p>"},{"location":"02_finops/01_finops_practitioner/#examples","title":"Examples","text":"<ul> <li> <p>Gall\u2019s law tells us that complex processes that work have evolved from simple processes that work; they are not designed from scratch. Do not attempt to build full solutions, rather, build only the amount of solution that you need in any given case. For example, you should build the capability to Run when it provides business value. If you are in the Run phase and it is not adding value, you may be wasting a most precious resource: time. </p> </li> <li> <p>In another example, you may be in the Run phase at buying commitment based discounts because you have a heavily VM based architecture that is very broad. Or, you may use a heavily serverless architecture that does not require a large amount of savings plans or RIs to be rate-optimized and you never need to develop this capability beyond the Crawl phase. None of these use cases is \u201cbetter,\u201d they are all well suited to their situation. </p> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#finops-lifecycle","title":"FinOps Lifecycle","text":"<p>Like Agile, DevOps, or other modern methodologies, we practice FinOps in an iterative loop, making small incremental changes to our cloud infrastructure as we advance. We describe this approach using the FinOps lifecycle which is comprised of three phases.</p> <p></p> <p>Strive for a regular, cyclical process to your analysis/work as you conduct the FinOps function.</p>"},{"location":"02_finops/01_finops_practitioner/#phases-in-practice","title":"Phases In Practice","text":"<ul> <li> <p>At first, it may take a while to perform the work in each phase and you may be more explicit about moving from one to another. However, over time, this cycle of looking at usage, looking for opportunities to improve, and then taking an incremental action step will become more fluid and natural. </p> </li> <li> <p>The ultimate goal is to exercise the FinOps lifecycle as frequently and quickly as possible, and to include as much automation to help that process as possible. This is how we take incremental steps toward building the culture of accountability and the governance to support our FinOps function.</p> </li> <li> <p>We use this looping lifecycle with FinOps, in conjunction with Crawl Walk Run, to get more mature every time we go through the loop. </p> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#important-concepts","title":"Important Concepts","text":""},{"location":"02_finops/01_finops_practitioner/#prioritization-triage","title":"Prioritization &amp; Triage","text":"<p>When conducting our work in FinOps, because the work is cyclical and iterative, we want to establish a triage or prioritization model early on to drive our work. A FinOps team should often consider the question \u201cWhat will I work on next?\u201d The answer to that question will often be \u201cThe thing that gives us the biggest business value boost.\u201d</p>"},{"location":"02_finops/01_finops_practitioner/#how-do-you-identify-or-document-the-value-of-any-given-step","title":"How do you identify or document the value of any given step?","text":"<p>For now, consider that we want to use the Pareto Principle, or 80/20 rule, to focus on the costs or problems that appear as outliers in the data. We are naturally predisposed to look at these outliers (either small or large) but by taking a consistent approach to looking at the largest cost items, we will often improve our overall cost situation the most.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#pick-the-right-approach","title":"Pick The Right Approach","text":"<p>As you focus in on the items to be addressed, take a moment as a FinOps team to think through various approaches you will use to address the opportunity. When identifying the right approach for integrating the FinOps Framework into your business processes and model ask the following questions. </p> <ul> <li>Are there any existing business processes, behaviors, or capabilities in place that could accelerate or empower Framework adoption? Are there any that could hinder it?</li> <li>What changes are needed in order to resolve those conflicts?</li> <li>What are the most valuable \u201cmissing pieces\u201d of the Framework to deliver first, for maximum impact? Are there any elements that may require considerable effort to achieve, and is there sufficient support for that effort?</li> <li>When developing your Framework adoption roadmap, ask: what is the appetite for change within the business, what are the cadences and the pace of change that the business can realistically achieve?</li> </ul> <p>Always keep the end goal in mind when building the FinOps Framework into your business - guide your actions by the key principles, and remember that this is a marathon, not a sprint! It will take time and an iterative approach to adopt the Framework and deliver success. </p> <p>There is a tendency to dive into the solution we know, or to use the technique we are comfortable with, or the tool most recently used successfully. </p> <p>Adoption of cloud is not just a technology problem, a business problem, or a system problem, it is very multi-faceted. Controls that traditionally were in place (procurement control on spending, IT control of technology selection, organizational control of speed, security physical control of environment) are less effective overall, so you may face and address issues that were handled by a wide variety of people in your organization previously all in one place.</p> <p>FinOps teams can become the catchall for questions from capacity planning to cloud service selection to automation to reporting to architecture redesign. Therefore, it is important to have the right resources lined up for support.</p>"},{"location":"02_finops/01_finops_practitioner/#making-tradeoffs","title":"Making Tradeoffs","text":"<p>Cloud tradeoffs are made on what we refer to as the iron triangle. </p> <p>All of these tradeoffs must be done by balancing the company\u2019s goals. Decisions can be made to save money but you will be balancing against speed or quality. Similarly,  you could decide to spend more for better quality but you may give up on cost. </p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#unit-economics","title":"Unit Economics","text":"<p>Making all these decisions ultimately leads us to where a mature organization wants to be able to clearly articulate its costs through Unit Economics. The goal is to make decisions based on value.</p>"},{"location":"02_finops/01_finops_practitioner/#finops-principles","title":"FinOps Principles","text":"<p>***FinOps principles give us north stars to guide our activities as we practice FinOps. These principles were developed by FinOps Foundation members and honed through experience. ***</p>"},{"location":"02_finops/01_finops_practitioner/#overview","title":"Overview","text":"<p>These principles are presented in no particular order and should be used all together as a set. Implementing one, without the others to the extreme creates problems just as implementing all except one will create. The principles are in open source in the FinOps Foundation github repository.</p> <ul> <li>Teams need to collaborate</li> <li>Decisions are driven by the business value of cloud</li> <li>Everyone takes ownership of their cloud usage</li> <li>FinOps reports should be accessible and timely</li> <li>A centralized team drives FinOps</li> <li>Take advantage of the variable cost model of the cloud</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#the-finops-principles","title":"The FinOps Principles","text":""},{"location":"02_finops/01_finops_practitioner/#teams-need-to-collaborate","title":"Teams need to collaborate","text":"<p>FinOps is about cultural change: breaking down the silos between teams that historically haven\u2019t worked closely together. Collaboration is the hallmark of FinOps. Teams must work together in near real-time as the cloud operates on a per resource per second basis. Continuous improvement and fast decision making are required and collaboration is the engine of the practice of FinOps.</p>"},{"location":"02_finops/01_finops_practitioner/#decisions-are-driven-by-the-business-value-of-cloud","title":"Decisions are driven by the business value of cloud","text":"<p>Unit economics and value-based metrics demonstrate business impact better than aggregate spend. Make conscious trade-off decisions between cost, quality, and speed (the iron triangle). Think of cloud as a driver of innovation, a driver of capability, and a way to get speed to market and customer satisfaction up.</p>"},{"location":"02_finops/01_finops_practitioner/#everyone-takes-ownership-of-their-cloud-usage","title":"Everyone takes ownership of their cloud usage","text":"<p>Accountability of usage and cost is pushed to the edge. Individual feature and product teams are empowered to manage their own usage of cloud against their budget. Decentralize the decision making about resource usage and optimization. Technical teams must begin to consider cost as a new efficiency metric. </p>"},{"location":"02_finops/01_finops_practitioner/#finops-reports-should-be-accessible-and-timely","title":"FinOps reports should be accessible and timely","text":"<p>Process cost data quickly and consistently for better cloud utilization. Visibility into cloud spend is provided to all levels of the organization. Create, monitor, and improve real-time financial forecasting and planning. Focus relentlessly on clean data to drive decisions. Utilize internal team benchmarking as well as industry peer-level benchmarking. </p>"},{"location":"02_finops/01_finops_practitioner/#a-centralized-team-drives-finops","title":"A centralized team drives FinOps","text":"<p>Centralized automation for FinOps reduces duplicated efforts. Executive buy-in for FinOps practices and processes is required. Rate and discount optimization is centralized. Centrally govern and control committed use discounts, reserved instances, and volume/custom discounts with cloud providers. Remove the need for engineers and operations teams to think about rate negotiations, then they stay focused on usage optimization.</p>"},{"location":"02_finops/01_finops_practitioner/#take-advantage-of-the-variable-cost-model-of-the-cloud","title":"Take advantage of the variable cost model of the cloud","text":"<p>The variable cost model of the cloud should be viewed as an opportunity, not a risk. This includes just-in-time prediction, planning, and purchasing of capacity. Agile iterative planning is preferred over static long term plans. Make continuous small adjustments in cloud usage/optimization.# Personas &amp; Teams</p>"},{"location":"02_finops/01_finops_practitioner/#personas","title":"Personas","text":""},{"location":"02_finops/01_finops_practitioner/#collaboration","title":"Collaboration","text":"<p>FinOps is inherently about collaboration. The key to the FinOps practice is the need to support a variety of different personas across the business. The FinOps team does not need to have all of the skills of each persona. Rather, they should work to build connections between personas as the FinOps culture becomes ingrained in the organization. FinOps teams also work to ensure the right people in the organization have the information they need to do their specific jobs.</p> <p></p> <ul> <li>Each persona represents a different discipline or perspective on the business</li> <li>Each persona brings their own particular motivations and backgrounds to the discussion</li> <li>Each persona brings important skills and abilities to the successful practice of FinOps</li> </ul> <p>The FinOps team should be focused on providing information specific to and useful to each of these personas. Cloud cost and usage data may be a very deep and broad set of data about an organization's services. However, a big part of what is done in data analysis and showback, chargeback, budgeting, forecasting, and in the organization alignment domain can be customized and tailored to the needs of the audience. The FinOps team can do more than simply provide \"all the data.\"</p>"},{"location":"02_finops/01_finops_practitioner/#personas-across-the-organization","title":"Personas Across the Organization","text":"<p>An important soft skill of a FinOps team is understanding how to serve each persona. Every persona has different interests (cost versus usage, applications versus services, scope, KPIs, etc.).</p> <p>Let's refer back to the FinOps principle: everyone is responsible for their cloud usage. Personas cannot be responsible without good information. Good information must come from all groups who use cloud being able to see, in near real time, what they are using. This enables them to optimize as they go and build responsibly. The FinOps team must ensure everyone takes the responsibility for their cloud usage seriously.</p> <p>Every organization will have specific personas that outline the roles and responsibilities of specific groups in the organization. For example, government entities often have very strong procurement or contract management personas due to the many contract restrictions on government purchasing. In another example, traditional IT companies might have an ITAM persona who works with the FinOps team. Other organizations may have neither of these and the finance persona will handle these responsibilities. Take some time to determine who the personas in your organization are and define how the FinOps team will support each.</p> <p>Practitione </p> <p>Executive </p> <p>PO </p> <p>Engineering </p> <p>Finance </p> <p>Procurement </p> <p>Additional information about FinOps personas.</p>"},{"location":"02_finops/01_finops_practitioner/#finops-team","title":"FinOps Team","text":"<p>FinOps sits at the junction of all these groups and helps to coordinate their activity. Additionally, the FinOps team will have interaction with and may coordinate the activities of cloud vendors externally and many teams internally.</p> <p></p> <p>While FinOps primarily focuses on the coordination of discounts and collaboration with commercial cloud companies, the same disciplines and processes can be used to coordinate workload placement in other commercial clouds or on-premises or collocated data centers as well.</p>"},{"location":"02_finops/01_finops_practitioner/#teams","title":"Teams","text":""},{"location":"02_finops/01_finops_practitioner/#a-finops-team","title":"A FinOps Team","text":"<p>For an organization to successfully adopt cloud, adopt the FinOps principles, generate best practices, and satisfy the needs of the diverse set of stakeholder personas, it needs a FinOps Team. The FinOps team is not a gatekeeper, but a facilitator which brings a unique set of skills and information to the organization to help it adopt a FinOps culture and more successfully drive value from their use of cloud.</p>"},{"location":"02_finops/01_finops_practitioner/#a-finops-teams-primary-actions","title":"A FinOps Team's Primary Actions","text":"<ul> <li>Push Accountability Through the Organization: FinOps requires that we extend accountability to the edges of the organization, where the commitment to purchase now resides. FinOps teams empower feature and product teams to manage their own usage of cloud against their budget. Note that every persona does not have to watch everything, the FinOps team can focus on providing curated information to meet a persona\u2019s needs.</li> <li> <p>Centralized Rate &amp; Discount Optimization: The FinOps team itself centrally governs and controls: Committed Use Discounts, Reserved Instances, Savings Plans, and Volume/Custom Discounts with Cloud Providers (FinOps principle: a centralized team drives FinOps). </p> <p>The FinOps team is looking at the macro consumption by regions, instance types, and will have insights into both product development and executive strategic planning. This is a specific job individuals within a FinOps team do themselves by analyzing, getting commit sign-off, procurement authorization, and executing.</p> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#building-a-finops-team","title":"Building a FinOps Team","text":"<p>FinOps teams are as diverse as company organization structures and there seems to be no one way for how to build or run a FinOps team. Here are some key questions to ask when getting started.</p> <ul> <li>Who should be on a FinOps team? </li> <li>What roles should we look for?</li> <li>How many people should be on a FinOps team?</li> <li>Where should the FinOps team report in the org chart?</li> <li>What are the barriers to effectiveness?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#team-structure-examples","title":"Team Structure Examples","text":"<ol> <li>Most FinOps teams start with someone part-time who has other job roles and then evolves from there.</li> <li>In a less complex organization, a dedicated team can be the central point for all activities.</li> <li>In a more complex organization, or one that has inconsistent use case across business units, a fully matrixed organization might be a better model, giving each unit more autonomy. For example, this might be a good model for a private equity company which expects each unit to be bought or sold independently, and only wants loose coordination across them.</li> <li>Fidelity speaks publicly about their \u201chub and spoke\u201d team structure which has each of their six large-scale cloud-using business units (BU) contributing a person to a core team. This core team performs the FinOps function for the organization as a whole (central RI purchasing, etc.) and then those people also represent and promote FinOps within their BU. They have long-term credibility, an in-depth knowledge of the specific needs of the business unit (all of which have very different cloud use cases), and they can drive that with their users. The centralized FinOps team has a shared understanding of FinOps, its value to the overall organization, and the benefits of the shared functions to the company as a whole.</li> </ol>"},{"location":"02_finops/01_finops_practitioner/#state-of-finops-data-teams","title":"State of FinOps Data: Teams","text":"<p>The State of FinOps survey report(opens in a new tab) is meant to be a living snapshot of the industry. We continue to collect additional responses from our membership and update this report as new insights come in.</p> <p>  In 2019, FinOps members identified the following common roles that existed on FinOps teams.</p> <p>  Our analysis also shows teams are growing 47% from last year and expecting to grow 75% next year.</p> <p>Team size seems to hinge on complexity of cloud use ($10M a year on one SaaS product is easier than $5M a year on 50 applications) and complexity of company (multi-BU, multinational, dozens of apps, five levels of management all complicates things).</p> <p>Most often FinOps sits where the problem started in an organization, and it should then move to wherever the coordination point is to continue doing it.</p> <p></p> Location of FinOps Team Pros / Cons CIO May have more sway with engineers; may not be aligned fully with finance, who watches the watchers CFO May be overly focused on cost savings, may not have support of engineers Procurement May be too low in the organization to be effective, may have the best view as to all avenues for cost savings, right mindset IT Finance May not have the skills or experience to think broadly about finance topics, may be closer to engineering teams CEO This should be a cooperative effort, not jammed down from above, but high level focus and push can make it effective immediately Strategic Initiative Ultimately cloud and FinOps are standard operating procedure, so if strategic, plan to find a permanent home for it soon CTO Worry about FinOps seeming like it\u2019s all about new things, technology change, again look for a permanent home ultimately"},{"location":"02_finops/01_finops_practitioner/#domains-capabilities","title":"Domains &amp; Capabilities","text":""},{"location":"02_finops/01_finops_practitioner/#domains-overview","title":"Domains Overview","text":""},{"location":"02_finops/01_finops_practitioner/#overview_1","title":"Overview","text":"<p>Remember, you are moving to the cloud, facing challenges, and opportunities along the way.  FinOps is helping you on that journey with the north star principles and you\u2019ve formed a FinOps team to help work toward them. Now, what does a FinOps team do?</p> <p>  The FinOps capabilities are the \u201cwhat\u201d the FinOps team does. Within the FinOps framework, the capabilities are categorized into domains. The FinOps team will do work in every domain. However, they will not do all the capabilities all the time or at the same level of maturity.</p> <p>Visit finops.org for more information on domains and capabilities</p>"},{"location":"02_finops/01_finops_practitioner/#finops-domains","title":"FinOps Domains","text":"<p>FinOps domains are the areas of activity or knowledge that are linked to the business outcomes an organization should expect from a FinOps practice. You can think of FinOps domains as the reaction to the large scale changes created by cloud use in the organization. Every organization should strive to do work in each of these domains.  </p>"},{"location":"02_finops/01_finops_practitioner/#key-questions","title":"Key Questions","text":"<p>Each domain answers important questions for the organization using cloud. Click each card to learn more.</p> Answer Question Understanding Cloud Usage and Cost What are we spending on cloud, what are we using, and who is paying for it? Performance Tracking &amp; Benchmarking Does what we\u2019re using and spending create a path for us to achieve our strategic and organizational objectives? Real-Time Decision Making What actions should we be taking right now to allow us to better meet (or stay in line with) our organizational goals? Cloud Rate Optimization How can we change the rate we\u2019re paying, or the way we\u2019re buying what we are using in the cloud to see better price performance? Cloud Usage Optimization How can we adjust what we\u2019re using in the cloud and when we\u2019re using it to better meet our organizational goals? Organizational Alignment What changes or integrations can I do to make my organization use cloud more effectively?"},{"location":"02_finops/01_finops_practitioner/#an-analogy","title":"An Analogy","text":"<p>Callie has been preparing to do a Master Gardening program. When she goes out into the garden every morning, she uses a similar lifecycle model to inform her as to the general health and situation of the garden. She will look for things she may want to do to optimize, then take action on those things for the period of time she has available.</p> <p>The types of things she will do in the garden might include: watering, fertilizing, pruning, planting, mulching, thinning, pulling up, shaping, replanting, or any number of other tasks. She might be at the \u201crun\u201d maturity at watering and fertilizing but still at the \u201ccrawl\u201d maturity when it comes to pruning. She might even be at the \u201crun\u201d maturity at pruning certain types of plants but not others.</p> <p>The one thing she knows is that she will never \u201cmulch\u201d her way to the perfect garden. She will always have to be able to draw upon a wide variety of skills \u2013 at all different levels of maturity \u2013 to maintain the garden. As Callie adds to the garden's diversity and experiences different weather conditions and seasons over time, her skills will have to mature and broaden as well.</p> <p>Just as Callie uses a lifecycle model and performs certain actions (capabilities), you will work to implement each of the different actions (capabilities) of FinOps to maintain the cultural practice of FinOps and maximize business value.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#understanding-cloud-usage-and-cost","title":"Understanding Cloud Usage and Cost","text":""},{"location":"02_finops/01_finops_practitioner/#understanding-cloud-usage-and-cost_1","title":"Understanding Cloud Usage and Cost","text":"<p>This domain enables an organization to understand what cloud services it\u2019s using, what is driving spend, and who owns that spending. It provides key data consistently to support a picture of current cloud usage and a view into historical trends at a level of granularity appropriate to the organization's current maturity level.</p>"},{"location":"02_finops/01_finops_practitioner/#key-questions_1","title":"Key Questions","text":"<ul> <li>What are we spending on cloud?</li> <li>What are we using?</li> <li>Who is responsible for that usage?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#focus-areas","title":"Focus Areas","text":"Focus Area Description WHEN TO USE When will you use this domain most?  Continuously throughout your FinOps practice and consistently during Crawl, Walk, and Run phases.  Over time you will develop more granular reporting, more detailed metadata strategies, and more automation to your hierarchy and compliance KEY BUSINESS OBJECTIVES What are the key business objectives that will lead you to perform this domain?  All of the other domains of FinOps rely heavily on this domain and without it they cannot succeed SUCCESS CRITERIA How do you need to think about this FinOps domain to be successful?   Data quality, consistency, timeliness, and clarity are absolutely essential  Evolve metadata, hierarchy and reporting consistently over time, making small improvements as your cloud use evolves and your FinOps practice becomes more mature APPLICABLE PERSONAS Which personas are critical to and most involved in this domain?  All stakeholder personas will rely upon this data  Defining the metadata and hierarchy for cost allocation will rely heavily on engineering platform teams and architecture teams  Reporting will rely heavily on finance and executives for input"},{"location":"02_finops/01_finops_practitioner/#capabilities","title":"Capabilities","text":""},{"location":"02_finops/01_finops_practitioner/#data-ingestion-normalization","title":"Data Ingestion &amp; Normalization","text":"<p>Data ingestion and normalization in the context of FinOps represents the set of functional activities involved with processing/transforming data sets to create a queryable common repository for your cloud cost management needs. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#cost-allocation-metadata-hierarchy","title":"Cost Allocation (Metadata &amp; Hierarchy)","text":"<p>Cost allocation is the set of practices to divide up a consolidated invoice or bill among those who are responsible for its various component parts. In the context of FinOps this typically involves dividing up consolidated Cloud Service Provider invoices among various IT groups who use cloud within the organization. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#managing-shared-costs","title":"Managing Shared Costs","text":"<p>A foundational principle of FinOps is: \u201cEveryone takes ownership for their cloud usage.\" The true key to understanding total cost of ownership is built upon transparency and accuracy, but unallocated shared costs hinders both of these. Without appropriately splitting costs that are shared, engineers and product managers lack a complete picture of how much their products are really costing. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#data-analysis-showback","title":"Data Analysis &amp; Showback","text":"<p>Data analysis and showback is the ability to leverage data, along with metadata on cloud resources and resource hierarchies, to create a near \u201creal time\u201d reporting mechanism for stakeholders which calls to attention: total costs for the desired business entity, opportunities for cost avoidance, and KPIs for financial health (e.g. performance of rate reduction commitments, unit cost measures for key services, efficiency metrics aggregated by desired \u201cteam\u201d, organizational unit, etc\u2026). Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#performance-tracking-benchmarking","title":"Performance Tracking &amp; Benchmarking","text":""},{"location":"02_finops/01_finops_practitioner/#performance-tracking-benchmarking_1","title":"Performance Tracking &amp; Benchmarking","text":"<p>Within this domain, the organization sets and maps its usage and cost to budgets, uses historical information to forecast, and establishes and measures KPIs and other performance indicators (including benchmarking). This domain entails the capabilities that look at past and current spend, setting baselines and budgets, and then forecasting to help understand if spending is expected, understood, and at a level that meets organizational objectives.</p>"},{"location":"02_finops/01_finops_practitioner/#key-question","title":"Key Question","text":"<p>Does what we\u2019re using/spending allow us to achieve our strategic and organizational objectives?</p>"},{"location":"02_finops/01_finops_practitioner/#focus-areas_1","title":"Focus Areas","text":"Focus Area Description WHEN TO USE When will you use this domain most?  Continuously throughout your FinOps practice and consistently during Crawl, Walk, and Run phases  Will take some work early in your journey  Slow, steady evolution toward things that bring you value  Large effort to adopt cloud budgeting KEY BUSINESS OBJECTIVES What are the key business objectives that will lead you to perform this domain?  Goal/budget setting relies on tracking over time and against others  Accurate forecasting in cloud is much more important  Consistent and meaningful KPI/unit metric reporting SUCCESS CRITERIA How do you need to think about this FinOps domain to be successful?  KPIs can be used in many ways across the business, they are most useful in dynamic areas of variable spend (be creative here)  Measure similar things against one another, measure unique things against themselves over time  Budgeting and forecasting both have to change dramatically and it will take years to complete APPLICABLE PERSONAS Which personas are critical to and most involved in this domain?  All stakeholder personas will rely upon this data  Defining the KPIs that will measure each discipline will require those managing each discipline  Budgeting will rely heavily on finance and executives for input  Forecasting will be a joint effort between finance and engineering groups in the long run"},{"location":"02_finops/01_finops_practitioner/#capabilities_1","title":"Capabilities","text":""},{"location":"02_finops/01_finops_practitioner/#measuring-unit-costs","title":"Measuring Unit Costs","text":"<p>This capability is about developing metrics that reveal the business value of your cloud spend. By calculating cloud spend for total revenue, you can attach growth in cloud spending to your overall business growth. When these are in line, it makes sense that cloud spend isn\u2019t wasted. When cloud spend is growing faster than the business, there may be cause for concern. For a customer-facing application, that unit might be a user or customer subscription; for an ecommerce platform, it might be a transaction; and for an airline, it might be a seat. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#forecasting","title":"Forecasting","text":"<p>Forecasting is the practice of predicting future spending, usually based on a combination of historical spending and an evaluation of future plans, understanding how future cloud infrastructure and application lifecycle changes may impact current budgets and influence budget planning and future cloud investment decisions. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#budget-management","title":"Budget Management","text":"<p>Budgeting for Cloud (or other IT expenses) is a process of collecting estimated expenses for a specific period of time. Decisions on how to operate as a business, what to invest in and other strategic decisions are made based on budgets. If actual expenses do not match the budget, it can impact the operations and other decisions that were made based on those budgets. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#real-time-decision-making","title":"Real-Time Decision Making","text":""},{"location":"02_finops/01_finops_practitioner/#real-time-decision-making_1","title":"Real-Time Decision Making","text":"<p>When we understand what we are spending and understand how we are performing relative to expectations and standards, we can use that information to make real-time decisions.</p> <p>The goal is not to strive for real-time data in and of itself, but to leverage timely access to consistent cost and usage data for making continuous adjustments. This domain improves stakeholder enablement by curating data in stakeholder specific contexts, continually improving decision speed and aligning organizational processes to the realities of operating in the cloud.</p>"},{"location":"02_finops/01_finops_practitioner/#key-question_1","title":"Key Question","text":"<p>What actions can I take now to allow me to better meet organizational goals and objectives?</p>"},{"location":"02_finops/01_finops_practitioner/#focus-areas_2","title":"Focus Areas","text":"Focus Area Description WHEN TO USE When will you use this domain most?  Continuously throughout your FinOps practice  Consistently during Crawl, Walk, and Run phases, but with more action required by the FinOps team earlier in maturity  As you mature, your decisions will be more impactful and important in the \"run\" phase KEY BUSINESS OBJECTIVES What are the key business objectives that will lead you to perform this domain?  Variable use and real-time usage of cloud services means costs accrue immediately  Monthly billing cycles are too slow to spot excessive spending SUCCESS CRITERIA How do you need to think about this FinOps domain to be successful?  Establish decision matrix ahead of problems  Update decision trees and policies regularly  Use automation (in layers) to spot anomalies  Regular communications to those who can investigate or solve anomalous spending APPLICABLE PERSONAS Which personas are critical to and most involved in this domain?  The engineering persona will be critically involved because they must be responsible for their cloud use  FinOps teams will drive this behavior initially if it is new to the organization  Finance or leadership may want to have an aggregate view of anomalous spending"},{"location":"02_finops/01_finops_practitioner/#capabilities_2","title":"Capabilities","text":""},{"location":"02_finops/01_finops_practitioner/#establishing-a-finops-decision-accountability-structure","title":"Establishing a FinOps Decision &amp; Accountability Structure","text":"<p>Establishing a FinOps decision and accountability structure is about capturing an organization\u2019s FinOps-related roles, responsibilities, and activities to bridge operational cloud cost management gaps between teams. These decision-making and accountability structures help cross-functional teams work out the processes and decision trees they\u2019ll need to use to tackle challenges and resolve conflicts, in addition to having them be proactively available when they need to take action ahead of time.</p>"},{"location":"02_finops/01_finops_practitioner/#managing-anomalies","title":"Managing Anomalies","text":"<p>Anomaly management is the ability to detect, identify, clarify, alert and manage unexpected or unforecasted cloud cost events in a timely manner in order to minimize detrimental impact to the business, cost or otherwise. Managing anomalies typically involves the use of tools or reports to identify unexpected spending, the distribution of anomaly alerts, and the investigation and resolution of anomalous usage and cost.</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-rate-optimization","title":"Cloud Rate Optimization","text":""},{"location":"02_finops/01_finops_practitioner/#cloud-rate-optimization_1","title":"Cloud Rate Optimization","text":"<p>Within this domain, the organization works to define pricing model goals, uses historical data to make pricing model adjustments by buying commitment based discounts, and works to manage the pricing aspects of services it is using in the cloud. The cloud rate optimization domain will contain the specialized capabilities to improve the way we purchase cloud services and ensure our pricing models, purchase options, and committed use are consistent with our goals.</p>"},{"location":"02_finops/01_finops_practitioner/#key-question_2","title":"Key Question","text":"<p>How can we change what we pay for in the cloud to achieve better price performance?</p>"},{"location":"02_finops/01_finops_practitioner/#focus-areas_3","title":"Focus Areas","text":"Focus Area Description WHEN TO USE When will you use this domain most?  Continuously throughout your FinOps practice  Likely in more impactful ways early in FinOps maturity  Over time you will develop more granular reporting to track your rate optimization KEY BUSINESS OBJECTIVES What are the key business objectives that will lead you to perform this domain?  Pay lower amounts of money for things you know you\u2019ll use over an extended period  Leverage commitment targets to move more workloads more quickly  Achieve a level of savings while doing longer-cycle optimizations SUCCESS CRITERIA How do you need to think about this FinOps domain to be successful?  Track commitments against actual usage, balance of various discounting levels, and commitment levels  Consistent coverage rate (at targets set by organization)  Improved rate optimization over time  KPIs around savings and cost avoidance as a result of rate optimization  High utilization of commitments APPLICABLE PERSONAS Which personas are critical to and most involved in this domain?  A FinOps team will provide access to forecasts and usage patterns to make commitment decisions  Executives and procurement will manage many of the commitment discussions  Finance will be involved in verifying commitments to strategy and approving commitment payments  Product owners consult on forecasting and give guidance on commitment impacts to budgets"},{"location":"02_finops/01_finops_practitioner/#capability","title":"Capability","text":""},{"location":"02_finops/01_finops_practitioner/#managing-commitment-based-discounts","title":"Managing Commitment Based Discounts","text":"<p>Spend-based commitment discounts and resource-based commitment discounts are the most popular rate optimizations that cloud service providers offer. Each cloud service provider has a slightly different offering with its own specific rules on how it works and the discounts it provides. You must consider the implementation models that organizations use, based on their needs, and how the overall process should work inside an organization. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-usage-optimization","title":"Cloud Usage Optimization","text":""},{"location":"02_finops/01_finops_practitioner/#cloud-usage-optimization_1","title":"Cloud Usage Optimization","text":"<p>Within this domain, the organization identifies and takes action to match running cloud resources to the actual demand of the workloads running at any given time. This work involves predictive rightsizing of resources, managing workloads to align with the correct number of scaling resources, turning resources off when not in use, and other techniques.</p> <p>The cloud usage optimization domain contains the set of capabilities to match our actual workload needs to the cloud services we use at any given time as closely as possible. Using the right resources, in the right size, only when we need them to produce business value is ultimately how the variable use model of cloud allows us to do to maximize value to our business.</p>"},{"location":"02_finops/01_finops_practitioner/#key-questions_2","title":"Key Questions","text":"<ul> <li>How can we change what we use in the cloud to better meet organizational goals?</li> <li>How can we change when we use it to better meet organizational goals?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#focus-areas_4","title":"Focus Areas","text":"Focus Area Description WHEN TO USE When will you use this domain most?  Continuously throughout your FinOps practice  More frequently during Crawl and Walk than in Run phase as engineering teams push cost earlier in the design &amp; build process  More for newer services and products that are unfamiliar KEY BUSINESS OBJECTIVES What are the key business objectives that will lead you to perform this domain?  Only use what you need SUCCESS CRITERIA How do you need to think about this FinOps domain to be successful?  Efficiency metrics will show the areas in which to focus  Prioritize teams, products, or use cases that provide most value (work through that list from top down)  Empower those who can make a difference as close to the resources as possible APPLICABLE PERSONAS Which personas are critical to and most involved in this domain?  Engineering is the key persona for cloud usage optimization  Everyone is responsible for their cloud use  FinOps teams will drive early on  Leadership should champion"},{"location":"02_finops/01_finops_practitioner/#capabilities_3","title":"Capabilities","text":""},{"location":"02_finops/01_finops_practitioner/#onboarding-workloads","title":"Onboarding Workloads","text":"<p>This capability is about establishing a cloud front door process to onboard brownfield and greenfield applications through financial viability and technical feasibility assessment criteria. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#resource-utilization-efficiency","title":"Resource Utilization &amp; Efficiency","text":"<p>The management of resource utilization and efficiency translates into identifying whether there is scope to reduce resource costs while maintaining the required performance and, if there is, making the changes required where it is economically worthwhile to do so. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#workload-management-automation","title":"Workload Management &amp; Automation","text":"<p>Workload management and automation focuses on running resources only when they are needed, and creating the mechanisms to automatically adjust what resources are running at any given time. This capability is intended to give FinOps teams the ability to match supply to demand most efficiently, and effectively optimize cloud usage through measurement of workload demand and provisioning capacity dynamically. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#organizational-alignment","title":"Organizational Alignment","text":""},{"location":"02_finops/01_finops_practitioner/#organizational-alignment_1","title":"Organizational Alignment","text":"<p>Within this domain, the organization acts and automates to manage cloud use within the context of other IT finance activities, and integrates FinOps capabilities with existing organizational processes, organizational units, and technology.</p> <p>This domain contains the capabilities we\u2019ll use to continuously improve, to change, and align our organization itself - its people, processes and technology - to use cloud in the way it will benefit the company best. Actions here may improve persona centric enablement, FinOps training and adoption, and align existing processes to support cloud use more effectively.</p>"},{"location":"02_finops/01_finops_practitioner/#key-questions_3","title":"Key Questions","text":"<ul> <li>What changes can I make within my organization to use cloud more effectively?</li> <li>How can I establish a FinOps culture to enable stakeholder teams?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#focus-areas_5","title":"Focus Areas","text":"Focus Area Description WHEN TO USE When will you use this domain most?  Continuously throughout your FinOps practice  Consistently during Crawl, Walk, and Run phases  Purposefully maintain focus on evolving organizational alignment as cloud maturity grows  Important to introduce early in the FinOps maturity for maximum impact (refine as you grow) KEY BUSINESS OBJECTIVES What are the key business objectives that will lead you to perform this domain?  Ensure all key stakeholders are informed, educated, and empowered to make timely, data-driven decisions to maximize value  Strategy and context flows across the business to promote successful implementation Improve the quality and pace of real-time decision making SUCCESS CRITERIA How do you need to think about this FinOps domain to be successful?  Clear and appropriate cadences and cycles for stakeholder reviews and decisions  High level of confidence that using cloud is being used in the best way to maximize benefit APPLICABLE PERSONAS Which personas are critical to and most involved in this domain?  All stakeholder personas will be affected by and involved in the organizational alignment domain  FinOps is driving alignment across all levels and disciplines within the organization  Successful alignment depends on engagement and support from the entire organization"},{"location":"02_finops/01_finops_practitioner/#capabilities_4","title":"Capabilities","text":""},{"location":"02_finops/01_finops_practitioner/#establishing-finops-culture","title":"Establishing FinOps Culture","text":"<p>This capability is about creating a movement to establish cultures of accountability so that your organization understands that the practice of cloud cost management is really about leveraging FinOps to accelerate the creation of business value. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#chargeback-finance-integration","title":"Chargeback &amp; Finance Integration","text":"<p>Chargeback and finance integration is about pushing spend accountability to the edges of the organization that are responsible for creating the expense. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#finops-education-enablement","title":"FinOps Education &amp; Enablement","text":"<p>FinOps education and enablement allows all those participating in FinOps practices to increase the business value of cloud by accelerating FinOps adoption. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-policy-governance","title":"Cloud Policy &amp; Governance","text":"<p>Policy and governance can be thought of as a set of statements of intent, with associated assurances of adherence. A \u201ccloud policy\u201d is a clear statement of intent, describing the execution of specific cloud-related activities in accordance with a standard model designed to deliver some improvement of business value. \u201ccloud governance\u201d is a set of processes, tooling or other guardrail solution that aims to control the activity as described by the cloud policy to promote the desired behavior and outcomes. Combining good policy and governance provides us with a mechanism to orchestrate and direct our Cloud FinOps activity. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#finops-intersecting-frameworks","title":"FinOps &amp; Intersecting Frameworks","text":"<p>This capability examines the intersection between FinOps with other standards and frameworks used within your organization. Widespread use of public cloud creates new challenges for traditional processes and the intention for this capability is to provide a place to capture FinOps\u2019 interactions with existing IT and financial standards being used by your organization. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#platforms-tools","title":"Platforms &amp; Tools","text":""},{"location":"02_finops/01_finops_practitioner/#platforms-tools_1","title":"Platforms &amp; Tools","text":"<p>Every organization will use some combination of cloud provider provided tools, third party or open source tooling, and internally developed tools and platforms to perform every domain. The mix of tooling and process support will change as you mature in your practice of FinOps and in your use of cloud.</p>"},{"location":"02_finops/01_finops_practitioner/#cloud-provider-cost-management-tools","title":"Cloud Provider Cost Management Tools","text":"<ul> <li>All cloud providers will include tools designed to help you understand your cloud usage and cost </li> <li>Cloud provider platforms will most often only be applicable to that cloud provider\u2019s usage</li> <li>Differences will exist between providers\u2019 data primarily in granularity, grouping/summarization, handling of amortization for prepaid amounts, and application of custom discounts and credits</li> <li>Cloud provider tools and platforms are typically going to be available for no or very low cost</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#finops-platforms-tooling","title":"FinOps Platforms &amp; Tooling","text":"<ul> <li>Understanding cost and usage calls for a lot of data ingestion, summarization, normalization and data analysis</li> <li>Broadly-focused platforms ingest cloud data, process it, provide recommendations, and provide a broad reporting mechanism that will cover a wide variety of reporting needs</li> <li>Consider more specialized tools where you have extensive use of specific products or services (e.g. Kubernetes)</li> <li>Broad FinOps platforms typically are sold at a percentage of your overall cloud cost managed</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#finops-service-providers-consulting-help","title":"FinOps Service Providers (consulting help)","text":"<ul> <li>Some FinOps service providers offer services which perform this type of service on your behalf, but these would typically be longer-term consulting engagements to do this broadly focused job</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#internal-tooling-custom","title":"Internal Tooling (custom)","text":"<ul> <li>FinOps teams need to be aware of the amount of data and degree of potential change which can occur in billing and usage data</li> <li>Data quality will need to be monitored closely and consistently over time</li> <li>Internal reporting and data analysis or metrics teams can often provide skilled resources who can help develop dashboards and other reporting capabilities inside your organization</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#activity","title":"Activity","text":""},{"location":"02_finops/01_finops_practitioner/#capabilities-review","title":"Capabilities Review","text":"<p>Read each of the following scenarios and consider which capability will best address it. (Flip each card for the answer before advancing to the next card)</p> <p>  FinOps Education &amp; Enablement</p> <p>  Resource Utilization &amp; Efficiency</p> <p>  Cost Allocation</p> <p>  Manage Commitment Base Discounts</p> <p>  Forecasting</p> <p>  Chargeback &amp; IT Finance Integration</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#motivations-common-language","title":"Motivations &amp; Common Language","text":""},{"location":"02_finops/01_finops_practitioner/#motivations","title":"Motivations","text":""},{"location":"02_finops/01_finops_practitioner/#overview_2","title":"Overview","text":"<p>Remember, you\u2019re moving to the cloud, facing challenges and opportunities. Your FinOps team is coming together to meet the FinOps principles and to perform the FinOps capabilities. However, as you think of the breadth of activities you\u2019ll need to perform, consider the motivations and common language needs that will come into play.</p> <p></p> <p>Everyone the FinOps team interacts with has a different set of motivations, language, and point of view. Further, every member of the FinOps team itself brings a different set of motivations, language, and point of view. One of the primary jobs of the FinOps team is to integrate these motivations, languages, and points of view to drive collaboration.</p> <p>In order to do that work across the organization, though, we first have to establish a common language and understand the motivations of all of the teams we will work with.</p>"},{"location":"02_finops/01_finops_practitioner/#motivations_1","title":"Motivations","text":"<p>FinOps teams are usually cross-functional and matrixed, meaning there are a wide variety across many dimensions. Different motivations and language can come together, through collaboration, to be more powerful.</p> <p>FinOps Teams Come with a Variety of:</p> <ul> <li>Backgrounds</li> <li>Points of View</li> <li>Motivations</li> <li> <p>Experiences</p> </li> <li> <p>Biases</p> </li> <li>Vocabularies</li> <li>Expertise</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#common-language","title":"Common Language","text":"<p>A big part of building the FinOps practice is building a common language or vocabulary. Everyone on the FinOps team will be learning new terms and new concepts. Many of these terms are loaded with meaning that may not be apparent to all.</p>"},{"location":"02_finops/01_finops_practitioner/#terms","title":"Terms","text":"<p>Each organization should build a working vocabulary or acronym list that defines key terms. This glossary should include both generic industry terms and terms that are specific to the organization. Below are examples of both generic and specific terms within FinOps (both cloud and discipline specific).</p> FinOps Inform  Optimize  Operate  Financial Crawl, Walk, Run   Rightsizing  Automation  Blended Rates Cloud AWS  Azure  GCP EC2  Enrollments  Projects Finance  Engineering / IT  Product / Business NPV  DevOps  Agile Organizatioal Organizational Hierarchy   Cost Tracking Business Unit, Division   Cost Center, CMDB Code"},{"location":"02_finops/01_finops_practitioner/#glossaries","title":"Glossaries","text":"<p>There are lots of terms and tools specific to FinOps, utilize the resources below to get started.</p> <p>FinOps Terminology</p> <p>A list of terminology and examples for Cloud Cost Management, Public Cloud, Software Development &amp; Operations, and Finance &amp; Accounting categories. FinOps Terms</p> <p>Multi-Cloud Tools &amp; Terminology</p> <p>A matrix of tools available to help FinOps practitioners learn and practice efficient utilization of cloud resources as well as terminology and additional resources. Multi-Cloud Terms</p>"},{"location":"02_finops/01_finops_practitioner/#finance-accounting","title":"Finance &amp; Accounting","text":"<p>Below are key accounting terms useful when dealing with finance and accounting teams. What we do in the cloud has big implications to the finance teams and is a big change from the old data center model. Check with your finance team to see if they have an existing glossary of terms or find definitions to many terms here.</p> <p> </p>"},{"location":"02_finops/01_finops_practitioner/#importance-of-a-common-language","title":"Importance of a Common Language","text":"<p>We need to drive toward the point where the FinOps team does not have to be in every meeting translating every sentence for every team. Rather, the FinOps team should bring everyone into a common language where discussions can be productive between any groups. We then are able to let these groups build that culture of the cloud in their own teams as well.# Anatomy of a Cloud Bill</p> <p>Remember, you\u2019re moving to the cloud, facing challenges and opportunities. Your FinOps team is in place, ready to perform the capabilities that will let you meet the goals of the FinOps principles. One of the biggest challenges you will face is something specific to cloud: the massive amount of information presented in the cloud bill.</p>"},{"location":"02_finops/01_finops_practitioner/#levels-of-cloud-usage-cost-information","title":"Levels of Cloud Usage &amp; Cost Information","text":"<p>Part of the reason FinOps can be so challenging is the quantity of data FinOps teams need to manage in order to report on usage, find optimizations, and act on them on a fast cycle. </p>"},{"location":"02_finops/01_finops_practitioner/#summary-invoice-data","title":"Summary Invoice Data","text":"<p>Summary invoice data at the management, enrollment or billing account level</p> <ul> <li>Usage summarized for your whole organization</li> <li>May be broken down by service name</li> <li>May or may not include discounts </li> <li>Several pages covering an unlimited amount of spend, delivered once a month after the fact</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#usage-cost-reporting-tools","title":"Usage &amp; Cost Reporting Tools","text":"<p>Usage and cost reporting platform provided by the cloud provider (or third party or that you build)</p> <ul> <li>Usage reportable more flexibly</li> <li>May or may not include specific rates, metadata, summarization information</li> <li>Business Intelligence type tool for creating custom reports, available anytime</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#detailed-usage-billing-data","title":"Detailed Usage &amp; Billing Data","text":"<p>Detailed cost and usage data via CUR file or billing APIs</p> <ul> <li>Detailed usage information at full granularity</li> <li>Extremely large datasets, up to billions of lines of data per month, delivered each day</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#invoice-level","title":"Invoice Level","text":"<p>Invoices are for billing, not FinOps. This is an example invoice report produced by a cloud provider. It summarizes hundreds of thousands of dollars, aggregated by service, with very little detail. This is too little data to effectively manage cost or usage. However, CUR Files, Billing Extracts and Billing APIs provide an often overwhelming amount of data.</p> <p>It is crucial to find the right tools to allow you to get the data you need at the right level of detail for your maturity level to make the real-time decisions you need to make.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#cloud-cost-management-platforms","title":"Cloud Cost Management Platforms","text":"<p>Cloud providers offer tools to see more granularity. These tools generally provide a basic way to look at the data. These tools are always advancing and becoming more flexible and detailed.</p> AWS AWS has the most mature billing process  Still Invoice and CUR come out of different systems, rarely match 100% to the penny  Constantly evolving  CUR is third generation bill format  CUR fed by individual service teams, not entirely internally consistent either AZURE Invoices monthly or quarterly, depending on the contract relationship  Billing data via billing APIs pre-2020 does not include list cost, amortization of upfront payments, prepaid RI costs, specific resource information (scale sets, eg),  Utilization data available from Azure Monitor  Significant advanced internal tooling/platforms for reporting GCP Most summarized of the three, constantly evolving their Standard Export and Detailed Export to add new columns to help customers understand their bill  Resource level information available for most services, the billing export is summarized at the SKU level OCI"},{"location":"02_finops/01_finops_practitioner/#anatomy-of-an-aws-cur-file","title":"Anatomy of an AWS CUR File","text":""},{"location":"02_finops/01_finops_practitioner/#detailed-cost-usage","title":"Detailed Cost &amp; Usage","text":"<p>There is a lot of new language introduced in the cloud usage and billing data, and we need to know how to deal with it. Cloud providers usually give you billing data every day; it is important to understand how the billing is coming in and how to understand the information.</p>"},{"location":"02_finops/01_finops_practitioner/#raw-cloud-data-is-not-human-readable","title":"Raw cloud data is not human readable.","text":"<ul> <li>Cloud bills can run to the hundreds of millions or billions of rows of data.</li> <li>AWS breaks its monthly CUR file into dozens of files in the S3 bucket where they are stored so that each file is smaller than the maximum file size limit on some machines. So, the CUR can\u2019t even be loaded all at once into Excel. It\u2019s too big.</li> <li>Azure and GCP provide data through an API, which allows more control over how big the data set is and how it\u2019s summarized. However, these services also have multiple APIs.</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#the-billing-data-contains-the-details-about-each-charged-item","title":"The billing data contains the details about each charged item.","text":"<ul> <li>The billing data contains attributes about the charges (metadata or dimensions) like region or instance ID or the time it ran, the tags, the description, the size, etc. </li> <li>Metrics include the amount of time it ran, or the usage quantity, and the rate(s).</li> <li>Multiple rates might be quoted, blended rates, unblended rates, amortized rates, etc. </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#one-virtual-machine-might-be-billed-at-various-rates","title":"One virtual machine might be billed at various rates.","text":"<ul> <li>Some of a virtual machine's time might be covered by reservations and some on-demand.</li> <li>Each \"rate x usage\" or \"rate x time\" combination will be a separate line.</li> <li>Some services also include many types of charges/meters \u2013 usage, storage, iops, read/write units, data transfer, etc. </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#these-files-apis-are-imperfectly-documented-and-change-often","title":"These files &amp; APIs are imperfectly documented and change often.","text":"<ul> <li>They can go into the many teams dumping data into the billing data discussion if helpful.</li> <li>They can go into the issue of data quality being a problem to manage if you build your own queries.</li> <li>They can go into ongoing improvements in this area from all the vendor.</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#cloud-billing-data-fundamentals","title":"Cloud Billing Data Fundamentals","text":"<p>At the basic level each item has a time or usage number and a rate. We multiply those to get the cost. Everything else is details (lots of details). If you want to change the cost for yourself, there are two main levers:</p> <ol> <li>Change how much you use (decentralized)</li> <li>Change the rate you pay (centralized)</li> </ol> <p># FOCUS</p> <p>When thinking about cost avoidance, rate reduction, and practically every FinOps capability, we must talk again about data and cloud billing. A massive quantity of cloud billing data, likely from a wide variety of vendors, shows up every day. Your ability to ingest, normalize, and then analyze this data into coherent reporting and recommendations is compromised by this complexity and variability. This inefficient process needs a solution.</p> <p>FOCUS (FinOps Open Cost &amp; Usage Specification) is a project designing a vendor agnostic technical specification for cloud billing data. FOCUS aims to make billing data more consistent and usable across Cloud, SaaS, and even internal billing sources, improving your understanding of your costs, and allowing you to make better decisions. </p> <p>focus.finops.org - Check out our dedicated FOCUS page to see the specification, contributors, and learn how to get involved. </p>"},{"location":"02_finops/01_finops_practitioner/#tell-me-more","title":"Tell Me More","text":"<p>Imagine there was a single view of spend connected to the delivery of applications and services in the cloud. Well, FOCUS says just how to do this! This means cloud adoption would move faster and stakeholders would start to trust more in the data and cost mapping.</p> <p>A simple bill that reliably reports across multiple vendors? FOCUS will remove complexity and overhead from processes such as allocation, chargeback, budgeting, forecasting, and more to maximize business value in the cloud. </p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#introduction-to-focus","title":"Introduction to FOCUS","text":"<p>In this session during FinOps X 2023, Mike Fuller (CTO of the FinOps Foundation) and Udam Dewaraja (Chair of the FOCUS Project) give an in-depth look at the FinOps Cost and Usage Specification project, better known as FOCUS. They discuss what the project is all about, its objectives toward steering the cloud billing data and its variants into something more of an open, accessible data model, and how practitioners, cloud service providers, and tooling vendors can get involved.</p> <p>Introduction to FOCUS</p>"},{"location":"02_finops/01_finops_practitioner/#how-will-this-work","title":"How Will This Work?","text":"<p>FOCUS is already underway. A specification has been created covering cloud service providers (CSPs) and future updates are expected to add support for SaaS providers and even on-premises datasets. The following steps show the outline for the modernization of cloud billing data.</p> <ol> <li>Build a specification detailing the dimensions and metrics required for good cost management</li> <li>Work with the community to convert existing billing formats into FOCUS compatible datasets</li> <li>Work with cloud service providers and SaaS providers to natively support FOCUS</li> </ol>"},{"location":"02_finops/01_finops_practitioner/#why-it-matters","title":"Why It Matters","text":"<p>Understanding data and FOCUS could lead to an increase in trust and collaboration within the organization. With simplified and reliable data, an organization might feel empowered to share data more openly. This would enable those you work with to have more ownership of their own cloud spend. Additionally, rather than having to learn (or teach someone) multiple ways to run queries, there will be one centralized location and set of processes. This also means that your skills are more portable. You will be able to run queries on datasets that comply with the FOCUS specifications regardless of which CSP or SaaS providers are involved.</p> <p>Additionally, FOCUS means:</p> <ol> <li>Better understanding of cost and usage data to make better engineering decisions that consider cost from the beginning</li> <li>Better ability to compare apples to apples when considering how and where to run resources as part of an infrastructure or application</li> <li>More consistent terminology and data structures to enhance collaboration, and to make skills more portable across clouds, FinOps tools, and organizations.</li> </ol>"},{"location":"02_finops/01_finops_practitioner/#what-people-are-saying-about-focus","title":"What People are Saying about FOCUS...","text":"<p>Tim O'Brien, Senior Director Engineering, Walmart  Learn more about how FinOps data is used at scale at Walmart and the importance of FOCUS for the future of data.  FinOps Data</p> <p>Mich Razon, VP &amp; GM Platform, Google  Fred Delombaerde, VP Core Commerce, Microsoft  Phil Newman, VP Product, Oracle  Learn from this panel about why the each CSP would be involved in FOCUS and what this initiative would provide to their customers (YOU!).   CSP Panel on FOCUS</p> <p>Google\u2019s Insight on FOCUS  When they go closed, we go open \u2013 Google Cloud and open billing data.  GCP on FOCUS</p> <p>Microsoft's Insight on FOCUS  This article explains how to export cost details using the FinOps Open Cost and Usage Specification (FOCUS).   Azure on FOCUS</p>"},{"location":"02_finops/01_finops_practitioner/#running-the-finops-team","title":"Running the FinOps Team","text":""},{"location":"02_finops/01_finops_practitioner/#recap","title":"Recap","text":"<p>We have spent a lot of time learning about the work that a FinOps team must do in an organization. Now, how do we use these concepts and models in our FinOps team to help our organizations achieve greatness and still focus on the FinOps team as a team?</p> <p>As we run our team we want to hone in on FinOps as a discipline. We also have to remember that our FinOps team itself (whatever the size, structure or reporting point) requires management and focus too.</p>"},{"location":"02_finops/01_finops_practitioner/#understanding-types-of-work-performed","title":"Understanding Types of Work Performed","text":"<p>As your FinOps practice continues to grow and evolve along with your cloud adoption journey, it is likely that no two days will be the same. As the roles, responsibilities, processes, and tasks of your team develop, they will often fall into three areas: ad-hoc, business as usual (BAU), and planned work.</p> <p>Appropriate time and resources should be budgeted to accommodate these different workflows, ensuring that the practice is always able to respond to time-sensitive matters while continuing to perform the daily activities.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#running-a-finops-team","title":"Running a FinOps Team","text":"<p>The Adopting FinOps Roadmap gets your organization primed to actually begin to perform the capabilities we have described as well as accelerate and amplify the value of your move to cloud. Once a FinOps team is running, there will also be an arc of progress as you launch, mature, and grow your cloud use.</p>"},{"location":"02_finops/01_finops_practitioner/#operating-the-team-as-a-team","title":"Operating the Team as a Team","text":"<p>First there should be a focus on operating the team as a team with a distinct set of goals, KPIs, and responsibilities. It is tempting to staff a FinOps team entirely with part-time resources or to distribute some of the jobs of the central FinOps team to other disciplines.</p> <p></p> <p>Without some focus on the team as a discipline, there is a likelihood that only the low hanging fruit of FinOps will be targeted and the deeper functionality and more lasting results will be missed.</p>"},{"location":"02_finops/01_finops_practitioner/#have-a-finops-leader","title":"Have a FinOps Leader","text":"<p>Second, there should be a FinOps leader. This is someone who will be responsible for the successful adoption of FinOps and closely accountable for the success of the organization\u2019s use of cloud.</p> <p></p> <p>The FinOps Professional certification is an excellent way to prepare to be a FinOps leader. </p>"},{"location":"02_finops/01_finops_practitioner/#work-the-finops-capabilities-mature-functionality-bring-value","title":"Work the FinOps Capabilities, Mature Functionality, Bring Value","text":"<p>Third, the FinOps team should work not just to do the FinOps capabilities, but to mature its own functionality and value to the organization. A FinOps team starting out will rack up some impressive results early on as low hanging fruit are often plentiful. However, over time, the team will begin to tackle harder challenges, which may take longer to implement or may involve more stakeholders to accomplish.</p> <p></p> <p>Begin as early as possible to focus on the value the team is bringing the organization. </p> <ol> <li>What recommendations are you making?</li> <li>Which are actioned?</li> <li>What value is being created?</li> <li>What long term value are you enabling?</li> <li>Are you making an impact on the engineering time available, the staffing, or the number of apps that can be moved or built in cloud?</li> </ol> <p>Continually focus on this value as you grow and mature.</p>"},{"location":"02_finops/01_finops_practitioner/#inform-phase-overview","title":"Inform Phase Overview","text":""},{"location":"02_finops/01_finops_practitioner/#recap_1","title":"Recap","text":"<p>Remember, you\u2019re moving to cloud, facing challenges and opportunities. You\u2019ve put together a FinOps team to realize the FinOps principles by exercising the FinOps capabilities. You\u2019ve looked at the motivations of teams around your company and mastered the cloud billing data.  Now we\u2019ll exercise all of those capabilities to understand our use and spending in the Inform phase.</p>"},{"location":"02_finops/01_finops_practitioner/#inform-phase","title":"Inform Phase","text":"<p>In the Inform phase, we create and use the tags/labels, account hierarchy and other taxonomy to allocate all costs to get a near-real-time view of our current cloud usage.</p> <p>The Inform phase supports the principles:</p> <ul> <li>Everyone takes ownership for their cloud usage</li> <li>FinOps reports should be accessible and timely</li> </ul> <p></p> <p>During the Inform phase, we're looking to see:</p> <ul> <li>What are we using and spending?</li> <li>Is it what we expected?</li> <li>What value is it creating?</li> <li>Who is responsible for its effective use?</li> </ul> <p></p> <p>The majority of the capabilities we will use to accomplish the Inform phase are in the domains:</p> <ul> <li>Understanding Cloud Usage &amp; Cost</li> <li>Real-Time Decision Making</li> <li>Performance Tracking &amp; Benchmarking</li> </ul> <p> </p>"},{"location":"02_finops/01_finops_practitioner/#reporting","title":"Reporting","text":"<p>Work to establish trust in numbers and consistently report cloud cost data within all groups. Assess the presentation materials for the audience, accuracy, scope, etc. Take all types of data quality issues seriously. </p>"},{"location":"02_finops/01_finops_practitioner/#reporting-the-user-interface-of-finops","title":"Reporting: The User Interface of FinOps","text":"<p>The reports and dashboards created to build FinOps inside your organization can be considered the User Interface (UI) of FinOps. These reports are often what your staff see when interacting with FinOps processes. By looking at your reports and dashboards as your UI, you can apply decades of research into good UI design, apply DevOps practices in order to manage your reports and design them with consideration to the psychology of how users interact with them. </p>"},{"location":"02_finops/01_finops_practitioner/#building-quality-finops-reports","title":"Building Quality FinOps Reports","text":"<ul> <li>Differentiate production reports from ad hoc and investigative reporting capabilities - and treat them like the production software they are</li> <li>Prioritize consistency and data quality above all else. Automate important reports to avoid human errors and ensure consistent delivery</li> <li>Make reports specific to the needs and motivation of a each persona</li> <li>Provide context: use KPIs instead of raw numbers</li> <li>Edit ruthlessly, simplify, and look at what\u2019s actually useful to your users</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#types-of-cost-metrics","title":"Types of Cost Metrics","text":"<p>There are various types of cost metrics available to use on reporting, on dashboards, and as part of KPIs. Click each card below to flip and view the definition.</p> Types of Cost Metrics Description On-Demand Cost On-Demand Cost: The list prices publicly stated by vendors, before any discounts. Discounted Rate Discounted Rate: The public rate discounted with some of the available discounts (free tier, commitment based discounts, negotiated rate discounts, sustained use discounts). Amortized Costs Amortized Cost: The amortized cost of a resource takes this initial payment into account and distributes it out based on usage, attributing the prorated cost for each hour of billing. Fully-Loaded Cost Fully-Loaded Cost: Are amortized, reflect the actual discounted rates a company is paying for cloud resources, equitably factor in shared costs, and are mapped to the business\u2019s organizational structure. In essence, they show the actual costs of your cloud and what is driving them. Unblended Rate Unblended Rate: Some resources are charged in decreasing rates the more you use them. This means you\u2019re billed different rates for resources as you use more, or for longer periods during the month. By examining your bill, you can see that some resource costs are larger than others, even for the same type of resource or an identical resource. When the rates are presented this way, they\u2019re called unblended. Blended Rate Blended Rate: AWS provides blended rate information on its invoice showing the effective rate for a group of resources with the same attributes where some of the resources are receiving a discount from reservations and some are not. This can help to eliminate the effects of reservations applying randomly to resources in multiple linked accounts, by providing a consistent rate for specific resources that would have been eligible to be covered by the reservation or savings plan."},{"location":"02_finops/01_finops_practitioner/#data-in-the-path-of-the-engineer","title":"Data in the Path of the Engineer","text":""},{"location":"02_finops/01_finops_practitioner/#the-prius-effect","title":"The Prius Effect","text":"<p>In a regular gas car, the feedback you receive about your mileage lags. You get it only when you fuel up, if you get a receipt and do some math. In the Prius, and other electric cars, the driver is given instant feedback on when they are using power from the engine, using gas, or when they are regenerating/charging. There is no light on the dash that says \u201cDrive economically!\u201d It is just the natural inclination of drivers to attempt to stay in the green zone. This effect will stay with you even when you drive in gas cars shortly after being in an electric, but it slowly wears off. This is not to say that you can\u2019t go hyper fast and powerful in an electric vehicle. Anyone who has driven a full-power Tesla knows this. </p> <p></p> <p>There is continuous feedback on usage in the Prius (engine, gas, or recharging/charging). Therefore, when you need to use all the power at your disposal you can make a conscious decision to do so and the car will support it. However, under ordinary circumstances, the continuous feedback provided on usage tends to guide responsible behavior. </p> <p>It is similar with the cloud. FinOps teams should strive to provide continuous, simple, clean feedback to cloud users to keep them driving economically. Engineering teams responsible for their cloud use will respond to cost information and use it as an efficiency metric, which is what we want. We refer to this as \u201cPutting Data in the Path of the Engineer.\" This doesn\u2019t just work for engineers, putting a good UI in front of any of our persona stakeholders makes a big difference in keeping cloud optimization front of mind. It is in the Inform phase that the FinOps team creates the data transparency that the organization needs to successfully execute the FinOps lifecycle.</p>"},{"location":"02_finops/01_finops_practitioner/#resources_1","title":"Resources","text":"<p>Encouraging Engineers to Take Action. This article addresses how finance, operations, and executives can work better together to encourage cloud cost optimization from their engineering teams. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#anomaly-detection","title":"Anomaly Detection","text":""},{"location":"02_finops/01_finops_practitioner/#anomaly-detection_1","title":"Anomaly Detection","text":"<p>Anomaly detection is crucial to any cloud operation. In addition to security and operational monitoring, cost monitoring can provide crucial early warning signs.</p> <p>Consider Various Alerting Schemes</p> <p></p> <p>Anomalies will occur. Security systems, performance systems, and configuration management systems will spot anomalies in usage. FinOps teams should choose tools to help spot anomalies in spending as well. Various alerting methods work in different scenarios: spending changes, spending changes over standard deviations, and checking each allocation category (e.g. $500 of extra spending may not be anomalous on a $50,000 monthly bill, but $500 extra in my $200 monthly bill is). Percentage change can also be an anomaly type, and in some cases, spending of any type of unexpected service type can be considered an anomaly. Anomaly definitions should be continuously reviewed and refined in order to balance valid alerting against noise.</p>"},{"location":"02_finops/01_finops_practitioner/#resources_2","title":"Resources","text":"<p>Managing Anomalies Learn more about the managing anomalies capability within the performance tracking and benchmarking domain. </p> <p>Anomaly Detection at Scale This practitioner story provides an example of anomaly detection at scale. |learn more</p>"},{"location":"02_finops/01_finops_practitioner/#benchmarking","title":"Benchmarking","text":"<p>Within the Inform phase, benchmarks enable you to see what is being used, how much it costs, and compare to others. There are multiple ways in which you can benchmark:</p> General Analyst Benchmarking Details Flexera, McKinsey, Gartner, IDC, etc. Provides some general information on state of the cloud, state of cloud adoption, cloud migration, etc. Cloud Providers Provides benchmarking for companies \u201clike you\u201d (sometimes this is not provided) FinOps Foundation: State of FinOps Provides benchmarks for some cloud use data.finops.org FinOps Slack Group Provides avenues to meet others and compile anecdotal comparisons to other companies in or outside your industry Internal Benchmarking Provides insight between teams within your organization with similar profiles of usage or for size-independent KPIs Benchmarking Against Self Provides useful and consistent benchmarks over time as well as a means to compare different types of teams <p>As you benchmark, work to develop KPIs that make sense to compare against one another. You are more likely to promote KPIs that are measured. KPIs will drive priorities - sometimes to the detriment of other things that are not being measured. It is important to select clear, relevant KPIs that are going to foster related benefits. </p> <p>You will use these KPIs and scores in the Optimize phase to utilize trending and conduct variance analysis. You will also assess performance over time since this is just as important as the numbers. Additionally, be sure to save and consistently evaluate behavior trends.</p> <p>Different benchmarks will measure the performance of different teams. Asking whether the FinOps team is performing well is a very different question than whether your engineering, architecture, or migration team is performing well.</p>"},{"location":"02_finops/01_finops_practitioner/#examples_1","title":"Examples","text":"<ul> <li> <p>Cost/Compute Hour Trend: Measures team against itself over time, compare against any team</p> </li> <li> <p>Consistent Compute Use Coverage Rate: Measures the performance of the FinOps team in buying commitment based discounts</p> </li> <li> <p>Recommended Optimization Savings/Total Cost Trend: Could measure each team or the architecture team in bringing in more scalable architectures or using spot</p> </li> </ul> <p></p> <p>Be sure not to over do it. You cannot benchmark with others until you understand your usage and have common language to communicate (FinOps). </p>"},{"location":"02_finops/01_finops_practitioner/#cost-allocation","title":"Cost Allocation","text":"<p>Cost allocation (or cost attribution) is the most important thing you will do as someone involved in FinOps. In order for anyone in the organization to adhere to the principle: \"Everyone is responsible for their cloud usage,\" they must know what they are spending. Further, to know what value we are getting from spend, we must be able to identify the costs associated with delivering that value. We perform cost allocation so we can produce these reports for the users of cloud. This reporting is usually one of two types: showback or chargeback. </p>"},{"location":"02_finops/01_finops_practitioner/#showback","title":"Showback","text":"<p>Showback reports are reports that use cost allocation mechanisms to show a team what they are using and spending.</p> <p></p> <ul> <li>These reports can be done at any level (what we\u2019re spending on compute across all applications, what we\u2019re spending on storage within this one microservice, what we\u2019re spending on network only in Azure, etc.)</li> <li>These reports are not mutually exclusive of one another</li> <li>They are designed to be informative and to be helpful to cloud users to understand usage and take actions to be responsible for its efficiency and effectiveness</li> <li>They are not entered into an accounting system, or general ledger. Rather, they are informational and designed to promote transparency and drive behavior</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#chargeback","title":"Chargeback","text":"<p>Chargeback reports are given to the accounting system and applied against an official budget the organization is tracking.</p> <p></p> <ul> <li>These reports are created for a specific P&amp;L or budget owner</li> <li>They are likely mutually exclusive (add them all up and that\u2019s all your cloud spend)</li> <li>They are designed to create debits against established budgets in the accounting system</li> </ul> <p>Chargeback reports may be the exact same report as a showback report, but they are official budget reports. You can have less mature and more mature versions of each (maybe your reports have shared costs, maybe they have blended rates, maybe they have indirect allocations, maybe they don\u2019t). Because these are similar, they can be produced similarly, but it is likely you will do showback for more groups.</p> <p>Chargeback reporting will face much more scrutiny. Making changes to charges in the accounting system can be difficult, or require documentation. Particularly, shared charges outside of a P&amp;L owner\u2019s control will face more scrutiny. Some organizations require SOC compliance testing of chargeback reporting. You will want to save and preserve your chargeback reporting more than showback reporting which can be more short-lived. This may affect the tooling or process you use. </p>"},{"location":"02_finops/01_finops_practitioner/#why-choose-a-model","title":"Why Choose a Model","text":""},{"location":"02_finops/01_finops_practitioner/#start-off-budgeting-centrally","title":"Start off Budgeting Centrally","text":"<p>Companies adopting cloud slowly may start off budgeting for \u201ccloud\u201d centrally</p> <ul> <li>It is easier</li> <li>It is unknown how costs will divide out at first</li> <li>It allows for flexibility and innovation, especially during the \u201cscience fair project\u201d phase</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#showbackchargeback","title":"Showback/Chargeback","text":"<p>Showback/Chargeback comes later with</p> <ul> <li>More shared cost items and complexity in the cloud environment</li> <li>Better predictability</li> <li>More scale making cloud costs material</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#chargeback-records-costs-when","title":"Chargeback records costs when...","text":"<p>Chargeback records costs in the accounting system when:</p> <ul> <li> <p>It is necessary </p> <ul> <li>Multinationals with different tax treatment</li> <li>Multi Business Unit who want to keep units very separate (e.g. high M&amp;A)</li> <li>Highly regulated or governmental requirements</li> </ul> </li> <li> <p>Have to account for changes after the fact (billing data sometimes shows up late)</p> <ul> <li>This is more complex operationally for finance/accounting teams</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#historically","title":"Historically","text":"<p>Chargeback may not typically be done in the traditional data center IT. Sunk costs are rarely billed or tracked for efficient use. The money was already out the door, outside of the P&amp;L owner\u2019s control, and did not change month-to-month. If chargeback was being done, it was likely done in the accounting system only and not in the reporting shown to those actually working on the applications.</p> <p>Unlike the data center, cloud cost can change and be tracked more easily and should be managed daily. Ideally, all direct and indirect costs should be allocated to the cost center budgeting for them.</p> <p></p> <p>Crawl Split the invoice up</p> <p>Walk Generate reports of direct costs with amortization of commiment based discounts</p> <p>Run Direct and shared costs, amortization is tied to business results of each cost center</p>"},{"location":"02_finops/01_finops_practitioner/#managing-shared-costs_1","title":"Managing Shared Costs","text":"<p>Try not to divide up shared costs unless you have to. If you have to divide up shared costs, do it in the simplest way that is feasible for your organization.</p>"},{"location":"02_finops/01_finops_practitioner/#managing-cost-sharing","title":"Managing Cost Sharing","text":""},{"location":"02_finops/01_finops_practitioner/#centrally-budget","title":"Centrally budget","text":"<ul> <li>Centrally budget and pay for shared costs without dividing (cheating here, but this is the easiest way)<ul> <li>We budget for security and compliance services separately, you as a P&amp;L owner don\u2019t worry about them</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#fixed-or-even-distribution","title":"Fixed or even distribution","text":"<ul> <li>Build a quick table of how much of the total each budget is going to pay<ul> <li>The SaaS product will pay 80% of the security and compliance costs, and the two other P&amp;L groups will pay 10% each</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#proportional","title":"Proportional","text":"<ul> <li>Cost is split based on the spending of each budget on some other item<ul> <li>We\u2019ll split the Enterprise support cost based on total spend in your direct allocated accounts that month, you get the proportion that your total spend represents</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#direct-allocation","title":"Direct Allocation","text":"<ul> <li>Cost is allocated based on tracking usage of some other non-cloud-bill data<ul> <li>We will pull in the Kubernetes cluster information which can identify which pods are being run by which application and we\u2019ll calculate total allocated resources by pod, then total by application, then figure out total cost of the environment, allocate to each application that cost, and allocate cost directly to each application\u2019s P&amp;L. Additionally, we\u2019ll have to distribute a percentage of vacant/unused container environment and we\u2019ll distribute that proportionally to the use of the overall container resources</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#resources_3","title":"Resources","text":"<p>Cost Allocation. Cost Allocation is the set of practices to divide up a consolidated invoice or bill among those who are responsible for its various component parts. In the context of FinOps this typically involves dividing up consolidated Cloud Service Provider invoices among various IT groups who use cloud within the organization. </p> <p>Data Analysis &amp; Showback. Data analysis and showback is the ability to leverage data, along with metadata on cloud resources and resource hierarchies, to create a near \u201creal time\u201d reporting mechanism for stakeholders which calls to attention: total costs for the desired business entity, opportunities for cost avoidance, and KPIs for financial health (e.g. performance of rate reduction commitments, unit cost measures for key services, efficiency metrics aggregated by desired \u201cteam\u201d, organizational unit, etc\u2026). </p> <p>Fair Cost Allocation in a Shared Platform. This article provides a look into the setup, goals and story of fair cost allocation in a shared platform. </p>"},{"location":"02_finops/01_finops_practitioner/#accounts-taxonomy-and-tags","title":"Accounts, Taxonomy, and Tags","text":"<p>Now that we know what Showback and Chargeback are, how do we produce reporting from our massive pile of cloud data?  We will use various cost allocation/attribution techniques involving:</p> <ul> <li>A meaningful structure/taxonomy of identifiers and metadata that allows us to meaningfully divide up our costs. This is very specific to your business: What do you call things? What do you call your divisions? Your cost centers? Your departments? Your P&amp;L segments? etc. </li> <li>AWS Accounts / Azure Subscriptions or Resource Groups / GCP Projects are the building blocks of organization in each of the cloud providers which are required and provide a concrete boundary of cost (and other things)</li> <li>Tags, labels, and other metadata are used to apply and associate the taxonomy values with the resources or resource hierarchy you are actually running</li> </ul> <p>You will use a combination of all of these structures/methods to accomplish your cost allocation task. </p>"},{"location":"02_finops/01_finops_practitioner/#terms_1","title":"Terms","text":"<p>Within the FinOps Foundation, we are vendor neutral, so we use generic terms for some of these things. In the rest of this lesson, \"account\" will be used to represent the resource hierarchy and \"tags\" will be used to represent cost allocation metadata.</p> Generic Term Specific Terms Resource Hierarchy accounts, subscriptions, account groups, projects, folders Cost Allocation Metadata metadata, tags, labels"},{"location":"02_finops/01_finops_practitioner/#methods","title":"Methods","text":"<p>Organizations often choose to allocate costs primarily by account, especially at first, because it is easy for everyone to understand. Every cost shows up in an account, even resources that can\u2019t be tagged. </p> <p>Eventually there will be accounts which are used for multiple purposes. Then you will need to tag things. In many cases you can tag the resource hierarchy too. In tagging individual resources you identify them in ways you will use to filter showback, chargeback, and ad hoc reporting later.</p> <p>You may not define your entire resource hierarchy plan and metadata strategy up front. You can take time and evolve these as you go. Remember, you aren\u2019t the only stakeholder here, CCOE, Platform, Engineering, Security, etc. They all have an interest in hierarchy and metadata.</p> <p>Account-based allocation is the most powerful method of dividing costs. Azure Management Groups, AWS Organizations, and multi-layered GCP folders make this even easier to manage. How is your taxonomy broken up? </p>"},{"location":"02_finops/01_finops_practitioner/#tags-and-labels","title":"Tags and Labels","text":"<p>Tags or labels used for cost allocation may need to be enabled or you may need to grant access to them to use them in downstream reporting (Cost Allocation Tags in AWS, IAM permissions required to view labels in GCP, etc.). Or, you may need to create or augment your cloud usage and cost data with third party tools or other data sets you have available within your organization (i.e. a CMDB of cost centers and their owners). Click each information icon below to learn more.</p>"},{"location":"02_finops/01_finops_practitioner/#resource-level","title":"Resource Level","text":"<p>Tag an instance,databese, connector, app ID, etc</p>"},{"location":"02_finops/01_finops_practitioner/#account-level","title":"Account Level","text":"<p>Everything in this account, resource, environment group goes to cost center xxx</p>"},{"location":"02_finops/01_finops_practitioner/#business-rule","title":"Business Rule","text":"<p>If a resource is tagged, put in the cost center it's tagged with. Otherwise, make it the cost center of the account it's in.</p> <p>Any GuardDuty or Cloudwatch charges go to the central IT cost center but other costs go to the team cost centers. If one of these services is used, tag it with a \"Data Services\" Service Category tag.</p> <p>Business rule tags typically do not live in the billing data from the cloud provider.</p>"},{"location":"02_finops/01_finops_practitioner/#activity_1","title":"Activity","text":"<p>There are lots and lots of tags; too many is just as debilitating as too few. While tags are needed for lots of reasons (operational, development, financial, team management, etc.), FinOps is interested specifically in the tags that allow us to allocate costs consistent with the company\u2019s needs. Tags can be at the resource level, at the group of resource level, at the account level, or at the synthetic level (applied after the billing is done). Certain tags are appropriate for each level. </p>"},{"location":"02_finops/01_finops_practitioner/#there-are-some-things-that-are-untaggable","title":"There are some things that are untaggable.","text":"<ul> <li>Cloud vendors are constantly adding things, but also releasing things that aren\u2019t taggable</li> <li>Some things have taggable bits and untaggable bits (data charges associated with an EC2 instance)</li> <li>Some things are only taggable after you create them </li> <li>Some things are only taggable through the SDK/API/CLI not through the console</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#tag-compliance-will-hit-everyone-sometime-or-another","title":"Tag compliance will hit everyone sometime or another.","text":"<ul> <li>Measure tag compliance by cost, not items or instances</li> <li>You will be in a good place if you get 99% of cost tagged</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#forecasting-budgeting","title":"Forecasting &amp; Budgeting","text":"<p>Forecasting is one of the greatest challenges of cloud. There are many unknowns. Traditionally 80% of IT cost was fixed, mostly depreciation. Therefore, if you were 100% wrong in your variable estimates, you were at most 20% variant from budget. Now, 80% of your IT costs are variable. If you\u2019re 50% wrong, you\u2019re 40% variant!</p> <p></p> <p>Crawl - Forecast based on manual estimates or last year plus models</p> <p>Walk - Forecast based on past usage at an application or an environment scale</p> <p>Run - Granular forecasting by service with daily tracking and updating to actuals, including discounts, amortization, and shared cost</p> <p>Budgeting is underrated. Budgets do not have to be official budgets. You can establish \"rule of thumb budgets\" for each team/view where someone is responsible for spending, set alert thresholds for alerts, and know what your daily/weekly/monthly spend patterns are. This will create a basis for your estimating going forward. You will get better at budgeting if you do it weekly and assess your results. Forecasting and budgeting are skills like any others. Practice now before the annual budget cycle so you get a feel for it and start to build your skills. </p>"},{"location":"02_finops/01_finops_practitioner/#resources_4","title":"Resources","text":"<p>Forecasting Forecasting is the practice of predicting future spending, usually based on a combination of historical spending and an evaluation of future plans, understanding how future cloud infrastructure and application lifecycle changes may impact current budgets and influence budget planning and future cloud investment decisions. # Optimize Phase Overview</p>"},{"location":"02_finops/01_finops_practitioner/#recap_2","title":"Recap","text":"<p>Now that we've learned about exercising all of the capabilities and understanding our use and spending in the Inform phase, let's look at opportunities to optimize. This could look like optimizing usage, cost profile, coverage, automation, or even level of visibility.</p>"},{"location":"02_finops/01_finops_practitioner/#optimize-phase","title":"Optimize Phase","text":"<p>In the Optimize phase we target, define, and document optimization opportunities; this is all about triage and prioritization.</p>"},{"location":"02_finops/01_finops_practitioner/#the-optimize-phase-supports-the-principles","title":"The Optimize phase supports the principles:","text":"<ul> <li>Business value of cloud drives decisions</li> <li>A centralized team drives FinOps</li> <li>Take advantage of the variable cost model of the cloud</li> </ul> <p>### During the Optimize phase, we're looking to see:</p> <ul> <li>Are we doing enough?</li> <li>Is each of these capabilities mature enough?</li> <li>Are we making progress toward our goals?</li> <li>Do we know enough to make good progress?</li> </ul> <p></p>"},{"location":"02_finops/01_finops_practitioner/#the-majority-of-the-capabilities-we-will-use-to-accomplish-the-optimize-phase-are-in-the-domains","title":"The majority of the capabilities we will use to accomplish the Optimize phase are in the domains:","text":"<ul> <li>All of the domains and capabilities will come into play in this phase</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#the-optimize-phase-is-all-about-identifying-opportunities","title":"The Optimize phase is all about identifying opportunities:","text":"<ul> <li>To do FinOps better</li> <li>To understand usage better</li> <li>To improve usage (do more where valuable, do less where valuable)</li> <li>To improve rates </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#kpis-outcomes","title":"KPIs &amp; Outcomes","text":"<p>In order to drive the rest of the work you will do in the Optimize phase we need to know:</p> <ul> <li>What outcomes are expected by the business? </li> <li>What Key Performance Indicators (KPIs) will our business use to measure success?</li> </ul> <p>Your organization may already have defined KPIs related to cloud use or to IT use in general. If not, you may need to take a look at what outcomes you are trying to achieve with cloud:  </p> <ul> <li>What behavior will help achieve those outcomes?</li> <li>How you can measure or determine that you are accomplishing that work?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#defining-kpi-challenges","title":"Defining KPI Challenges","text":"<p>Defining good KPIs for cloud use can be challenging  because cloud use is new to many teams and  because there is so much to measure and so much data to measure it with. </p>"},{"location":"02_finops/01_finops_practitioner/#sample-kpis","title":"Sample KPI's","text":"<p>Examples of ways to measure each of the capabilities is found in the real-world resources section within each capability on FinOps.org</p> <ul> <li>Consider difference in reserved coverage rate when using cost versus usage</li> <li>Do you want to promote spot use? Or reserved use? Or total?</li> <li>Do KPIs measure the performance of the FinOps team or the development teams?</li> <li>Reservation coverage rate (cost or usage)</li> <li>Reservation utilization rate </li> <li>Optimization opportunities as a percent of spending</li> <li>Spot/preemptible/low priority as a percent of compute</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#incremental-goals-and-targets","title":"Incremental Goals and Targets","text":"<p>As you perform the Optimize phase, do so with an eye toward taking steps to improve KPIs or achieve the outcomes you have defined. Remember, you do not have to achieve the outcomes in one step, think incrementally. Make your immediate term goals and targets achievable, actionable, and clear. Revisit these goals each time you move through the FinOps lifecycle.</p> <ul> <li>What were we trying to achieve last time?</li> <li>Did we achieve it by doing what we did?<ul> <li>Yes. Then more of that, please.</li> <li>No. Then, do we need to act with more scale? Less scale? Different action?</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#example","title":"Example","text":"<p>We have an OKR (Objective and Key Results) of having a highly rate optimized cloud environment for all production systems. We have established a KPI to measure this: discount percentage for consistent-use, production compute workloads - which we would like to achieve and sustain at 50%.</p> <p>This means we would like our average discount to be 50% for all of our consistently running production compute instances. Some will be covered by three-year savings plans, some compute, some EC2, some will be covered by one-year savings plans, and some will be paid on demand. All of these are providing different rates of savings for various resources, and of course, our workload mix and total demand is changing/growing over time as well. </p>"},{"location":"02_finops/01_finops_practitioner/#expectations","title":"Expectations","text":"<p>It is unreasonable to expect to go from the time we establish this KPI to meeting it in one cycle. </p> <ul> <li>First, we don\u2019t want to buy all of our reservation at once, we want to buy them incrementally over time</li> <li>Second, we don\u2019t want to make too large a bet at any one time, we want to watch trending over time and take small incremental actions</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#goal-setting","title":"Goal Setting","text":"<p>As a goal during this cycle in the Optimize phase, we may want to look to improve this KPI from where it is now to something slightly better. Perhaps we\u2019re currently at 32%. To make it better we have to consider several things:</p> <ul> <li>Cover more resources that are currently at 0% discount</li> <li>Cover resources currently getting lower discount coverage with higher discount options</li> <li>We have the option to purchase some or all of our recommended purchases of discount options</li> <li>What do we do?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#taking-action","title":"Taking Action","text":"<p>Once we have a plan of what we would like to accomplish, we look at options, and attempt to not only identify what incremental step we take now, but what effect we expect it will have.</p> <p>If we take that step, we can then, in the next loop through the lifecycle, look at the impact we actually had and determine if our estimations were correct. This will give us more information about how our actions impact our KPIs and give us a better understanding of what to do next time.</p> <p>By taking small steps we are passing up some potential savings, but in the long run, our incremental improvement approach and the confidence created by this approach, will pay larger dividends.</p>"},{"location":"02_finops/01_finops_practitioner/#monitoring","title":"Monitoring","text":"<p>We will put our goals and opportunities into a tracking system.</p> <ul> <li>For Agile, create a backlog of items to address</li> <li>Create visibility into how we are doing, what we are working on, and how we are prioritizing</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#defining-good-goals","title":"Defining Good Goals","text":"<p>The first goal of any optimization effort should be good cost allocation. Without a full understanding of all of the costs, optimization will aim off target. Cost savings can be a goal - just not the only, or most important, goal. Be sure to express cost savings in ways that allow for flexibility (the model of the cloud).</p> <p></p> <p>Remember the iron triangle. The goal is to make value-based decisions knowing that trade offs between cost, speed, and quality are required.</p>"},{"location":"02_finops/01_finops_practitioner/#resources_5","title":"Resources","text":"<p>KPIs See a list of common KPIs. Learn More</p>"},{"location":"02_finops/01_finops_practitioner/#primary-ways-to-optimize-usage","title":"Primary Ways to Optimize Usage","text":""},{"location":"02_finops/01_finops_practitioner/#workload-management","title":"Workload Management","text":"<p>The first primary way you can optimize usage is through workload management. This means turning things on only when you need them. A central FinOps team, as well as utilizing automation, can help make this easier. Note that this is not appropriate for all workloads. </p> <p></p> <p>Crawl - Manually turn off resources when idle</p> <p>Walk - Schedule an automated off of resources when idle</p> <p>Run - Identify and auto-terminate idle resources</p>"},{"location":"02_finops/01_finops_practitioner/#scalability-and-elasticity","title":"Scalability and Elasticity","text":"<p>Another way to optimize your usage is by introducing scalability or elasticity. The idea is to use a number of smaller resources to accomplish a task or support a workload such that as the demands of that workload vary over time, the number of small resources can be adjusted. Scalability and elasticity is a function of the architecture of the systems running in the cloud. Architecture teams, development teams, and platform teams should look for ways to accomplish this by incorporating scalable architecture choices as early as possible and completing involved re-architecting.</p>"},{"location":"02_finops/01_finops_practitioner/#examples_2","title":"Examples","text":"<ul> <li>Microservice architectures are ones where the end user app or website are made up of many smaller services each of which provides a piece of what the user sees. Because each can be scaled and developed separately this provides the ability to serve the webpage by having all sections generating their content at once on separate machines</li> <li>Stateless compute instances. These don\u2019t need to handle a long series of transactions in a particular order, but can just work on atomic transactions, and can be used instead of stateful process servers which must wait around for long sequences to finish (or for very slow humans to respond) by using queueing techniques or developing what are called loosely coupled architectures</li> <li>Serverless architectures bypass many of the scalability challenges by only calling on compute resources when there is actual demand, and having each individual call its own resources to run</li> <li>Container-based applications are often built to scale horizontally, adding capacity as it becomes necessary </li> <li>Basic websites often have what\u2019s called a three-tiered architecture where the front-end servers that users connect to can be stateless and can be reached via a \u201cload balancer\u201d which allows multiple front end web servers to work together to handle the load. The number of these can be adjusted for actual or anticipated demand</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#rightsizing","title":"Rightsizing","text":"<p>Rightsizing always has to be approached as a collaborative effort. The centralized FinOps team cannot do this alone and will need to: ask for help, talk, discuss, agree, and then build a business case. The FinOps team should talk about opportunities with other teams regularly, not just when there\u2019s a \u201cproblem.\" Additionally, the FinOps team will need to collaborate with the architecture team to build a working relationships and stay informed about about planned changes. </p> <p>It is as important to confirm good workload match as it is to identify change opportunities!</p>"},{"location":"02_finops/01_finops_practitioner/#getting-started_1","title":"Getting Started","text":"<p>Where to start?</p> <ul> <li>Unattached and idle resources (find and remove underutilized resources)</li> <li>Storage types and classes (rightsizing, management plan)</li> <li>Ultra low utilization (rightsizing)</li> <li>Old generation instances (modernization)</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#cadence","title":"Cadence","text":"<p>Maintain a monthly cadence with development teams.</p> <ul> <li>Identify opportunities for rightsizing throughout the month</li> <li>Everyone should look for rightsizing opportunities</li> <li>Maintain regular cadence with architecture and platform teams <ul> <li>Planned architecture changes / platform changes</li> <li>Verify continued use of services and resources, watch out for trials and tests</li> </ul> </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#rightsizing-versus-commitment-based-discounts","title":"Rightsizing Versus Commitment Based Discounts","text":"<p>Optimization and commitment purchasing are two sides of the same coin. We will want to create loose ties and checks as we do both.  * Be sure not to commit to resources you might rightsize  * Be sure not to rightsize without checking what you are already committed to using</p> <p>We will perform both sets of activities on their own cadence. Include touchpoints with the other process at key decision points and prior to detailed analysis. The FinOps team can give development teams timely information for them to take action while allowing them to work optimization into their sprint.</p> <p></p> <p>## Optimize Usage</p>"},{"location":"02_finops/01_finops_practitioner/#candidates-for-optimization","title":"Candidates for Optimization","text":"<p>In the Optimize phase is where you will identify optimization opportunities. Look for a mix of easy wins and harder elements. It will become tougher as you become more advanced (fewer easy wins, better team usage). You will want to do a combination of all items listed below as you go through your work.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#examples_3","title":"Examples","text":"<p>This is a potential list of optimization opportunities. They are more or less in order of difficulty. Some of these are slightly more concrete examples of optimization opportunities you could go after. </p> <p></p> <ul> <li>Turn off/turn on development, test, sandbox environments</li> <li>Create/manage storage policies to deprecate storage over time to cheaper tiers</li> <li>Rightsize compute, databases, networks, environments </li> <li>Change from 3rd party licensed resources to cloud native resources</li> <li>Modernize resources</li> <li>Service substitution (or license substitution)</li> <li>Mature your DevOps approach </li> <li>Move to/expand use of containers</li> <li>Move to serverless</li> </ul> <p>Based on what you are seeing in your Inform phase, your FinOps team might create such a list of optimization opportunities as a triage or brainstorming exercise. With each opportunity ask the following questions:</p> <ul> <li>What is the value of each of these? </li> <li>What is the effort required?</li> <li>Which are reasonable to consider for the Operate phase?</li> <li>Who would we need to talk to to get all these answers?</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#optimize-rates","title":"Optimize Rates","text":"<p>Optimizing rates is the job of the central team (FinOps principle). Committed based discount purchasing, like reserved instances, savings plans, CUDs are the main focus here.</p>"},{"location":"02_finops/01_finops_practitioner/#discounting","title":"Discounting","text":"<p>Although the specifics can vary greatly by vendor and service, discounting in general is similar regardless of vendor or type. Commitment to the cloud provider \u2013 in terms of dollars, time, and details \u2013 will get you discounts. The more specific, the larger, or the longer your commitments, the more you can generally save.</p> <p>\"discount types</p> <p>Cloud providers discount because they want predictability (the same as private data centers, but with more scale). Because you are committing to pay, you are by definition giving up flexibility that on-demand service usage offers. The other way to think about this is the cloud providers are buying your flexibility. Despite the fact that this is scary, do not wait. Constantly work on getting discounts. </p>"},{"location":"02_finops/01_finops_practitioner/#before-you-commit","title":"Before you Commit","text":"<p>Cloud providers are experts at discounting. So, before you commit, be able to forecast your demand and understand what commitments you can live with.</p> <p>You do not need to get the highest discount ever (Crawl Walk Run applies here too). If you can only forecast a total spend number over the next year, take a 15% discount over nothing. If you can forecast that you will use a particular instance family in a particular region for three years, go for the 74% off. Also, mix up what you buy and how you negotiate.</p>"},{"location":"02_finops/01_finops_practitioner/#how-to-optimize","title":"How to Optimize","text":"<p>What discounts you buy and how you buy them will impact the tools you need to have in place. How would you optimize?</p> <ul> <li>Primarily through procurement for negotiated discounts</li> <li>If you have enterprise agreements for licenses or other contracts, handle like that and spend an appropriate amount of time given the scale of your spending</li> <li>You can\u2019t optimize much in time-based or usage based discounts</li> <li>It is important to know what discounts are happening so you can use them in any other arrangements</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#discounting-decisions","title":"Discounting Decisions","text":"<p>When looking for discounts, whether it\u2019s negotiated, tiered, or commitment based discounts, you have several decisions to make. </p> <ol> <li>Are you willing to pay upfront? This is increasingly not beneficial, but still gets you a 10% bump in discount if that works with your internal cost of capital. If you pay up front, where will that money come from? How will it be recovered by those who provide it? </li> <li>How will you collect, recognize, and apply the discounts when they come in?</li> <li>Will you show discounts to your engineers or others responsible for cloud costs?</li> </ol>"},{"location":"02_finops/01_finops_practitioner/#commitment-based-discounts","title":"Commitment-Based Discounts","text":"<p>RIs, savings plans, and committed use discounts are commitments to use a certain type of resource (maybe in a certain place or of a certain type), or to spend a certain amount of money (over a period of one or three years, every hour of every day). </p>"},{"location":"02_finops/01_finops_practitioner/#examples_4","title":"Examples","text":"<ul> <li>Reserved Instances (RIs)</li> <li>Committed Use Discounts (CUDs)</li> <li>Capacity Reservations</li> <li>Savings Plans</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#features","title":"Features","text":"<ul> <li>Like coupons, not actual resources</li> <li>1-year or 3-year</li> <li>17-75% discounts</li> <li>The less flexible they are, the bigger the discount</li> <li>Up-front payments or monthly </li> <li>ocation, instance family, size, tenancy decisions</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#discount-purchasing","title":"Discount Purchasing","text":"<p>Managing discounts is complex and there are a lot of decisions to make. That is one reason we recommend managing centrally with input from finance (your cost of money) and technology groups (your future usage) to inform decisions.</p> <p>Discounts are complex to figure out correctly and maintain well. It may be best to have a person on your team who knows all the options you have, inside and out. Then, have someone else learn from that person. </p> <p>When you own these discounts they will apply against running resources your engineering team launches. This is why we have to be sure they will continue to use them. There is no indication that a resource is covered when you stop using it (coverage will apply randomly across your whole cloud estate). </p>"},{"location":"02_finops/01_finops_practitioner/#spot-market","title":"Spot Market","text":"<p>Spot Market available on all three major CSPs:</p> <ul> <li>AWS Spot Instances</li> <li>GCP has Preemptible and Spot VMs</li> <li>Azure Low Priority VMs, Spot VMs</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#benefits","title":"Benefits","text":"<ul> <li>Provides \u201cspare\u201d capacity for sale at deep discounts</li> <li>Many limitations and restrictions on use</li> <li>Can be pulled at any time on very short notice</li> <li>Usually priced 70-91% lower than on-demand rates</li> <li>Not appropriate for all workloads</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#limitations","title":"Limitations","text":"<ul> <li>VMs can be recalled within 30 seconds or 2 minutes.</li> <li>The FinOps team cannot implement this itself</li> <li>Challenge teams and architects to find uses for spot if you use AWS. Cost savings can be a game changer if you can deal with the volatility</li> <li>You can attach EBS volumes to spot instances and allow them hibernate, or turn them off based on price changes or preemption</li> <li>Many more uses means discount will probably decrease because more are in \u201dnormal\u201d use</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#applications","title":"Applications","text":"<ul> <li>Dev boxes, test boxes, trials, short-cycle jobs, stateless taskers</li> <li>More and more services in AWS are starting to allow the use of Spot (e.g. Sagemaker, ECS Fargate, etc.)</li> <li>Applications can include Jenkins, batch things, even K8s when managed correctly</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#business-cases","title":"Business Cases","text":"<p>Never bring a business case to a discussion fight.</p>"},{"location":"02_finops/01_finops_practitioner/#business-cases_1","title":"Business Cases","text":"<p>Don\u2019t spend too much time on a business case until you know that time will be valuable. The amount of data needed to build a business case around an opportunity can be tremendous.  Business cases should: </p> <ul> <li>Be as simple, clear, and concise as possible</li> <li>Have something for everyone (business, technology, finance)</li> <li>Use measurable, achievable, and actionable goals/targets</li> <li>Be agreed upon before drafting the details</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#business-case-cadence","title":"Business Case Cadence","text":"<ol> <li>Gather Reports \u2013 Pull together the information needed to flesh out the opportunity.</li> <li>Analyze \u2013 Evaluate the data; look at options and different parameters. This could be things like: what terms to use for an RI purchase, what instance types should be the focus of a round of rightsizing, or what old instance types are the focus of upgrading. Figure out what you want to achieve with the action.</li> <li>Document \u2013 Write down your decisions, your rationale, your thought process, approvals, etc. and save it in an appropriate repository for your organization.# Operate Phase</li> </ol>"},{"location":"02_finops/01_finops_practitioner/#operate-phase-overview","title":"Operate Phase Overview","text":""},{"location":"02_finops/01_finops_practitioner/#recap_3","title":"Recap","text":"<p>Remember, you\u2019re moving to the cloud, overcoming challenges by applying FinOps principles and exercising the FinOps capabilities with your FinOps team, as well as considering everyone\u2019s motivations and each group\u2019s goals. As you exercise the FinOps lifecycle, you\u2019ve looked at how you are using cloud in the Inform phase. You\u2019ve looked at many opportunities for optimization in the Optimize phase. What is next?</p>"},{"location":"02_finops/01_finops_practitioner/#operate-phase","title":"Operate Phase","text":"<p>The Operate phase is where we take action to achieve goals and the company\u2019s internal processes are engaged. The challenge of this phase is taking care of business, actually getting things done, then seeing the impact as we re-enter the Inform phase.</p> <p></p> <p>In this phase, the business may:</p> <ul> <li>Perform an optimization plan or put it on the backlog</li> <li>Not implement the plan</li> <li>Determine the plan is infeasible to action - minimize</li> </ul> <p>The Operate phase is much more about your business than it is about the cloud. This is where you will create the culture and the integration to the persona stakeholders who will drive value out of your cloud spend. You will spend a lot of time defining process, defining workflows, and defining responsibilities. </p> <p></p> <p>Meet stakeholders where they are:</p> <ul> <li>Keep them informed</li> <li>Present them with optimization opportunities</li> <li>Help them put the opportunities into operation</li> </ul> <p>The Operate phase supports the principles:</p> <ul> <li>Teams need to collaborate</li> <li>Business value of the cloud drives decisions</li> <li>Take advantage of the variable cost model of the cloud</li> </ul> <p></p>"},{"location":"02_finops/01_finops_practitioner/#aligning-teams","title":"Aligning Teams","text":"<p>The Operate phase is where the rubber meets the road. It is where the technical work of identifying optimization opportunities has to be enacted in your organization.</p> <p>How do we get teams to actually make these changes, adopt FinOps, and take on responsibilities?</p> <ul> <li>By aligning goals</li> <li>Utilizing FinOps team members' influence in their organizations</li> <li>Build credibility and trust through small wins</li> <li>Take all costs into account</li> <li>Consider using a Challenger Sale approach internally to become a help to your teams</li> <li>Create a bias for action (where taking action is your default state)</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#communications","title":"Communications","text":"<p>Communications in a FinOps culture is of paramount importance. In order to align teams, you must communicate with them effectively. </p> <p></p> <p>How will you:</p> <ul> <li>Get the word out</li> <li>Message effectively</li> <li>Develop training programs</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#examples_5","title":"Examples","text":"<ul> <li>Put information in the path of engineers (and others): utilize dashboards, meet them where they work (Slack, Confluence, JIRA, Teams), through product design tools </li> <li>Integrate with training systems used by your company</li> <li>Develop a training program with internal and external speakers</li> <li>Attend FinOps events</li> <li>Speak at business conferences about FinOps in your company</li> <li>Invite and include your vendors and cloud providers to speak on specific topics</li> <li>Ensure consistent and clear communication</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#engineers-taking-action","title":"Engineers Taking Action","text":"<p>One of the top challenges shown in the State of FinOps data(opens in a new tab) has been getting engineers to take action (working with engineers taking action), etc. Let\u2019s agree: engineers are the ones taking action and we need to be involved.</p>"},{"location":"02_finops/01_finops_practitioner/#metrics-driven-cost-optimization","title":"Metrics Driven Cost Optimization","text":""},{"location":"02_finops/01_finops_practitioner/#containers-shared-environments","title":"Containers &amp; Shared Environments","text":"<p>Containers are another layer of abstraction that allows you to use the variable cost, variable usage model to gain advantage (in addition to other technical advantages of containers for some applications).</p> <p>Container technology is similar to cloud five years ago: new terminology, new concepts, but also rapidly maturing and standardizing. You need to understand your fully-loaded costs, tag appropriately, chargeback, optimize, and align to business. </p> <p>Special care is needed to get the right Inform phase data from container environments like GKE, EKS, AKS. However, the process is the same as getting variable cost/use data from the cloud. </p> <ul> <li>You need to tag</li> <li>You need an allocation strategy</li> <li>You need good reporting</li> <li>You need to plan how to optimize, etc. </li> </ul>"},{"location":"02_finops/01_finops_practitioner/#resources_6","title":"Resources","text":"<p>Calculating Container Costs Addressing how and why containers complicate how teams manage the visibility and optimization of container costs, and how to apply FinOps best practices to improve cloud financial management.</p> <p>State of FinOps Data Last year, practitioners ranked their FinOps challenges and we took charge in creating projects, training, and content to help them master FinOps fundamentals. </p>"},{"location":"02_finops/01_finops_practitioner/#finops-and-other-methodologies","title":"FinOps and Other Methodologies","text":"<p>FinOps is closely related to several other methodologies that may be in use at your company. You can create awareness by drawing distinctions or highlighting similarities with users of those methodologies. A FinOps practice can find affinity with practice of other similar methodologies, value in working together, and using each other for support. Vendors, consultants, developers, and security teams may all be sources of partnership for your FinOps Team. Use all the resources at your disposal!</p>"},{"location":"02_finops/01_finops_practitioner/#finops-agile-and-devops","title":"FinOps, Agile, and DevOps","text":"<p>The FinOps lifecycle has many conceptual similarities to other methodologies that will be discussed or actually be in use. The most commonly encountered will be DevOps, Agile, and perhaps other concepts such as CI/CD Pipeline. It will be important in conversations with cloud stakeholders to understand enough about these complementary methodologies and how they relate to FinOps.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#azure-cloud-adoption-framework","title":"Azure Cloud Adoption Framework","text":"<p>Azure has a cloud adoption framework. In building out your FinOps team, consider your TAMs and the other vendor resources they can bring to bear (for money or for free). They will use this language when they talk to you, so become familiar with your vendor\u2019s cloud adoption framework and get your money\u2019s worth out of their help.</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#google-cloud-center-of-excellence","title":"Google Cloud Center of Excellence","text":"<p>Google has created a Cloud Adoption Framework for thinking about the various aspects of cloud use. Various other organizations also promote Cloud Center of Excellence as a catchall phrase to group things that help companies adopt and promote cloud use. Google's Cloud Center of Excellence focuses on much more than FinOps, including other aspects of cloud control such as governance, security, strategy, and cloud technical competence. However, it also has many similarities to FinOps such as collaboration, clarity and transparency, training, information sharing, and focus on business outcomes. </p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#aws-well-architected-framework","title":"AWS Well Architected Framework","text":"<p>This is how AWS looks at managing the architecture needs of cloud systems. FinOps addresses cost optimization but also has strong ties to other pillars. Be familiar with this framework as AWS cloud teams will use it.</p> <p>Increasingly companies are going with best of breed solutions in each pillar rather than one-tool-fits-all approaches (both to give them capability across cloud providers, and because they are increasingly outgrowing the MVP tools provided natively by the vendors).</p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#other-methodologies","title":"Other Methodologies","text":"<p>What do all these methodologies have in common with FinOps? None of them are the business of your company (most likely). All of them require work on the part of many people throughout the company. Security in particular, but all other disciplines also have this impact on the company that can be profound if not actioned. In many cases, these disciplines are also not very prescriptive, but more targeting for attention.</p> <p></p> <p>Be careful not to just wave red flags, but layout what actions could be taken to address the risks, cost optimization opportunities, unused licensing, etc. Licensing in particular should be called out as an area where some companies in the right circumstances can save large amounts of money (or spend large amounts) and if this is an area for you, your ITAM or SAM team should be engaged. # Maturing FinOps</p>"},{"location":"02_finops/01_finops_practitioner/#maturing-your-finops","title":"Maturing Your FinOps","text":"<p>One of the consequences of the change from building IT infrastructure to consuming IT infrastructure is that the job never ends. As you become more experienced in FinOps, you will find that there is so much left to learn. The challenges become more complex or varied; they can be brought on by changes in how your organization uses cloud, what services are available from cloud providers, and by the needs of your maturing organization and team. As a FinOps practitioner, you will be helping to drive the culture change your organization needs to get the most value out of your cloud use. This means your team will need to adapt over time as well.</p>"},{"location":"02_finops/01_finops_practitioner/#evolutionary-build","title":"Evolutionary Build","text":"<p>Dann Berg, the leader of the NYC meetup and FinOps Ambassador, talked about the evolution of his team at his last two companies as being an evolutionary build.</p> <p>At first, the team builds a visibility capability, then brings on someone to operationalize it. Learning and communications are next, the mechanisms are established and then someone steps in to carry it forward.</p> <p>Optimization activities that are important then get built and someone comes on to continue those activities. Over time, some of the earlier functions may become routine, established within the broader organization, or carried out by other teams. In the best cases, these earlier functions  become automated away or made obsolete by the good behavior of the organization. As new functions for the FinOps team are established, the team grows and changes to accommodate the new work.</p>"},{"location":"02_finops/01_finops_practitioner/#building-success","title":"Building Success","text":"<ul> <li>FinOps team leadership is critical to making the team successful</li> <li>No one knows all of the ins and outs of FinOps from a single engagement. Use your resources, like the FinOps Foundation, to provide edge cases and outside perspectives</li> <li>Regularly and routinely step back, look at how the FinOps team is fulfilling the principles and the organization\u2019s goals, then adjust</li> <li>Recognize that the team\u2019s jobs and functions will change, sometimes dramatically, over time. Hire and grow with a mix of people who are flexible, broadly skilled, curious problem solvers as well as operationally minded and who can promote change and development from the team</li> <li>You need to manage the FinOps team as a thing, the same way a marketing team needs to manage the team of people doing marketing and the marketing function\u2019s effectiveness. They are intertwined but distinct functions and there is merit in focusing on the value that having a FinOps team brings to the organization and then managing it, and managing what it delivers</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#achieving-results","title":"Achieving Results","text":"<p>The KPIs that the FinOps team is asked to deliver will also change over time. When an organization is first starting to do FinOps, the returns on work tend to be very large because there is a lot of inefficiency which can be addressed by taking fairly simple steps.</p> <p>Over time, the work that will be required increases \u2013 both the mechanics of doing the cost optimization and the number of people who will need to be involved in making the changes. The relatively large inefficiencies that once existed are now corrected, leaving smaller incremental improvements. However, without the consistent work of the FinOps team to promote efficiency, and the culture change to bring it on board, there can be a quick backslide into inefficient practices.</p> <p>Revisit the KPIs for the FinOps team as it evolves to make sure the value is aligned with what is being produced and the team is focused on the right things to create sustaining value for the organization.</p>"},{"location":"02_finops/01_finops_practitioner/#activity-elevator-pitch","title":"Activity: Elevator Pitch","text":"<p>Think about how you can incorporate what you\u2019ve learned in this course into your own work when you return. You\u2019re about to become a certified FinOps practitioner! When you meet your CIO and they ask \u201cWhat does this FinOps thing mean for us?\u201d What is your elevator pitch? What will you say?</p>"},{"location":"02_finops/01_finops_practitioner/#examples_6","title":"Examples","text":"<ul> <li>Cloud FinOps will enable us to drive business value/innovation for financial accountability through increased visibility and transparency as we better understand unit economics. This will help us to balance speed, cost and quality, and to make smart business decisions. Cloud FinOps also brings the business together to collaborate in the best interest of the business, working towards common goals, and building a common culture.</li> <li>FinOps helps us identify and drive value for cloud across the organization. With FinOps, we can improve our understanding of cost allocations and make informed decisions about tradeoffs. Further, using FinOps, we can drive alignment between IT, the business, and finance to ensure the best possible uses of our resources.</li> <li>FinOps is a cultural change that will transform the organization into one with robust and agile control over its cloud provisioning and spending.</li> <li>FinOps means cloud structure understanding and innovation to provide our organization with the direction we need to make improvements and provide more value to our teams and ultimately our customers.</li> </ul>"},{"location":"02_finops/01_finops_practitioner/#state-of-finops-data","title":"State of FinOps Data","text":"<p>As you mature your FinOps practice, you will face different challenges. At first, forecasting and adoption may be the top challenges. As you become more mature, getting engineers to take action will become more of an issue. As your maturity increases you will have overcome some of the early challenges and begin to work on more complex tasks around reducing waste and automation. </p> <p></p>"},{"location":"02_finops/01_finops_practitioner/#advice-from-the-field","title":"Advice from the Field","text":"<p>Patrick Brogan, Principal Product Manager, Cloud Business Operations (Wells Fargo)</p> <p>Dusty Bowling, Principal Engineer, Cloud Financial Management (SailPoint)</p>"},{"location":"02_finops/focp_questions/","title":"FOCP","text":"<ol> <li> <p>What term is used to describe the ability to identify and allocate costs to the appropriate cost categories in use by a customer?</p> <p>Cost Allocation</p> <p>In FinOps, the ability to identify and allocate costs to the appropriate cost categories in use by a customer. Ideally direct costs (the cost of resources running in my accounts), amortized costs (the amortization of prepaid costs paid upfront for RIs applied in my accounts), and shared costs (my share of common services accounts run by others on my behalf) can be allocated to individual budgeting categories for a clear view of the entire cost of running my application or workload in the cloud. Reference: Please review the terminology page before the exam https://www.finops.org/resources/terminology/ </p> </li> <li> <p>Each major cloud provider labels the platforms 'allocation metadata' a specific way. How does GCP name the allocation metadata?</p> <p>\"Labels\" and \"billing acounts\" Explicaci\u00f3n GCP( Google Cloud Platform)- \u201clabels\u201d and \u201cbilling accounts\u201d; GCP uses \u201clabels\u201d and \u201cbilling accounts\u201d; AWS \u201cresource tags\u201d, \u201cLinked Accounts\u201d and \u201cOrganizations\u201d; Azure \u201cSubscriptions\u201d, \u201cResource Groups\u201d and \u201cresource tags\u201d We do need to know some cloud provider specific terms for the exam. Refer here before the exam FinOps Terminology</p> </li> <li> <p>AWS provides what is called a 'Blended Rate' on its invoices. What is the blended rate showing?</p> <p>Shows the effective rate for a group of resources with the same attributes.</p> <p>AWS provides Blended Rate information on its invoice showing the effective rate for a group of resources with the same attributes where some of the resources are receiving a discount from reservations and some are not.</p> <p>Terminology is a critical knowledge area for the exam.</p> </li> <li> <p>Which of the following is NOT part of the FinOps Maturity Model?</p> <p>Sprint</p> <p>A \u201cCrawl, Walk, Run\u201d approach to performing FinOps enables organizations to start small, and grow in scale, scope and complexity as business value warrants maturing a functional activity. Taking quick action at a small scale and limited scope allows FinOps teams to assess the outcomes of their actions, and to gain insights into the value of taking further action in a larger, faster, or more granular way.</p> <p>Reference: Please review this page before the exam. FinOps Maturity Model</p> </li> <li> <p>'Establish FinOps Culture' would be under what domain according to the FinOps Foundation?     Organizational Alignment</p> <p>Explanation: There are six specific domains in FinOps according to the FinOps Foundation. We will want to be able to understand what topics are covered by each domain.</p> <p></p> </li> <li> <p>Multiple Selection:(Select two). Which of the following statements would be true regarding deploying Kubernetes clusters concerning cost complexity?     Generally organizations have multiple teams consuming portions of those underlying container resources</p> <p>The average lifespan of a container being one day versus a typically much longer utilization time for a VM</p> <p>Explanation: Managing Kubernetes clusters on just about any cloud platform is very challenging due to the complexity of how Kubernetes is deployed, how resources are consumed and the general lack of real time visibility. Secondly, all providers charge for additional resource usage so for the example the amount of bandwidth or storage API access may not be visible even with tagging.</p> <p>Please refer to this page before the exam. Calculating Container Costs (finops.org)</p> </li> <li> <p>Which of the following is the best definition of a Kubernetes Pod?     A pod consists of a group of containers and treats them as a single block of resources that can be scheduled and scaled on the cluster.</p> <p>Explanation: The other answers are incorrect and are variations of the correct answer.</p> <p>Reference: Please review the terminology here for containers. Calculating Container Costs (finops.org)</p> </li> <li> <p>_ _ _ _ _ _ or _ _ _ _ _ _ is the foundation of telling apart workloads in the cloud, identifying ownership, and attributing costs to teams.     Tagging or Labeling.</p> <p>Explanation: Tagging or labeling is the foundation of telling apart workloads in the cloud, identifying ownership, and attributing costs to teams.  Read more about forecasting. Accurate Cloud Forecasts (finops.org).</p> </li> <li> <p>Multiple Selection:(Select three)</p> <p>Cloud Forecasting can be a challenge, especially in large disparate organizations. Centralization can be a helpful factor but also there are some focus areas that we can use to 'break the challenge into addressable parts'.</p> <p>Tagging and cost allocation can provide insight into resource spending.</p> <p>Use forecasting models to help provide predicable models for consistency.</p> <p>Use communications to relay that forecasting is being used for decision making</p> <p>Explanation: The other answers are incorrect.  For example, we can use both third party and provider tools since some providers may not provide all the reports, features etc. we may want. It is also a Finops best practice to actually centralize our FinOps practice and provide consistency in our reporting/forecasting.</p> <p>Reference: https://www.finops.org/projects/accurate-cloud-forecasts/</p> </li> <li> <p>True or False:</p> <p>Distributed decision making coupled with the move to variable spending in cloud allows technology teams to efficiently partner with finance and business teams to make informed decisions that drive continual optimization.</p> <p>True</p> <p>Explicaci\u00f3n Statement is correct. Remember that FinOps is really about collaboration.</p> <p>Reference: FinOps Foundation - What is FinOps?</p> </li> <li> <p>When comparing TBM and FinOps, which one would focus on results mainly on speed?</p> <p>FinOps</p> <p>FinOps is focused on results much more frequently than with TBM. TBM is monthly or quarterly focused whereas FinOps collects and reviews data constantly.</p> <p>Technology Business Management (TBM), a best practice discipline for IT business management; and FinOps, the financial operating model for public cloud consumption, share the same goal of defining IT by impact rather than spend.</p> <p>TBM was built to serve the needs of on-prem IT with data-driven decision-making to manage, plan, and optimize spend. TBM has incorporated data-driven decision-making for the cloud but doesn\u2019t manage the complexities of allocating cloud costs and the prescriptive methods of controlling those costs. TBM looks at the \u201cwhat\u201d of all IT spend, including a macro view of cloud spend.</p> <p>By bringing together people (and data) from IT finance, operations, and business, TBM creates a community of stakeholders to manage all IT.</p> <p>FinOps was born for the cloud. Systems, best practices, and cultures increase an organization\u2019s ability to understand cloud costs and make informed and timely balancing decisions. FinOps focuses on optimizing the cost and utilization of the cloud through technical and organizational means.</p> </li> <li> <p>True or False: In regards to cloud forecasting there is no one forecasting method that fits all situations.</p> <p>True</p> <p>Every organization and even cloud provider has different requirements that are to be met or are met. Some organizations my need a granular VM pricing whereas other may not.</p> <p>Some cloud providers support things diffferently than other and therefor require the organization to consider the best model they need. Unfortunately there is no one forecasting method that fits all situations. Cloud spend is variable which is inherently difficult to predict.</p> <p>Specifically engineers can start workloads at any time typically without having to go through a procurement process. Forecasting cloud-provider consumption as product or service consumption requires specific data and tooling to be consistently available.</p> <p>Billing and reporting from cloud providers is difficult to understand and explain to traditional finance teams. Workloads need to be clearly defined whether through tagging or account structures so that cost can be attributed back to them and their owners.</p> <p>Please review this page before the exam. Accurate Cloud Forecasts (finops.org)</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal. What is the primary goal for a Chief Technology Officer (CTO)?</p> <p>Leverage technology to give the business a market and competitive advantage</p> <p>Explanation: There are clearly labeled roles for each 'Persona' and we must learn these for the exam.</p> <p>Reference:  FinOps Personas</p> </li> <li> <p>True or False: In FinOps decisions are not driven by the business value of the cloud?</p> <p>False</p> <p>In FinOps decisions are driven by the business value of the cloud. With FinOps we look at the cloud as a business value creator. One of the main roles of FinOps is to maximize the value of the cloud spending.</p> </li> <li> <p>Which of the following terms are associated with Agile?</p> <p>Sprint</p> <p>Explicaci\u00f3n: There are several terms affiliated with Agile development such as Sprint, User Story, Epics, Lean, etc. Rightsizing, Zones and Regions are cloud computing terms.</p> <p>Sprint a short interval of work in an Agile project, usually a week or two weeks but sometimes more or less, during which time an agreed-upon amount of work will be delivered.</p> <p>Reference:</p> <p>Please review the Terminology page before the exam. https://www.finops.org/resources/terminology/</p> </li> <li> <p>In Cloud Computing some costs can be considered fixed and some are variable. Which of the following costs would generally a fixed costs, meaning predictable monthly or annual costs?</p> <p>Support and Maintenance</p> <p>Explanation: Support and Maintenance are almost always a fixed cost meaning that you would pay a certain amount for a specific amount of support/users/response times. Variable costs would be about any resource you would use.</p> <p>Reference: Please review this page before the exam. FinOps Terminology</p> </li> <li> <p>Which of the following roles/personas would be responsible for 'Rate Negations' with a cloud provider?</p> <p>Procurement</p> <p>Explanation: Procurement is handled somewhat different in the world of FinOps.</p> <p>We know that Procurement is moved from a CAPEX to a OPEX manner in the cloud. Procurement should have the following objectives in a FinOps organization. Negotiate the best win-win cloud contract, Exercise enterprise discount / volume commitment programs and Manage relationship with Cloud platform provider.</p> <p>Reference: Please review this page before the exam https://www.finops.org/framework/personas/#product-owner</p> </li> <li> <p>True or False: FinOps is about saving money. </p> <p>False</p> <p>Explicaci\u00f3n FinOps is about making money. Cloud spend can drive more revenue, signal customer base growth, enable more product and feature release velocity, or even help shut down a data center.</p> <p>Please refer to this page. FinOps Foundation - What is FinOps?</p> </li> <li> <p>Your organization has recently adopted a FinOps based method for dealing with cloud costs and adopting FinOps. Currently, your organization has recently completed 'Step Two' for FinOps culture in your company. What would the next stage for the organization to accomplish?</p> <p>Preparing the organization for FinOps</p> <p>Explanation: The next step after Stage 1 - Planning for FinOps in an Organization (Laying the groundwork) is the Stage 2 - Socializing FinOps for adoption in an organization. Then After Step 2 would be Stage 3 - Preparing the organization for FinOps</p> <p>Reference: Please reference this page before the exam. Adopting FinOps - Getting Started</p> </li> <li> <p>Multiple Selection: (Select three) Which activities would fit under the FinOps principle of ' Decisions are driven by business value of cloud' ?</p> <p>Trending and variance analysis helps to understand why costs increased</p> <p>Internal team benchmarking drives best practices and celebrates wins</p> <p>Industry peer-level benchmarking determines how your company is performing</p> <p>Explicaci\u00f3n: Decisions are driven by business value of cloud The other activities are under a different phase of activities.</p> <p>Please reference this page, section. https://www.finops.org/framework/principles/</p> </li> <li> <p>Which service on AWS used to download and store the Cost and Usage report on so you can query it?</p> <p>AWS S3</p> <p>AWS S3 is the service for storing data on AWS. You can publish your AWS billing reports to an Amazon Simple Storage Service (Amazon S3) bucket that you own and choose to use that how you like.</p> <p>Reference: https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.htm</p> </li> <li> <p>True or False: A key role toward building FinOps adoption is the Driver.</p> <p>True</p> <p>A key role toward building FinOps adoption is the Driver which means that we must get broad executive support and buy-in to dedicate the time and resources needed for the cultural change.</p> <p>Reference:</p> <p>Please review this page before the exam. https://www.finops.org/projects/adopting-finops/</p> </li> <li> <p>FinOps Principles are north stars that guide the activities of our FinOps practice. These principles are clearly broken down and we must encourage members to practice these. When it comes to these principles which of the following activities would be under the 'Teams need to Collaborate' principle?</p> <p>Define governance and controls for cloud usage</p> <p>Explanation: Honestly, some of these activities may or not intuitively seem like they are under specific principles. This is perhaps the most confusing part of the content to remember. For Teams need to collaborate these are the activities specified by the FinOps Foundation: Finance moves at the speed and granularity of IT Engineering considers cost as a new efficiency metric Continuously improve your practice to gain efficiency and innovation Define governance and controls for cloud usage.</p> <p>Reference:</p> <p>Please refer to this page before the exam. FinOps Principles</p> </li> <li> <p>In regards to the FinOps Maturity Model Guidelines which of the following statements would be true regarding the Maturity Level Characteristics for 'Run'.</p> <p>Capability is understood and followed by all teams within the organization</p> <p>Explicaci\u00f3n</p> <p>The guidelines and characteristics are clearly defined by the FinOps Foundation and these are a must know for the exam.</p> <p>RUN MATURITY CHARACTERISTICS Capability is understood and followed by all teams within the organization Difficult edge cases are being addressed Very high goals/KPIs set on the measurement of success Automation is the preferred approach The maturity model</p> <p>Must read. FinOps Maturity Model</p> </li> <li> <p>AWS has a wealth of FinOps capabilities that we could use as an AWS user. Which of the following AWS Services would we use to track costs and usage and send alerts when a threshold is exceeded.</p> <p>AWS Budgets</p> <p>Explanation: AWS Budgets allows users to set up alerts, initiated when actual or forecasted costs and usage exceed predetermined budget thresholds. The goal of AWS Budgets is to reduce unintentional over-spending. AWS Budgets also allows for the configuration of automated responses if costs or usage exceed desired limits.</p> <p>https://docs.aws.amazon.com/cost-management/latest/userguide/budgets-managing-costs.html</p> </li> <li> <p>Your FinOps leader and mentor has reached out to you to find out more about Azure Capabilities. What tool in Azure would you use to implement enforcement of Tagging on Azure?</p> <p>Azure Policy</p> <p>Explanation: You use Azure Policy to enforce tagging rules and conventions. By creating a policy, you avoid the scenario of resources being deployed to your subscription that don't have the expected tags for your organization. Instead of manually applying tags or searching for resources that aren't compliant, you create a policy that automatically applies the needed tags during deployment.</p> <p>Tags can also now be applied to existing resources with the new Modify effect and a remediation task. The following section shows example policy definitions for tags.</p> <p>References:  https://www.finops.org/projects/multi-cloud-tools-and-terminology/</p> <p>Policy definitions for tagging resources - Azure Resource Manager | Microsoft Learn</p> </li> <li> <p>Which stage in the FinOps Adoption Process would we be 'performing initial resourcing' such as getting budget approval?</p> <p>**Stage 1 - Planning for FinOps in an Organization (Laying the groundwork) **</p> <p>Explanation: When planning for FinOps we must assemble resources, estimate, review, plan and assemble people and all this is done in the first stage.</p> <p>Please review this page before the exam. Adopting FinOps - Getting Started</p> </li> <li> <p>Each of the cloud providers have tools that can help FinOps professionals specifically in that cloud platform. You have been working with AWS for over 1 year. You know would like to go back and view the billing reports but also perform a detailed report for BI analysis. What AWS service could you use?</p> <p>AWS QuickSight </p> <p>is a cloud-native, serverless, business intelligence with native ML integrations and usage-based pricing, allowing insights for all users.</p> <p>Reference: </p> <p>https://www.finops.org/projects/multi-cloud-tools-and-terminology/</p> <p>AWS</p> </li> <li> <p>Which of the following statements would be correct about Weighted Average Cost of Capital?</p> <p>This is the rate the company is expected to pay on average to all its securities holders to finance the operation of the business.</p> <p>Weighted Average Cost of Capital - the rate the company is expected to pay on average to all its securities holders to finance the operation of the business. Importantly this is set by the external market (what the market is willing to pay for various forms of the company\u2019s securities) not by management.</p> <p>Reference: FinOps Terminology</p> </li> <li> <p>Which of the following a native tool in AWS that we would use in our FinOps exercises to understand costing issues, get recommendations, etc.</p> <p>Cost Explorer</p> <p>Explanation: Cost Explorer is a free tool that AWS offers to all customers that provides visibility across the AWS infrastructure and has features like rightsizing, savings plans recommendations, and cost anomaly alerting. Cost and Usage Reports (CUR) provides no recommendations and it is important to that Trusted Advisor has free and paid support options but does not provide insight into billing.</p> <p>Reference: https://aws.amazon.com/aws-cost-management/aws-cost-explorer/</p> </li> <li> <p>FinOps Principles are north stars that guide the activities of our FinOps practice. They\u2019re developed by FinOps Foundation members, and honed through experience. When it comes to the FinOps principle of 'A centralized team drives FinOps' which of the following statements would be true?</p> <p>Centralized discount buying process removes rate negotiations from engineering team consideration.</p> <p>Explicacion: Using a granular approach is recommended and Track team-level targets to drive accountability is not under the A centralized team section, it is under 'Everyone takes ownership for their cloud usage'</p> <p>Reference: Please review this page before the exam. FinOps Principles</p> </li> <li> <p>'Manage Commitment Based Discounts' would be under what domain according to the FinOps Foundation?</p> <p>Cloud Rate Optimization</p> <p>Explanation: There are six specific domains in FinOps according to the FinOps Foundation. We will want to be able to understand what topics are covered by each domain.</p> <p>Reference: Managing Commitment Based Discounts (finops.org)</p> </li> <li> <p>Multiple Selection: (Select two) Your business unit has decided to use Azure for its cloud services for production. Other business units have been Azure for both development and production use cases. You have been asked to provide tools in Azure that can provide recommendations for reducing costs and getting insight into better ways of resource management. What tools in Azure could you identify?</p> <p>Azure Advisor</p> <p>Azure has only one tool </p> <p>Explanation: Every cloud provider has their own approach for billing and cost management. We need to know the three major providers in preparation for the exam.</p> <p>Reference: Please refer to this page for a handy table. Multi-Cloud Tools and Terminology (finops.org)</p> </li> <li> <p>When rightsizing your containers which of following would be focused on responding dynamically to different conditions?</p> <p>Autoscaling</p> <p>Autoscaling provides the ability to respond dynamically to different conditions, such as increased or decreased demand. This can take some architecting and iterative adjustments to get right for your application, and there is room for waste along the way. However, the more tightly your horizontal pod autoscaling (when we need more / less pods) and cluster autoscaling (when do we need more / less nodes) are configured, the less waste and unnecessary cost to run your application.</p> <p>Please review this page before the exam. (Section Optimize)</p> <p>Reference: Calculating Container Costs (finops.org)</p> </li> <li> <p>_ _ _ _ _ _ _ _is the idea is to measure cloud spend against a business metric or metrics such as revenue, subscribers, etc. What is the correct term?</p> <p>Unit Economics</p> <p>Explanation:</p> <p>One of the most important concepts in FinOps is Unit Economics.</p> <p>The idea is to measure cloud spend against a business metric (total revenue, shipments made, paid subscribers, customer orders completed, etc.). Choosing the right business metric is a complex process. For now, the main thing to remember is that Unit Economics relies on almost every aspect of FinOps, including tagging, cost allocation, cost optimization, and FinOps operations. This business metric is important, because it allows you to change the conversation from one that is just about dollars spent to one about efficiency and the value of cloud spend.</p> <p>Reference: https://www.finops.org/project/introduction-cloud-unit-economics/</p> </li> <li> <p>FinOps Principles gives us what are called _ _ _ _ _ _ _ _to help guide our activities in FinOps.</p> <p>North Stars</p> <p>Explanation: FinOps Principles are north stars that guide the activities of our FinOps practice. They\u2019re developed by FinOps Foundation members, and honed through experience. These were initially proposed as part of the writing the Cloud FinOps book in Sept 2019 as a joint AWS announcement at CloudyCon. Now, they cover multiple clouds, and knowing how cloud services change every quarter it seems, they may change slightly over time as new experience is gained by all.</p> </li> <li> <p>FinOps Practitioners use _ _ _ _ _ _ _ _ to provide insight into how well an organization is doing with cloud spend.</p> <p>Cloud Performance Benchmarking</p> <p>Explanation: Benchmarking is important because it provides a reference to measure against. There are both internal and external benchmarks to consider as well.</p> <p>Reference: Performance Tracking &amp; Benchmarking (finops.org)</p> </li> <li> <p>Multiple Selection: What would be some common names that could used for a FinOps team? (Select three)</p> <p>Cloud Business Office (CBO)</p> <p>Cloud Economics Team </p> <p>Cloud Center of Excellence</p> <p>Explanation: A FinOps team may have different names in difference organizations.</p> <p>Here are some examples.</p> <ul> <li>Cloud Business Office (CBO)</li> <li>Cloud Economics Team</li> <li>Cloud Center of Excellence</li> </ul> </li> <li> <p>What is the name of the file format used in AWS Cost and Usage reports?</p> <p>CSV</p> <p>Explanation: The AWS Cost and Usage Reports (AWS CUR) contains the most comprehensive set of cost and usage data available. AWS updates the report in your bucket once a day in comma-separated value (CSV) format. You can view the reports using spreadsheet software such as Microsoft Excel or Apache OpenOffice Calc, or access them from an application using the Amazon S3 API.</p> <p>Reference: https://docs.aws.amazon.com/cur/latest/userguide/what-is-cur.html</p> </li> <li> <p>Multiple Selection : Select all the correct options. When managing cloud costs specifically around containers there are several things in Google Cloud we can do to manage costs and identify these costs. Which of the following would be ways we could break down costs? </p> <p>Billing Hierarchy</p> <p>Namespaces</p> <p>Labels.</p> <p>Explanation: Google Cloud provides some robust methods to identify costs and also segment. Availability Zones is actually an AWS concept so that's incorrect. One method, recommended by Debo Aderibigbe, a Google Cloud Billing Product Manager, is to break down costs by:</p> <p>Billing Hierarchy: Organizations, folders, projects, normalizing them with cross-cloud concepts: Linked Accounts, Tags, Subscriptions, etc. Resources: Compute cores, RAM, GPU, TPU, Load Balancers, Persistent Disk, Custom Machines, Network Egress</p> <p>Namespaces: labeling specific, isolated containers</p> <p>Labels: Teams, cost centers, app names, environment, and more With a deep labeling and tagging of all of these cost drivers, users can improve the accuracy of how they invoice teams, audit costs, allocate costs, optimize overrun costs, model budgeting scenarios, or fit workload costs within quotas or under budget caps. Please review this page before the exam.</p> </li> <li> <p>Multiple Selection:(Select four) Which of the following are considered goals of the FinOps journey?</p> <p>Visibility</p> <p>Benchmarking</p> <p>Budgeting </p> <p>Forecasting </p> <p>Visibility, Benchmarking, Budgeting and Forecasting are goals of the FinOps Inform Phase. The Inform Phase of the FinOps journey is about understanding the current state of your system.</p> <p>Due to the on-demand and elastic nature of access to cloud resources, along with variable pricing structures, it is critical to have access to timely and accurate system metrics to make appropriate, informed decisions. In this phase there are five primary goals:</p> <ul> <li>Visibilit</li> <li>Allocatio</li> <li>Benchmarkin</li> <li>Budgetin</li> <li>Forecasting</li> </ul> <p>Please review this page before the exam https://www.finops.org/framework/phases/</p> </li> <li> <p>An Availability Zone in AWS is defined as?</p> <p>A sub-unit of a Region, there are typically multiple AZs per Region</p> <p>In AWS a Region is a geographic area that holds multiple Availability Zones. AWS does not deploy a Region w/o at least three AZs available.</p> <p>Terminology is a critical knowledge area for the exam. FinOps Terminology</p> </li> <li> <p>Which are the correct FinOps Principles? (Select Six) </p> <p>Teams need to collaborate</p> <p>Business value of cloud drives decisions</p> <p>Everyone takes ownership of cloud usage</p> <p>FinOps reports should be accessible and timely</p> <p>A centralized team drives FinOps</p> <p>Take advantage of the variable cost model of the cloud</p> <p>Reference: Before the exam you must review this page! https://www.finops.org/framework/principles/</p> </li> <li> <p>What is the name of the resource you would look at to identify the full list of the columns that can appear in AWS Cost and Usage Reports (AWS CUR) and the services that the columns apply to?</p> <p>Data Dictionary</p> <p>Explanation: You can analyze your usage and cost in detail once you've set up your report. AWS has provided a Data Dictionary that lists the columns you'll see in your report, along with definitions and examples.</p> <p>Reference: Data dictionary - AWS Cost and Usage Reports (amazon.com)</p> </li> <li> <p>Which of following is a simple formula for cloud spending?</p> <p>Spend = Usage \u00d7 Rate</p> <p>The simple formula plays a key part of deciding both how to optimize and who in the organization takes optimization. Usage could be the number of hours of a resource used and the rate is the hourly (or per second) amount paid for the usage of that resource.</p> </li> <li> <p>Multiple Selection : (Select two) Your business unit has decided to use GCP for its cloud services for production. Other business units have been GCP for both development and production use cases. You have been asked to provide tools in GCP that can provide recommendations for reducing costs and getting insight into better ways of resource management. What tools in GCP could you identify?</p> <p>Recommender</p> <p>Commitment Analysis</p> <p>Explicaci\u00f3n Every cloud provider has their own approach for billing and cost management. We need to know the three major providers in preparation for the exam. Please refer to this page for a handy table. Multi-Cloud Tools and Terminology (finops.org)</p> </li> <li> <p>According to the FinOps Foundation there are very specific roles/personas. For the role of a product owner what would be the 'Primary Goal' ?</p> <p>Quickly bring new products and features to market with an accurate price point.</p> <p>Explanation: The product owner is focused on Product Growth and other concerns such as delivering innovative, market leading solutions cost effectively. Products need to get market correctly.</p> <p>Reference: Please review this page before the exam https://www.finops.org/framework/personas/#product-owner</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal. What is the primary goal for the Engineering Lead?</p> <p>Deliver faster and high quality services to the organization, whilst maintaining business as usual</p> <p>There are clearly labeled roles for each 'Persona' and we must learn these for the exam.</p> <p>Reference: FinOps Personas</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal. What is the primary goal for a Chief Technology Officer (CTO)</p> <p>Leverage technology to give the business a market and competitive advantage</p> <p>There are clearly labeled roles for each 'Persona' and we must learn these for the exam.</p> <p>Reference: FinOps Personas</p> </li> <li> <p>Multiple Selection : Which of the following is true regarding teams working in FinOps organizations? (Select two) </p> <p>All teams have a role to play in FinOps</p> <p>Teams have different motivators that drive spend and savings.</p> <p>Some other basic realities are with FinOps teams are</p> <ul> <li>Teams need to work together with a balance of empathy for one another\u2019s goals.</li> <li>FinOps practitioners help align teams to organizational goals.</li> </ul> <p>Teams inside your organization are able to work together to understand one another\u2019s goals alongside a centralized FinOps team that is helping to build out reporting and practices to assist everyone in achieving them.</p> </li> <li> <p>What is the purpose of a FinOps Center of Excellence in an organization?</p> <p>To strictly enforce FinOps governance policies and models</p> <p>A FinOps Center of Excellence is built around business, technology, financial, and operational stakeholders. It defines the governance policies and models for FinOps, and the rest of the organization follows these guidelines to ensure effective adoption of FinOps practices.</p> </li> <li> <p>What is the key factor for the successful adoption of Cloud Computing?</p> <p>Building a culture of FinOps</p> <p>The successful adoption of Cloud Computing relies on the proper implementation and adoption of the FinOps Framework. Building a culture of FinOps involves having a FinOps Center of Excellence and ensuring that the organization strictly follows the defined governance policies and models.</p> </li> <li> <p>True or False: FinOps teams primarily focus on managing costs, while innovation and velocity are secondary considerations.</p> <p>False.</p> <p>While cost optimization is undoubtedly a core component of FinOps, the statement that FinOps teams prioritize it at the expense of innovation and velocity is inaccurate. In fact, a successful FinOps approach recognizes the need to balance all three aspects:</p> <ul> <li> <p>Cost optimization: Finding ways to optimize cloud spending without compromising performance or functionality.</p> </li> <li> <p>Innovation: Encouraging teams to explore and adopt new technologies and cloud services that can drive business value.</p> </li> <li> <p>Velocity: Ensuring projects and deployments happen quickly and efficiently without incurring unnecessary costs.</p> </li> </ul> <p></p> </li> <li> <p>What is the primary benefit of OpEx for businesses?</p> <p>Reduced hardware and software costs</p> <ul> <li>(a) Reduced hardware and software costs: This is correct because a major benefit of OpEx is the ability to rent instead of purchase technology and infrastructure, leading to cost savings on hardware and software.</li> <li>(b) Elimination of IT staff workload: While OpEx may reduce some burden on IT, it doesn't completely eliminate their work. Managing cloud resources and optimizing costs still requires their expertise.</li> <li>(c) Increased control over IT infrastructure: Moving to the cloud generally involves some loss of control over infrastructure compared to on-premise solutions. While management tools exist, the absolute control of your own hardware isn't present.</li> <li>(d) Faster deployment of new technologies: This may be a secondary benefit of cloud-based OpEx due to its scalability and flexibility.</li> </ul> </li> <li> <p>What does the OpEx ratio measure?</p> <p>The efficiency of cloud cost management</p> <ul> <li>(a) The efficiency of cloud cost management: This is correct, the OpEx ratio is a key metric for comparing a company's cloud spending to its revenue, effectively measuring their cost efficiency.</li> <li>(b) The level of IT infrastructure control: While control over infrastructure plays a role in cost management, the OpEx ratio specifically focuses on financial efficiency, not control levels.</li> <li>(c) The return on investment in cloud services: The OpEx ratio compares current spending to revenue, not investments or future returns.</li> <li>(d) The profit margin of a business: The OpEx ratio is a specific metric within OpEx and doesn't directly reflect a company's overall profit margin, which encompasses various factors beyond cloud costs.</li> </ul> </li> <li> <p>What is a challenge associated with managing cloud costs across multiple providers? (Select Two)</p> <p>Increased operational complexity</p> <p>Reduced visibility into spending</p> <p>Reduced visibility into spending. there is a difficulty of understanding costs across multiple clouds, hindering optimization efforts.</p> <ul> <li>(a) Increased operational complexity: This is correct because managing resources across multiple cloud providers can be challenging, requiring additional tools, processes, and expertise to maintain visibility and control, hence increasing operational complexity.</li> <li>(b) Reduced visibility into spending: This is also correct as the passage mentions the difficulty of understanding costs across multiple providers, making it harder to analyze and optimize spending.</li> </ul> </li> <li> <p>How can FinOps help prevent cloud cost spikes?</p> <p>By setting spending limits and alerts</p> <p>This is correct because It highlights the importance of proactive monitoring and alerts to prevent unforeseen cost spikes. FinOps teams often leverage tools and dashboards to set spending thresholds and trigger alerts that prevent excessive spending.</p> </li> <li> <p>True or False : FinOps aims to balance cost management with business agility and innovation, ensuring that cost-consciousness aligns with overall business goals.</p> <p>True</p> <p></p> </li> <li> <p>What does FinOps represent?</p> <p>Financial Operations, more commonly referenced as FinOps, represent the intersection of Finance, DevOps, and Business.</p> <p>Here's why:</p> <ul> <li> <p>FinOps focuses on managing and optimizing cloud costs: HR doesn't typically play a direct role in this process, while DevOps teams have significant involvement in cloud resource utilization and cost drivers.</p> </li> <li> <p>Collaboration between Finance, DevOps, and Business is crucial: This collaboration ensures informed decision-making regarding cloud investments, balancing cost optimization with business value and agility needs.</p> </li> <li> <p>Marketing doesn't directly manage cloud resources: While Marketing might benefit from cloud technologies, they're generally not involved in optimizing their infrastructure costs.</p> </li> </ul> <p>Therefore, FinOps primarily operates at the intersection of Finance, DevOps, and Business, where the focus lies on:</p> <ul> <li> <p>Finance: Provides financial expertise, budgeting, and cost visibility.</p> </li> <li> <p>DevOps: Understands cloud resource usage, identifies optimization opportunities, and implements efficient practices.</p> </li> <li> <p>Business: Sets strategic goals, prioritizes initiatives, and aligns cloud investments with business objectives.</p> </li> </ul> <p>By fostering collaboration and shared responsibility across these stakeholders, FinOps empowers organizations to optimize cloud costs, maximize value, and achieve sustainable cloud growth.</p> <p>Remember, FinOps is more than just cost reduction. It's about driving responsible and value-driven cloud adoption that benefits the entire organization.</p> <p>Reference: https://www.finops.org/introduction/what-is-finops/ </p> </li> <li> <p>What is the role of cloud management tools in OpEx management?</p> <p>They help keep things in check and manage cloud resources effectively.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>a. They eliminate the need for FinOps teams: Cloud management tools are powerful, but they cannot replace the expertise and strategic role of FinOps teams. These teams still need to analyze data, set goals, and make decisions based on the insights provided by the tools.</li> <li>b. They provide complete control over IT infrastructure: While cloud management tools offer greater visibility and control than simply relying on the cloud provider's interface, they don't offer complete control over the underlying infrastructure. The level of control depends on the specific tool and cloud provider.</li> <li>d. They only focus on financial benchmarks: Cloud management tools offer a wider range of features beyond just financial data. They can track resource utilization, security, performance, and compliance, providing a holistic view of cloud resources.</li> </ul> <p>Therefore, cloud management tools act as valuable assistants to FinOps teams, helping them monitor, analyze, and optimize cloud resources for cost-effectiveness and overall efficiency. They automate tasks, provide alerts, and generate reports, making it easier to manage large and complex cloud environments.</p> <p>Remember, FinOps is the broader strategy and framework, while cloud management tools are the technical instruments that support its implementation.</p> </li> <li> <p>Why is it essential for business leaders to analyze budgets and financial benchmarks when moving to cloud-based OpEx offerings?</p> <p>To ensure long-term savings despite some upfront costs</p> <p>Here's why the other options are incorrect:</p> <ul> <li>a. To increase employee salaries: Although cost optimization often leads to increased profitability, which might allow for employee raises, that's not the primary focus when analyzing budgets and benchmarks for cloud migrations.</li> <li>b. To eliminate all risks associated with on-premise infrastructure: Moving to the cloud doesn't completely eliminate all risks associated with on-premise infrastructure. There are still cloud-specific risks and considerations.</li> <li>d. To completely avoid the need for cloud cost management: Even with apparent long-term savings, cloud cost management remains crucial. Analyzing budgets and benchmarks helps anticipate the upfront costs and ongoing expenses to effectively manage spending and optimize your cloud investment.</li> </ul> <p>Therefore, analyzing budgets and financial benchmarks ensures that the potential long-term savings from cloud-based OpEx outweigh the initial costs and ongoing expenses. This analysis helps business leaders make informed decisions about resource allocation, pricing models, and optimization strategies to maximize the cloud's cost-effectiveness for their business.</p> <p>Remember, even though the cloud promises flexibility and scalability, proper financial planning and management are still essential for a successful cloud migration and cost optimization journey.</p> </li> <li> <p>What role does cloud health monitoring play in FinOps?</p> <p>It provides insights into cloud consumption.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>a. It ensures complete control over IT infrastructure: While cloud health monitoring offers increased visibility and control compared to purely relying on the cloud provider's interface, it doesn't guarantee complete control over the underlying infrastructure. The level of control still depends on the tools and the specific cloud provider.</li> <li>c. It eliminates the need for cloud management tools: Cloud health monitoring is actually a core function of many cloud management tools. While monitoring provides valuable insights, tools offer additional features like automation, alerts, and reporting, making them crucial for comprehensive FinOps strategies.</li> <li>d. It focuses solely on financial benchmarks: While monitoring data can be used to track costs and optimize expenditure, its role in FinOps extends beyond just financial aspects. Cloud health monitoring also provides insights into resource utilization, performance, security, and compliance, offering a holistic view of your cloud environment's health and efficiency.</li> </ul> <p>Therefore, cloud health monitoring plays a vital role in FinOps by providing valuable data and insights into your cloud consumption. This information empowers FinOps teams to:</p> <ul> <li>Identify areas for optimization and cost reduction.</li> <li>Improve resource utilization and prevent waste.</li> <li>Track performance and detect potential issues.</li> <li>Ensure compliance and secure your cloud environment.</li> </ul> <p>Overall, cloud health monitoring serves as a critical diagnostic tool for FinOps teams, enabling them to make informed decisions and optimize your cloud investment for cost-effectiveness, performance, and overall health.  63. What is the purpose of tagging in cloud cost management?</p> <p>To provide metadata for individual resources.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>a. To eliminate the need for cost allocation strategies: While tagging can facilitate cost allocation, it doesn't eliminate the need for strategies entirely. You still need to determine how costs are attributed to different tags and define relevant groupings for analysis.</li> <li>b. To organize tags based on hierarchy groupings: Tag hierarchies can be helpful, but the primary purpose of tagging is not to create hierarchies. Tags are primarily used to tag individual resources with relevant information.</li> <li>d. To enforce compliance with cloud service provider policies: While tags can be used to track compliance with some policies, this is not their primary purpose. Tags are primarily used for cost management and resource organization.</li> </ul> <p>Therefore, the main purpose of tagging in cloud cost management is to add descriptive metadata to individual resources. This metadata can include information such as:</p> <ul> <li>Project name</li> <li>Team or department</li> <li>Environment (e.g., production, development, testing)</li> <li>Application name</li> <li>Owner or contact information</li> </ul> <p>This metadata allows you to:</p> <ul> <li>Track costs by category: By tagging resources with relevant categories, you can easily analyze your cloud spend and identify areas for optimization.</li> <li>Allocate costs to different teams or departments: Tags can be used to attribute costs to individual teams or departments, making it easier to track their cloud usage and budget allocations.</li> <li>Filter and group resources: Tags can be used to filter and group resources based on specific criteria, making it easier to manage and troubleshoot your cloud environment.</li> <li>Automate tasks: Some cloud platforms allow you to automate tasks based on tags, such as sending cost alerts or decommissioning unused resources.</li> </ul> <p>Overall, tagging plays a crucial role in effective cloud cost management by providing a detailed and flexible way to organize and analyze your cloud resources. By using tags strategically, you can gain valuable insights into your cloud usage and make informed decisions to optimize your spending and improve your cloud efficiency.</p> </li> <li> <p>What are the primary categories of tags used in cost allocation for chargeback or showback?</p> <p>Business Tags, Environment Tags, and Automation Tags.</p> <p>Here's why:</p> <ul> <li>Business Tags: These are crucial for identifying the business unit, department, or project responsible for the cloud resources' costs. Examples include project names, product lines, or business units.</li> <li>Environment Tags: These categorize resources based on their purpose (e.g., production, development, testing) or specific configurations. This helps understand cloud usage across different environments and allocate costs accordingly.</li> <li>Automation Tags: While not directly related to cost allocation, these tags enable automation of cost-related tasks based on resource attributes. For example, automatically decommissioning idle resources tagged for \"testing\" after a certain period.</li> </ul> <p>Other options:</p> <ul> <li>a. Business Tags, Security Tags, and Compliance Tags: While Security and Compliance are important categories, they wouldn't necessarily be primary for cost allocation. They might be used for tracking resource configurations for compliance purposes, but wouldn't directly map to cost attribution.</li> <li>c. Compliance Tags, Automation Tags, and Business Owner Tags: \"Business Owner Tags\" might be relevant for specific scenarios, but generally, Business Tags encompass broader ownership information. Compliance tags wouldn't be primary for cost allocation as explained earlier.</li> <li>d. Name Tags, Encryption Tags, and Cost Center Tags: \"Name Tags\" are simply descriptive labels and wouldn't be meaningful for cost allocation. Encryption tags might be relevant for specific security needs but not directly related to cost attribution. \"Cost Center Tags\" could overlap with Business Tags depending on the organization's structure.</li> </ul> <p>Therefore, while the specific tag categories may vary based on individual organizational needs, Business Tags, Environment Tags, and Automation Tags are the most likely primary categories used in cost allocation for chargeback or showback due to their direct relevance to resource ownership, usage, and cost attribution.</p> <p>Remember, effective tagging requires a thoughtful and consistent approach to ensure accurate and insightful cost allocation for chargeback or showback purposes.</p> </li> <li> <p>Why is it recommended to assign tags as close to the resource and source data as possible?</p> <p>To allow tags to flow with cost and usage data to downstream systems.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>a. To minimize the number of tags needed: While minimizing tag clutter is advisable, assigning tags close to the source doesn't automatically guarantee minimizing the number of tags. It actually enables more granular and accurate cost allocation.</li> <li>b. To ensure compliance with cloud service provider policies: Tagging can facilitate compliance with certain policies, but compliance isn't the primary reason for this recommendation.</li> <li>c. To guarantee complete control over IT infrastructure: Tagging offers increased visibility and control, but it doesn't guarantee complete control over the underlying infrastructure.</li> </ul> <p>Therefore, the primary reason for assigning tags as close to the resource and source data as possible is to ensure that the tags seamlessly flow with the associated cost and usage data throughout your internal systems. This flow is crucial for:</p> <ul> <li>Accurate cost allocation: By inheriting resource tags, downstream systems like cost management platforms can accurately assign costs to the relevant business units, projects, or departments.</li> <li>Granular analysis: Tags closer to the source enable fine-grained analysis of resources and their associated costs, providing deeper insights into cloud usage patterns and potential optimization opportunities.</li> <li>Automated cost tracking: When tags flow automatically with cost data, downstream systems can trigger automated actions based on predefined tag-based cost thresholds, improving cost control and efficiency.</li> </ul> <p>Overall, assigning tags close to the resource and source data fosters a cohesive and integrated cloud cost management ecosystem. This tight integration allows for accurate cost attribution, deeper analysis, and automated cost control, ultimately leading to optimized cloud spend and improved financial transparency.</p> <p>Remember, strategic tagging and efficient data flow are essential pillars for effective cloud cost management and FinOps practices.</p> </li> <li> <p>Why is it crucial for on-premise teams and cloud teams to use the same unit of measure when comparing infrastructure services?</p> <p>To ensure fair and accurate cost comparison.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>a. To make cloud services seem more expensive: This is misleading. Using the same unit of measure actually promotes transparency and facilitates objective cost comparisons.</li> <li>b. To prevent accurate cost comparison between on-premise and cloud services: This is the opposite of the actual goal. Standardizing the unit of measure allows for apples-to-apples comparisons and informed decision-making.</li> <li>d. To discourage organizations from moving to the cloud: This doesn't align with the benefits of adopting a unified unit of measure. It enables organizations to assess the true cost-effectiveness of different options, including cloud alternatives.</li> </ul> <p>Therefore, using the same unit of measure is crucial because it provides a fair and consistent basis for comparing the costs of on-premise and cloud infrastructure services. This facilitates:</p> <ul> <li>Informed decision-making: By accurately understanding the true cost of both options, organizations can make informed choices about migrating or expanding their cloud presence.</li> <li>Budget allocation and planning: Standardized cost metrics enable consistent budgeting and financial planning across both on-premise and cloud environments.</li> <li>Cost transparency and accountability: Consistent units help track and compare costs effectively, promoting transparency and accountability within the organization.</li> </ul> <p>Common units of measure used for comparing infrastructure services include:</p> <ul> <li>Cost per core-hour: This measures the cost of using a CPU core for a specific period.</li> <li>Cost per gigabyte-month: This measures the cost of storing data for a specific period.</li> <li>Cost per network transfer: This measures the cost of transferring data across the network.</li> </ul> <p>Using a standardized unit of measure is recommended best practice for cloud cost management and FinOps principles. It fosters transparency, objectivity, and informed decision-making when evaluating and comparing different infrastructure options, empowering organizations to optimize their cloud spend and maximize the value of their cloud investments. </p> </li> <li> <p>True or False: Visibility into cloud spend allows investigating trends and building forecasts for future costs in FinOps. </p> <p>True</p> <p>Explicaci\u00f3n: Visibility into cloud spend is essential for investigating trends, building forecasts, and making informed decisions about future costs in FinOps.</p> </li> <li> <p>How can a FinOps practitioner address resources that are not tagged?</p> <p>Enforce tagging via cloud service provider capabilities.</p> <p>Here's why the other options are less preferable:</p> <ul> <li>b. Rely solely on 3rd party cost allocation systems: While third-party cost allocation tools can offer valuable insights and automation, they still rely on accurate and consistent tagging data for effective attribution. Ignoring untagged resources completely would lead to inaccurate cost visibility and hinder optimization efforts.</li> <li>c. Ignore untagged resources for cost allocation: This completely neglects the costs associated with untagged resources, leading to inaccurate financial reporting and potential waste. It's crucial to address and allocate costs for all resources used, even if untagged.</li> <li>d. Apply peer pressure on cloud service providers: While advocating for improved tagging features with cloud providers is valid, it's not a direct solution for addressing immediate untagged resources and their associated costs.</li> </ul> <p>Therefore, the most proactive approach is to utilize the tagging enforcement capabilities offered by most cloud service providers. These features allow FinOps practitioners to:</p> <ul> <li>Set mandatory tagging requirements: You can define specific tags that must be applied to all resources before they can be deployed.</li> <li>Trigger alerts for untagged resources: Monitor for newly created resources and proactively identify any that are missing tags.</li> <li>Enforce cost allocation rules for untagged resources: Implement pre-defined rules to attribute costs for untagged resources to specific categories or departments based on resource type or other available information.</li> </ul> <p>Additionally, FinOps practitioners can:</p> <ul> <li>Educate and incentivize developers and cloud users: Promote the importance of proper tagging and the consequences of leaving resources untagged.</li> <li>Automate tagging solutions: Utilize tools or scripts to automatically apply tags based on resource attributes or usage patterns.</li> <li>Regularly audit and refine tagging practices: Continuously review tagging effectiveness, identify improvement opportunities, and adapt the strategy as needed.</li> </ul> <p>By actively addressing untagged resources and enforcing a strong tagging culture, FinOps practitioners can ensure accurate cost allocation, optimize cloud expenses, and gain valuable insights into resource utilization for informed decision-making.</p> </li> <li> <p>Which stakeholders are involved in developing a robust cost allocation methodology?</p> <p>Engineering, Finance, and Executives.</p> <p>Here's why the other options are less likely:</p> <ul> <li>a. Finance and Compliance teams: While Finance is crucial for cost allocation, Compliance usually focuses on regulations and data security, not cost attribution models.</li> <li>c. Business Owners and Security teams: Although Business Owners can provide input on cost distribution preferences, security teams wouldn't typically lead the development of the methodology itself.</li> <li>d. Cloud Service Providers and 3rd party vendors: While cloud providers offer tagging functionalities and third-party tools can provide insights, they wouldn't spearhead the internal development of an organization's specific cost allocation methodology.</li> </ul> <p>Engineering teams bring technical expertise and understand the resource dependencies and utilization patterns. Finance teams possess accounting knowledge and ensure cost allocation principles are sound and align with financial reporting requirements. Executives provide strategic direction and set budget constraints, ultimately approving the adopted methodology.</p> <p>Collaboration between these key stakeholders is crucial for developing a robust cost allocation methodology that:</p> <ul> <li>Reflects the organization's specific needs and structure.</li> <li>Balances fairness and accuracy in cost attribution.</li> <li>Aligns with technical feasibility and data availability.</li> <li>Supports clear communication and transparency across departments.</li> </ul> <p>Effective cost allocation methodologies enable informed decision-making, optimize resource utilization, and promote cloud cost accountability within an organization.</p> </li> <li> <p>What are the reasons for starting FinOps practices early in an organization? (Select three)</p> <p>To quickly reduce the cloud bill </p> <p>To achieve better visibility and make informed decisions</p> <p>To ensure compliance with industry benchmarks</p> <p>The following are reasons to start FinOps practices early in an organization</p> <ul> <li>A. To quickly reduce the cloud bill: True. Implementing FinOps practices like cost optimization, resource management, and budgeting can help identify and eliminate cloud waste, leading to cost reductions early on.</li> <li>C. To achieve better visibility and make informed decisions: True. Early FinOps practices provide better insights into cloud spend patterns, resource usage, and potential cost drivers. This data empowers informed decisions about resource allocation, pricing models, and optimization strategies.</li> <li>D. To ensure compliance with industry benchmarks: True. While not the primary goal, early FinOps can help establish best practices and align cloud usage with industry standards, indirectly contributing to compliance.</li> </ul> <ul> <li>B. To avoid any executive interventions: False. While early FinOps can lead to smoother scaling and resource allocation, avoiding executive involvement is not a healthy goal. FinOps should involve collaboration with leadership to ensure aligned goals and resource prioritization.</li> <li>E. To promote misunderstandings among teams: False. This is the opposite of the desired outcome. FinOps promotes collaboration and communication between finance, operations, development, and business teams to achieve shared goals.</li> <li>F. To establish complex financial models: False. Early FinOps should start with simple and actionable practices. Complex financial models can be introduced later as the organization matures in its FinOps journey.</li> </ul> <p>Therefore, the correct answers are A, C, and D. Starting FinOps early allows organizations to gain better control over cloud spending, make informed decisions based on data, and potentially align with industry best practices. It's not about avoiding leadership involvement, promoting team conflict, or establishing overly complex financial models right away.</p> </li> <li> <p>What is the relationship between cost allocation and a FinOps culture?</p> <p>A FinOps culture can achieve more results than technology alone in applying tags.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>Cost allocation replaces the need for a FinOps culture: This is incorrect. Cost allocation is one element of FinOps, but it's not sufficient on its own. A FinOps culture promotes collaboration, awareness, and responsible cloud usage, fostering behaviors that optimize costs beyond just tagging resources.</li> <li>Cost allocation is solely dependent on technology, not culture: While technology plays a role in automating tagging and cost data analysis, effective implementation relies on human engagement and a shift in mindset. A FinOps culture encourages participation from different teams, ensuring accurate tagging and responsible resource usage.</li> <li>A FinOps culture is unnecessary for successful cost allocation: This is inaccurate. While cost allocation can be implemented, the results will be limited without a supportive FinOps culture. Lack of awareness, collaboration, and ownership can lead to inconsistent tagging, inaccurate cost attribution, and missed optimization opportunities.</li> </ul> <p>Therefore, a strong FinOps culture empowers effective cost allocation by:</p> <ul> <li>Encouraging accurate and consistent tagging: Users become engaged in understanding their costs and properly tag resources with relevant information.</li> <li>Promoting shared responsibility: Different teams feel involved in optimizing cloud expenses, leading to collaborative cost-saving initiatives.</li> <li>Fostering continuous improvement: The focus on cloud cost management becomes embedded in the organization's culture, leading to ongoing efforts to refine tagging practices and cost allocation methodologies.</li> <li>Technology like tagging systems and cost management tools can automate tasks and provide valuable insights, but ultimately, a FinOps culture drives the behavioral change and shared commitment necessary for sustainable and effective cloud cost optimization.</li> </ul> <p>Remember, a successful FinOps strategy integrates both technological solutions and a cultural shift toward cloud cost awareness and responsibility.</p> </li> <li> <p>which of the following is the challenge for shared costs?</p> <p>Shared costs may not be supported by tagging.</p> <p>Here's why the other options are incorrect:</p> <ul> <li>Shared costs are easier to allocate than dedicated costs: This is generally not true. Shared costs often require more complex allocation strategies compared to dedicated costs, which have a clear owner and usage pattern.</li> <li>Shared costs do not require cost allocation structures: This is incorrect. Shared costs still need a defined allocation structure to determine how the costs are attributed to different owners or departments. Without this, cost tracking and optimization become difficult.</li> <li>Shared costs are always 1:1 ownership ratios: This is not necessarily true. Ownership ratios for shared costs can vary depending on factors like resource utilization, project contribution, or budget limitations. A single resource might have multiple owners with different cost shares.</li> </ul> <p>Tagging systems can be invaluable for cost allocation, but they often struggle with shared costs. This is because tagging typically identifies a single owner for a resource, which doesn't work well for resources whose costs need to be split across multiple entities. This lack of native support for shared costs in tagging systems presents a significant challenge for accurate and transparent cost attribution.</p> <p>While some cloud providers and third-party tools offer advanced tagging features or custom cost allocation schemes, the challenge of managing shared costs persists. FinOps practitioners need to explore alternative solutions, such as:</p> <ul> <li>Manually defining cost allocation rules: This requires manual attribution of costs based on defined criteria like usage patterns, project budgets, or ownership agreements.</li> <li>Leveraging cost allocation tools: Some specialized tools allow defining complex cost allocation rules and integrating with specific cloud provider's cost data.</li> <li>Combining tagging with external data sources: By linking tag data with additional information like project budgets or resource utilization insights, shared costs can be attributed more accurately.</li> </ul> <p>Addressing the challenge of shared costs is crucial for effective cloud cost management, and FinOps practitioners need to adopt creative and flexible strategies to ensure accurate and fair cost allocation for all resources, regardless of ownership structure.</p> </li> <li> <p>True or False: Unit economics provides data to make decisions around the Iron Triangle in FinOps.</p> <p>True</p> <p>Unit economics allows teams to make decisions weighing the benefits of changes against the expected impact on the unit cost, aligning with the Iron Triangle principles.</p> </li> <li> <p>What is crucial for building trust and partnership in FinOps?</p> <p>Visibility, responsibility, and role definition.</p> <p>Out of the options given, the most crucial element for building trust and partnership in FinOps is:</p> <p>Here's why:</p> <ul> <li>Process automation: While automation can streamline operations, it doesn't inherently build trust or partnerships. Without clear communication and shared responsibility, automation can lead to misunderstandings and friction.</li> <li>Monthly cost reports: Regular reporting is important for tracking progress and identifying areas for improvement, but it doesn't address the underlying need for shared understanding and collaboration.</li> <li>Centralized management: Centralized management can ensure consistent practices, but it can also create silos and hinder collaboration between teams. Shared responsibility and open communication are key for effective FinOps partnerships.</li> </ul> <p>On the other hand, clear visibility, defined roles, and individual accountability foster trust and collaboration in several ways:</p> <ul> <li>Transparency: When everyone has access to the same data and insights, it eliminates suspicion and encourages open communication about costs and resource utilization.</li> <li>Shared responsibility: Defining clear roles and responsibilities ensures that everyone understands their contributions and owns their portion of the cloud cost management process.</li> <li>Collaboration: Building trust allows teams to work together effectively, share best practices, and collectively tackle cost optimization challenges.</li> </ul> <p>Therefore, prioritizing open communication, clearly defined roles, and shared accountability lays the foundation for strong partnerships and a successful FinOps culture. This collaborative approach allows teams to move beyond simply reporting costs and towards proactively optimizing cloud expenses for everyone's benefit.</p> <p>Remember, FinOps is not just about technology or processes; it's about fostering a collaborative environment where everyone feels empowered to contribute to shared cost optimization goals.</p> </li> <li> <p>How does FinOps suggest dealing with teams that prioritize speed over cost savings?</p> <p>Highlight positive impacts and track non-compliance.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>Implement strict penalties: Punitive measures can create animosity and hinder collaboration. FinOps promotes a positive and collaborative approach to optimize costs.</li> <li>Increase budget allocations: Simply throwing money at the problem doesn't address the underlying behavior and can encourage continued prioritization of speed over cost-effectiveness.</li> <li>Disregard the speed concerns: Ignoring the needs of speed-focused teams can lead to friction and hinder productive collaboration. Finding a balance between speed and cost is crucial.</li> </ul> <p>The FinOps approach emphasizes finding a balance between agility and cost optimization. Highlighting the positive impacts of speed for the business while simultaneously encouraging cost awareness and tracking non-compliance with established cost optimization best practices can be effective. This can involve:</p> <ul> <li>Demonstrating the long-term cost implications of short-term speed prioritization. Show how optimized resource utilization can maintain performance while decreasing costs, ultimately providing the organization with more resources for future innovation and growth.</li> <li>Providing alternative resource configurations and optimization strategies. Offer guidance and support to teams in finding cost-effective ways to achieve their speed goals. This could involve suggesting different cloud provider offerings, recommending resource scaling strategies, or promoting automation for efficient resource utilization.</li> <li>Implementing cost visibility tools and dashboards. Empowering teams with real-time insights into their resource usage and associated costs can encourage them to make informed decisions that balance speed with cost-effectiveness.</li> <li>Establishing clear goals and expectations. Set measurable targets for both speed and cost optimization, and track progress collaboratively. This fosters accountability and encourages teams to find creative solutions that address both priorities.</li> </ul> <p>Remember, successful FinOps involves collaboration and understanding, not dictating or penalizing. By working together with speed-focused teams, FinOps practitioners can identify win-win situations that address both the need for agility and the responsibility for cost-effectiveness.</p> <p>Ultimately, the key is to promote a culture of shared responsibility for cloud costs while acknowledging the value of speed and agility for the business. This collaborative approach enables organizations to leverage the cloud's full potential for innovation and growth without compromising on financial sustainability.</p> </li> <li> <p>True or False: The primary goal of FinOps is cost savings, and growth and velocity are secondary considerations.</p> <p>False</p> <p>Explicaci\u00f3n: In highly competitive spaces, the goal of FinOps is often about driving more features and faster growth, not just cost savings.</p> </li> <li> <p>What is the recommended approach for automation in FinOps?</p> <p>Follow a clearly defined process for automation.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>Automate all processes simultaneously: While automation can be beneficial, rushing into it without a plan can lead to inefficient practices, unforeseen consequences, and potential disruptions. A systematic approach is crucial for successful FinOps automation.</li> <li>Rely on external consultants for automation: While external expertise can be helpful, relying solely on consultants for automation can create dependence and hinder internal understanding and ownership of the process. Building internal capabilities for FinOps automation is key for long-term success.</li> <li>Avoid automation in FinOps processes: This is the least recommended approach. FinOps thrives on streamlining and optimizing processes, and automation plays a crucial role in achieving this. Manual tasks are susceptible to human error and inefficiency, while automation can improve accuracy, speed, and cost-effectiveness.</li> </ul> <p>Therefore, the most effective approach for FinOps automation is to:**</p> <ul> <li>Define clear goals and priorities: Identify the specific processes you want to automate and align them with your overall FinOps objectives.</li> <li>Evaluate potential impact: Analyze the benefits and potential risks of automating each process, considering factors like cost savings, efficiency gains, and potential disruptions.</li> <li>Develop a phased approach: Don't try to automate everything at once. Prioritize high-impact processes and implement automation in stages, allowing for testing, adaptation, and continuous improvement.</li> <li>Utilize appropriate tools and technology: Choose automation tools and platforms that are compatible with your cloud environment and FinOps practices.</li> <li>Invest in training and development: Ensure your team has the necessary skills and knowledge to understand, implement, and manage automated FinOps processes.</li> </ul> <p>By following a clearly defined and strategic approach, you can leverage automation to streamline your FinOps activities, improve cost transparency and control, and unlock the full potential of your cloud investments. Remember, effective FinOps automation should be a collaborative effort that combines technology with human expertise to achieve optimized and sustainable cloud costs.</p> </li> <li> <p>What is a critical factor for achieving FinOps goals, especially in the \"Operate\" phase?</p> <p>Combining visibility, responsibility, and role definition.</p> <p>Here's why the other options are not the best fit:</p> <ul> <li>Strict adherence to automated processes: While automation plays a vital role in the \"Operate\" phase, solely relying on it can hinder adaptability and miss opportunities for further optimization. A balance between automation and human oversight is crucial.</li> <li>Focusing solely on usage optimization: While optimizing usage is important, the \"Operate\" phase also focuses on continuously refining cloud cost management practices, evaluating cost allocation models, and adapting to changing needs. It's a broader scope than just usage optimization.</li> <li>Reducing overall budget allocations: This approach might seem efficient, but it doesn't consider the potential value delivered by cloud resources within budget constraints. The \"Operate\" phase aims to optimize costs while ensuring resources effectively support business objectives.</li> </ul> <p>Therefore, combining visibility, responsibility, and role definition forms the backbone of successful FinOps in the \"Operate\" phase. This entails:</p> <ul> <li>Maintaining transparent cost visibility: All stakeholders should have access to accurate and up-to-date cost data to understand their resource usage and associated expenses.</li> <li>Ensuring shared accountability: Clearly defined roles and responsibilities empower individuals and teams to take ownership of their cloud costs and optimize them within their domain.</li> <li>Adapting and refining practices: Regular review and analysis of cost data, usage patterns, and optimization strategies allow for continuous improvement and adjustment to evolving needs.</li> </ul> <p>By fostering collaboration, shared ownership, and data-driven decision-making, the \"Operate\" phase of FinOps can translate initial cost optimization gains into sustained financial stability and value through the efficient and responsible use of cloud resources.</p> <p>Remember, the \"Operate\" phase is not just about maintaining the status quo; it's about leveraging continuous improvement and adaptation to maximize the financial and operational benefits of the cloud for the long term.</p> </li> <li> <p>Which of the following factors contribute to the success of a FinOps? (Select Three)</p> <p>Establishing a common lexicon on cloud spending.</p> <p>Fostering collaboration between finance and technology teams.</p> <p>Implementing FinOps processes incrementally.</p> <p>Let me break down why the other options are not ideal:</p> <ul> <li>Maximizing cloud spending without constraints: This contradicts the core principles of FinOps, which emphasize cost optimization and maximizing value from cloud investments.</li> <li>Avoiding collaboration between finance and technology teams: Strong collaboration between these teams is crucial for effective FinOps. Finance provides financial expertise and budgeting skills, while technology teams offer insights into resource usage and optimization opportunities.</li> <li>Embracing a static long-term planning approach: FinOps requires agility and adaptability to respond to changing business needs and cloud technologies. A static plan wouldn't allow for adjustments based on data and ongoing evaluations.</li> </ul> <p>Establishing a common language, implementing practices incrementally, and fostering collaboration between finance and technology teams are key factors that contribute to the success of a FinOps practice. Maximizing spending, avoiding collaboration, and limiting visibility, on the other hand, would hinder its effectiveness.</p> </li> <li> <p>What should organizations focus on when dealing with teams of different maturity levels in the FinOps lifecycle?</p> <p>Focusing on the critical aspects relevant to each team's maturity.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>Criticizing less mature teams: This is counterproductive and demoralizing. It hinders collaboration and progress, potentially causing teams to resist further engagement with FinOps practices.</li> <li>Encouraging competition among teams: While striving for improvement is good, framing it as competition can create unhealthy rivalries and divert focus from the overall goal of optimized cloud costs.</li> <li>Ignoring the differences in maturity levels: This can lead to ineffective strategies and missed opportunities. Tailoring the approach to individual needs is crucial for successful FinOps implementation across all teams.</li> </ul> <p>Therefore, focusing on the critical aspects relevant to each team's maturity is the most effective approach for several reasons:</p> <ul> <li>Customized support: It provides targeted guidance and resources based on specific needs and challenges. Crawl-stage teams might need basic budgeting and tagging support, while Walk-stage teams might benefit from automation tools and advanced cost allocation strategies.</li> <li>Faster progress: Addressing immediate challenges and delivering quick wins builds momentum and motivates less mature teams to continue their FinOps journey.</li> <li>Efficient resource allocation: Focusing on impactful actions for each stage leverages resources effectively and avoids wasting time on irrelevant tasks.</li> <li>Collaborative environment: Tailored support fosters collaboration and knowledge sharing across different maturity levels, promoting a unified FinOps culture.</li> </ul> <p>Remember, a successful FinOps approach embraces inclusivity and recognizes that diverse maturity levels are natural in any organization. By focusing on individual needs, providing targeted support, and fostering collaboration, you can guide all teams on a path towards optimized cloud costs and maximized value from your cloud investments.</p> </li> <li> <p>True or False: The primary goal of the Action stage in FinOps is to create new reports, with minimal focus on turning off cloud resources.</p> <p>False</p> <p>Explicaci\u00f3n The Action stage in FinOps involves processes and activities that enable organizations to reach their goals, including turning off unnecessary cloud resources for efficiency.</p> </li> <li> <p>How does unit economics help in decision-making during the optimize phase of FinOps?</p> <p>By providing a framework for evaluating the cost-effectiveness of different optimization options.</p> <p>Here's why the other options are not the sole focus of unit economics in the optimize phase:</p> <ul> <li>Focusing only on operational metrics: While operational metrics are important, they don't directly quantify the financial impact of optimization choices. Unit economics adds the financial lens to understand how operational changes translate into cost savings or value improvement.</li> <li>Reducing cost per subscriber: This specific goal might be an outcome of applying unit economics principles, but it's not the defining characteristic. Unit economics can reveal opportunities to optimize beyond just subscriber-based costs, potentially impacting other cost components like infrastructure or data storage.</li> <li>Increasing RI coverage: Reserved Instances (RIs) can be a cost-optimization strategy, but unit economics goes beyond specific tactics. It provides a framework for evaluating the potential cost benefits and trade-offs of any optimization option, including RIs compared to other options like on-demand pricing or spot instances.</li> <li>Automating processes: Automation is valuable in the optimize phase, but it's a tool, not the driving force of decision-making. Unit economics helps in choosing which processes to automate based on their potential impact on the overall cost-effectiveness of cloud usage.</li> </ul> <p>Therefore, understanding unit economics during the optimize phase enables organizations to:</p> <ul> <li>Quantify the potential cost savings or revenue gains from different optimization options.</li> <li>Compare the cost-effectiveness of various resource configurations, pricing models, and optimization strategies.</li> <li>Prioritize optimization initiatives based on their financial impact and alignment with business goals.</li> <li>Track progress towards cost optimization goals by monitoring how unit economics evolve over time.</li> </ul> <p>By providing a robust framework for financial analysis and decision-making, unit economics becomes a crucial tool for organizations to identify and implement the most effective cost optimization strategies during the FinOps optimize phase.</p> <p>Remember, successful FinOps in the optimize phase goes beyond simply implementing cost-saving tactics. It involves understanding the financial implications of each decision and choosing the options that provide the most significant and sustainable value for the organization. Unit economics empowers you to make those informed choices and move towards optimized cloud costs that align with your business objectives.</p> </li> <li> <p>In FinOps, what does the 'Iron Triangle' refer to?</p> <p>Cost, performance, and reliability.</p> <p>Here's why:</p> <ul> <li>Cloud infrastructure, development, and operations: These are important elements of FinOps, but they don't represent the specific trade-offs inherent in the Iron Triangle concept.</li> <li>Unit economics, revenue impact, and operational metrics: These are relevant concerns in FinOps, but the Iron Triangle focuses on a more fundamental level of resource management, balancing core technical requirements.</li> <li>Operations, finance, and business teams: These stakeholder groups are crucial for FinOps collaboration, but the Iron Triangle represents a specific set of technical trade-offs, not organizational roles.</li> </ul> <p>The \"Iron Triangle\" in FinOps draws an analogy from project management principles, highlighting the constant juggling act between:</p> <ul> <li>Cost: Minimizing cloud spend through efficient resource utilization and cost-saving strategies.</li> <li>Performance: Ensuring adequate performance and scalability to meet business needs without resource bottlenecks.</li> <li>Reliability: Guaranteeing dependable and stable cloud services with minimal downtime or service disruptions.</li> </ul> <p>These three factors are in constant tension: optimizing for lower costs might compromise performance, while prioritizing high performance might incur higher expenses. Achieving optimal balance requires careful consideration of trade-offs and implementing strategies like:</p> <ul> <li>Cost-benefit analysis: Evaluating different resource configurations to find the right balance between cost and performance.</li> <li>Hybrid approaches: Utilizing various pricing models like on-demand, reserved instances, and spot instances based on usage patterns.</li> <li>Automation: Automating infrastructure and resource management to improve efficiency and cost-effectiveness.</li> <li>Monitoring and optimization: Continuously monitoring resource utilization and costs to identify opportunities for further optimization.</li> </ul> <p>By understanding the \"Iron Triangle\" and its implications, FinOps practitioners can make informed decisions about cloud resource allocation, pricing models, and optimization strategies, ensuring a balanced and sustainable approach to managing cloud costs while meeting business needs effectively.</p> <p>Remember, the \"Iron Triangle\" is a valuable framework for navigating the complexities of cloud resource management. By acknowledging the trade-offs and employing smart strategies, organizations can optimize their cloud investments for both cost-effectiveness and performance, maximizing the value they derive from their cloud environment.</p> </li> <li> <p>How can unit economics help in situations where increased spend is required for performance improvement?</p> <p>By making intentional choices based on cross-functional conversations.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>By decreasing application performance: This contradicts the purpose of spending for performance improvement and doesn't align with the goals of unit economics.</li> <li>By ignoring the impact on revenue: Unit economics emphasize understanding the financial implications of decisions, including the impact on both costs and revenue. Ignoring revenue would hinder informed decision-making.</li> <li>By reducing overall cloud spend: While reducing costs is a significant aspect of unit economics, it shouldn't come at the expense of necessary performance improvements that can positively impact the business.</li> </ul> <p>Therefore, using unit economics in scenarios requiring increased spend for performance improvement involves:</p> <ul> <li>Cross-functional conversations: Engaging developers, operations, finance, and business stakeholders in discussions about performance benchmarks, cost implications, and potential revenue gains ensures a holistic perspective and informed decision-making.</li> <li>Data-driven analysis: Unit economics provide metrics like cost per unit performance, return on investment (ROI), and cost-benefit analysis to quantify the trade-offs between increased spend and potential performance gains.</li> <li>Prioritization: By analyzing the cost-benefit of various performance improvement options, prioritizing initiatives with the highest ROI optimizes spending and maximizes value.</li> <li>Strategic resource allocation: Allocate resources efficiently within the increased budget, using unit economics to compare resource configurations, pricing models, and optimization strategies to find the best balance between cost and performance.</li> <li>Monitoring and adapting: Continuously monitor actual performance improvements and costs after the increased spending. Unit economics enable tracking ROI and adjusting strategies if needed to ensure sustained value from the performance investments.</li> </ul> <p>By facilitating informed conversations, data-driven analysis, and strategic resource allocation, unit economics helps organizations make intentional choices about increasing spend for performance improvement, ensuring these investments deliver the desired outcomes and contribute to overall business success.</p> <p>Remember, unit economics shouldn't be solely focused on minimizing costs but on finding the optimal balance between costs and the value delivered, including potential performance improvements that can drive revenue growth and improve customer satisfaction. By leveraging unit economics effectively, organizations can navigate the complexities of balancing costs with performance goals and make strategic investment decisions that maximize the value they derive from their cloud resources.</p> </li> <li> <p>True or False: Starting FinOps practices is recommended only when an organization faces a crisis in cloud spending.</p> <p>False!</p> <p>While a cloud spending crisis can certainly be a catalyst for starting FinOps practices, it's definitely not the only or ideal reason to do so. In fact, starting FinOps early offers numerous benefits:</p> <ul> <li>Proactive cost optimization: By establishing good practices and visibility from the outset, organizations can prevent potential cost issues before they escalate.</li> <li>Smoother scaling and growth: When FinOps principles are embedded from the beginning, scaling your cloud environment becomes easier and more cost-effective.</li> <li>Cultural shift towards cost awareness: Starting early fosters a culture where everyone involved in cloud decisions understands the financial implications and prioritizes value creation.</li> <li>Easier adoption and adaptation: Implementing FinOps gradually allows for smoother learning, adaptation, and continuous improvement compared to a rushed response to a crisis.</li> </ul> <p>Therefore, while a crisis can prompt action, it's far from the only reason to embrace FinOps. Proactive implementation offers more significant advantages and sets organizations on a path for sustainable cloud usage optimization and value creation.</p> </li> <li> <p>What is the significance of tracking the North Star metric with low entropy in unit economics?</p> <p>It ensures decisions in one part of the business do not affect metrics used by others.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>It increases overall cloud spend: This is not necessarily true. A low-entropy NSM could actually help optimize cloud spend by focusing on efficiency and value delivered per unit.</li> <li>It requires frequent changes in the chosen metric: While the optimal NSM might evolve over time, a low-entropy metric should be relatively stable and represent a core value driver for your business, reducing the need for frequent changes.</li> <li>It makes the metric less relevant for decision-making: On the contrary, a low-entropy NSM is highly relevant for decision-making due to its focus on core value and its resistance to external influences.</li> </ul> <p>So, why is low entropy crucial for the NSM in unit economics?</p> <ul> <li>Clarity and focus: A low-entropy NSM is clear, concise, and directly tied to your core business value. This helps ensure everyone in the organization is aligned towards a common goal and can make decisions based on the same metric.</li> <li>Reduced noise and bias: Low entropy minimizes the influence of internal or external factors that might distort the metric, making it a more reliable indicator of true performance and efficiency.</li> <li>Informed trade-offs: When decisions in one part of the business don't significantly impact the NSM used by others, it becomes easier to make informed trade-offs and optimize resources across departments without disrupting individual team goals.</li> </ul> <p></p> </li> <li> <p>What does the term 'activity-based costing' involve in FinOps?</p> <p>Managing cost drivers actively.</p> <p>Here's why the other options are not the best fit:</p> <ul> <li>Reducing cloud usage: While optimizing cloud usage is a FinOps goal, ABC is a methodology for assigning costs to activities and understanding their drivers, not simply a cost-reduction tactic.</li> <li>Automating billing processes: Automating billing is valuable for FinOps, but it doesn't directly relate to the core concept of ABC, which focuses on cost allocation and analysis.</li> <li>Setting monthly budgets: Budgeting is important in FinOps, but ABC delves deeper into understanding the reasons behind specific costs and identifying opportunities for optimization within those constraints.</li> </ul> <p>Activity-based costing (ABC) involves:</p> <ul> <li>Identifying key cloud activities: These are the processes or functions that consume cloud resources, such as running virtual machines, data storage, or application deployments.</li> <li>Analyzing cost drivers: For each activity, you identify the specific factors that influence its cost, such as resource type, usage patterns, or workload demands.</li> <li>Allocating costs based on drivers: Instead of simply distributing costs evenly or based on resource consumption, you assign them to each activity based on the identified cost drivers, providing a more nuanced understanding of where expenses originate.</li> <li>Optimizing activities: By understanding the cost drivers, you can identify inefficiencies and optimize activities to reduce unnecessary expenses or improve resource allocation.</li> </ul> <p>In FinOps, using ABC can provide several benefits:</p> <ul> <li>Improved cost transparency: Shows the true cost of specific cloud activities, enabling targeted optimization efforts.</li> <li>Data-driven decision-making: Provides insights into the cost drivers of different services and workloads, allowing for informed choices about resource allocation and pricing models.</li> <li>Shared accountability: Creates ownership for cloud costs within teams responsible for specific activities, promoting cost awareness and optimization efforts.</li> </ul> <p>While implementing ABC in FinOps can be complex, it offers a powerful framework for understanding and managing cloud costs effectively. By actively managing cost drivers and optimizing activities, organizations can achieve significant cost savings and maximize the value they derive from their cloud investments.</p> <p>Remember, ABC is not a one-size-fits-all solution, and its successful implementation requires careful planning, data analysis, and collaboration across different teams within the organization. However, it can be a valuable tool for FinOps practitioners seeking to gain deeper insights into their cloud costs and drive sustainable cost optimization.</p> </li> <li> <p>True or False: Decentralizing decision-making about resource usage is a core principle of FinOps.</p> <p>True.</p> <p>Decentralizing decision-making about resource usage is indeed a core principle of FinOps, empowering individual teams to manage their own cloud usage.</p> <p>Reference: https://www.finops.org/framework/principles/</p> </li> <li> <p>In unit economics, what scenario might lead to adjusting the performance of a free-tier offering?</p> <p>When cloud spend exceeds the projected increase in revenue.</p> <p>Here's why the other options are not as likely to trigger an adjustment:</p> <ul> <li>When cloud spend decreases: While a sudden drop in cloud spend might require investigation, it wouldn't necessarily lead to changes in the free tier performance specifically. Other factors like cost optimization or reduced usage might explain the decrease.</li> <li>When revenue decreases: A decrease in revenue could be a factor to consider, but it wouldn't automatically necessitate adjusting the free tier. Other strategies like cost optimization or marketing efforts might be explored first.</li> <li>When the free tier is introduced: Introducing a new free tier typically involves careful planning and consideration of expected impacts. Adjustment might happen later based on usage data and performance, but not immediately upon introduction.</li> </ul> <p>However, when cloud spend starts exceeding the projected increase in revenue due to the free tier, it raises concerns about the sustainability of the model. This scenario suggests that:</p> <ul> <li>The free tier might be attracting too many users who aren't converting to paying customers.</li> <li>The resources provided in the free tier might be too generous, leading to excessive cloud costs.</li> <li>The user engagement or conversion rate from free to paid tiers might be lower than expected.</li> </ul> <p>In such situations, adjusting the performance of the free tier could involve:</p> <ul> <li>Limiting resource availability: Reducing CPU, storage, or other features offered in the free tier to manage cloud costs while still providing a basic functionality.</li> <li>Imposing usage restrictions: Setting quotas or caps on resource usage for free tier users to prevent excessive consumption.</li> <li>Introducing tiered free plans: Offering different levels of free service with varying resource allocations and features to target different user segments.</li> <li>Enhancing conversion efforts: Improving the onboarding experience, providing clear calls to action, and highlighting the benefits of paid plans to encourage free tier users to upgrade.</li> </ul> <p>Remember, continuously monitoring the performance of your free tier in terms of user engagement, conversion rates, and cloud costs is crucial. When cloud spend outpaces revenue growth, adjusting the free tier becomes a strategic decision to ensure the long-term success and sustainability of your business model. By finding the right balance between attracting users, encouraging conversions, and managing costs effectively, you can leverage the power of the free tier to drive both user acquisition and sustainable business growth.</p> </li> <li> <p>How can unit economics help decide whether to invest more in cloud resources?</p> <p>By considering the long-term benefits for the business.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>By ignoring business growth: Unit economics should actually take business growth into account. It helps analyze how additional cloud resources can contribute to increasing revenue, expanding customer base, or improving operational efficiency, thus supporting business growth.</li> <li>By making unintentional choices: Unit economics encourages informed decision-making by providing data-driven insights into the potential costs and benefits of additional cloud investments. Unintentional choices could lead to missed opportunities or financial pitfalls.</li> <li>By avoiding cross-functional conversations: Effective unit economics implementation involves collaboration between teams like finance, operations, and development. Cross-functional discussions help assess technical feasibility, resource needs, and financial ROI from different perspectives.</li> </ul> <p>Therefore, the key strength of unit economics in making investment decisions lies in its holistic approach:</p> <ul> <li>Analyzing cost-benefit: By quantifying the costs associated with additional cloud resources and estimating the potential benefits in terms of revenue growth, operational efficiency, or improved scalability, unit economics helps evaluate the financial feasibility of the investment.</li> <li>Long-term perspective: It goes beyond immediate savings and considers the long-term impact on the business. This includes analyzing how the additional resources can contribute to sustained competitive advantage, cost optimization, or future growth opportunities.</li> <li>Data-driven insights: Unit economics leverages metrics like cost per unit of output, return on investment (ROI), and breakeven points to provide data-driven evidence to support or reject investment proposals.</li> <li>Cross-functional collaboration: Effective unit economics involves bringing together different stakeholders like finance, operations, and development to share expertise, analyze data, and discuss potential risks and rewards of the investment.</li> </ul> <p>By considering these factors, unit economics enables organizations to make informed and strategic decisions about cloud resource investments. It helps identify the initiatives with the highest potential ROI, ensure financial sustainability, and ultimately contribute to the long-term success and growth of the business.</p> </li> <li> <p>What role does the North Star metric play in determining if cloud spend is 'wasted'?</p> <p>It helps identify if cloud spend aligns with business growth.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>It doesn't impact the assessment of wasted spend: The NSM directly connects cloud spend to the organization's core value driver. If spend isn't driving growth in the NSM, it raises questions about its efficiency and potential waste.</li> <li>It focuses only on short-term influences: While the NSM considers immediate performance, it also takes a longer-term view, assessing the sustainable impact of cloud spend on business growth. Short-term fluctuations might not definitively indicate waste, but a sustained disconnect between spend and the NSM could be a red flag.</li> <li>It is unrelated to cloud spend assessment: The NSM serves as a central point of reference for all business decisions, directly impacting resource allocation and ultimately, cloud spend. Understanding how spend aligns with the NSM's trajectory is crucial for optimizing costs and avoiding waste.</li> </ul> <p>Therefore, the NSM plays a critical role in assessing cloud spend by:</p> <ul> <li>Providing a benchmark: As a measure of core business value, the NSM acts as a benchmark against which cloud spend can be compared. If spend significantly outpaces NSM growth, it indicates the possibility of inefficient resource utilization or unnecessary expenses.</li> <li>Prioritizing investments: Focusing on initiatives that contribute to the NSM helps ensure cloud investments align with the overall business goals. This reduces the risk of spending on resources that don't contribute to the core value driver, reducing potential waste.</li> <li>Facilitating data-driven decisions: The NSM provides quantifiable data that can be used to analyze the relationship between cloud spend and its impact on business growth. This data-driven approach helps identify areas where spend can be optimized or redirected to activities with higher ROI.</li> <li>Driving continuous improvement: Regularly monitoring the relationship between cloud spend and the NSM promotes ongoing cost awareness and encourages efforts to identify and eliminate sources of waste.</li> </ul> <p>Remember, the NSM is not a binary indicator of \"wasted\" vs. \"effective\" spend. It's a dynamic tool that helps identify areas for improvement and optimize cloud investments for sustained growth and value creation. By effectively connecting cloud spend to the core business objective, the NSM empowers organizations to make informed decisions that maximize the effectiveness and efficiency of their cloud infrastructure.</p> </li> <li> <p>True or False: FinOps practices are primarily beneficial for organizations with massive cloud deployments and multimillion-dollar bills.</p> <p>False!</p> <p>While organizations with large cloud deployments and significant spending undoubtedly benefit from FinOps practices, the statement that these practices are only relevant for such cases is a misconception. In fact, FinOps offers immense value for organizations of all sizes, regardless of their cloud usage or budget:</p> <ul> <li>Smaller organizations: Even with limited spending, managing cloud resources effectively can save money, improve efficiency, and avoid future cost issues. FinOps provides the framework and tools to do this effectively.</li> <li>Startups and early-stage ventures: For startups, optimizing cloud expenses is crucial for maximizing limited resources and ensuring sustainable growth. FinOps helps establish good practices early on and avoid falling into cost traps later.</li> <li>Non-profit organizations: Managing resources responsibly is even more critical for non-profits, where wasted funds directly impact their ability to serve their mission. FinOps provides the tools and techniques for responsible and effective cloud usage.</li> </ul> <p></p> </li> <li> <p>How does the 'Iron Triangle' impact decision-making in FinOps?</p> <p>It balances cost, performance, and reliability in decisions.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>It emphasizes cost reduction only: While cost optimization is a significant aspect of FinOps, the Iron Triangle recognizes the trade-offs between cost, performance, and reliability. Reducing costs without considering the impact on performance or reliability could lead to suboptimal outcomes.</li> <li>It focuses on operational metrics: While operational metrics are important for monitoring and managing cloud resources, the Iron Triangle focuses on a higher level of decision-making, balancing the fundamental trade-offs between the three core priorities.</li> <li>It avoids cross-functional conversations: On the contrary, the Iron Triangle encourages cross-functional conversations by bringing together stakeholders from finance, operations, development, and business teams to discuss the trade-offs and prioritize goals based on the specific scenario.</li> </ul> </li> <li> <p>What does the \"Crawl, Walk, Run\" model specifically emphasize in FinOps implementation?</p> <p>A gradual and incremental approach to learning from each step.</p> <p>Here's why the other options are not ideal:</p> <ul> <li>Immediate and large-scale adoption of FinOps practices: While the \"Crawl, Walk, Run\" model encourages ongoing progress, it emphasizes starting small and scaling up gradually, not diving headfirst into large-scale changes.</li> <li>A slow and cautious approach to FinOps implementation: While the model advocates for deliberate progress, it's not simply about being slow. It focuses on learning from each step and building upon that knowledge for continuous improvement.</li> <li>Rapid deployment of financial forecasting tools: Implementing forecasting tools can be part of the \"Walk\" or \"Run\" stages, but the model itself doesn't prioritize that specific action. It's more concerned with the overall approach to learning and growth in FinOps maturity.</li> </ul> <p>Therefore, the \"Crawl, Walk, Run\" model emphasizes:</p> <ul> <li>Starting small and building upon success: Begin with simple, achievable initiatives in a limited scope. This reduces risk and allows for quick wins that build confidence and momentum.</li> <li>Iterative learning: Each step provides valuable insights and lessons learned. The model encourages reflecting on these learnings and using them to inform the next step, rather than making drastic leaps without feedback.</li> <li>Gradual expansion: As comfort and competence increase, the scope and complexity of FinOps initiatives can be gradually expanded. This ensures a sustainable and adaptable approach to growth.</li> <li>Continuous improvement: The model is not about reaching a \"Run\" stage and stopping there. It encourages ongoing evaluation, learning, and refinement of FinOps practices over time.</li> </ul> <p>By emphasizing gradual learning and adaptation, the \"Crawl, Walk, Run\" model provides a well-structured and manageable approach to implementing FinOps in organizations. It helps avoid overwhelming challenges and costly mistakes while encouraging steady progress towards optimizing cloud costs and maximizing the value of cloud investments.</p> </li> <li> <p>Which of the following is NOT a part of core principles of FinOps?</p> <p>Maximizing cloud spending without constraints.</p> <p>Here's why the other options are core principles of FinOps:</p> <ul> <li>Decentralizing decision-making about resource usage: This empowers teams to optimize their cloud usage based on their specific needs and knowledge, fostering ownership and cost awareness.</li> <li>Embracing the variable cost model of the cloud: FinOps recognizes that cloud resources are typically pay-as-you-go, allowing for flexible scaling and avoiding unnecessary fixed costs.</li> <li>Teams work together to continuously improve for efficiency and innovation: This collaborative approach is crucial for identifying and implementing optimization opportunities, leading to a culture of shared responsibility and sustained value creation.</li> </ul> </li> <li> <p>True or False: Organizations should only start implementing FinOps when they face cloud migration challenges.</p> <p>False!</p> <p>FinOps offers benefits beyond addressing migration-specific issues.</p> <p></p> </li> <li> <p>Which of the following is the key element required to connect FinOps with TBM(Technology Business Management)?</p> <p>Shared taxonomy.</p> <p>Here's why the other options are less relevant:</p> <ul> <li>Shared language: While a shared language is important for communication and collaboration, it's not the core foundation for connecting FinOps and TBM. Both frameworks use specific financial and technical terms, but a taxonomy provides a more specific and structured mapping of those terms to common categories and structures.</li> <li>Common goals: While FinOps and TBM share broad goals of cloud cost optimization and value creation, a shared taxonomy provides the concrete framework for aligning those goals by ensuring consistent categorization and measurement of cloud resources and costs across both frameworks.</li> <li>Mutual agreements: Agreements can be helpful for specific initiatives or collaborations, but they wouldn't necessarily be the key underlying element for connecting two entire frameworks like FinOps and TBM. A shared taxonomy offers a standardized approach that goes beyond individual agreements.</li> <li>Unified budget: A unified budget might be a desired outcome of connecting FinOps and TBM, but it's not the initial element required to make the connection. A shared taxonomy provides the basis for mapping and consolidating cost data from different sources under the same structure, which can then lead to a unified budget as a later step.</li> </ul> <p>Therefore, a shared taxonomy serves as the critical foundation for connecting FinOps and TBM. It enables consistent cost mapping, allows for comparable data analysis, and facilitates collaboration between finance and technology teams in optimizing cloud usage and costs. This shared understanding of categories and structures forms the backbone for aligning the goals and practices of both frameworks.</p> <p>Remember, both frameworks play crucial roles in managing and optimizing cloud investments, and establishing a strong connection between them can significantly enhance your organization's cloud cost consciousness and value creation through cloud resources.</p> <p>Reference : https://www.finops.org/wg/finops-tbm-navigating-coexisting-disciplines/</p> </li> <li> <p>How does FinOps address the challenges of managing public cloud spend?</p> <p>By providing a flexible and agile approach.</p> <p>Here's why the other options are less likely:</p> <ul> <li>By increasing complexities: Although implementing FinOps processes can involve initial learning and setup, its core principles aim to simplify and streamline cloud cost management, not add complexity.</li> <li>By aligning with TBM practices only: While aligning with TBM (Technology Business Management) can be beneficial for FinOps, it's not the only way FinOps addresses spend challenges. FinOps offers its own set of principles and practices beyond just TBM integration.</li> <li>By reducing the frequency of cost monitoring: Frequent cost monitoring is a crucial aspect of FinOps, as it allows for continuous optimization and identification of potential issues. Reducing monitoring would contradict this principle.</li> <li>By centralizing control of all cloud operations: Centralizing control can be helpful in some situations, but FinOps also promotes decentralized decision-making based on local knowledge and team ownership. A flexible and agile approach allows for adapting to various cloud environments and team structures.</li> </ul> </li> <li> <p>True or False : Uncontrolled cloud spending can lead to unexpected and unsustainable costs, causing surprise and potentially hampering financial planning and resource allocation across the organization.</p> <p>**True! **</p> <p>Uncontrolled cloud spending can indeed lead to unexpected and unsustainable costs, causing surprise and potentially hampering financial planning and resource allocation across the organization.</p> <p></p> </li> <li> <p>Which of the following is true advantage for cloud-first companies?</p> <p>Scalability and innovation,</p> <p></p> </li> <li> <p>In Cloud Computing some costs can be considered fixed and some are variable. Which of the following costs would generally a fixed costs, meaning predictable monthly or annual costs?</p> <p>Support and Maintenance</p> <p>Support and Maintenance are almost always a fixed cost meaning that you would pay a certain amount for a specific amount of support/users/response times. Variable costs would be about any resource you would use.</p> <p>Please review this page before the exam. https://www.finops.org/resources/terminology/</p> </li> <li> <p>Your currently working with the head of finance to understand how to identify specific cloud usage to specific business units. What would we use to account for costs for each business units and then debit the business unit for the cloud usage?</p> <p>Chargebacks and showbacks both represent processes where departments are asked to be accountable for their technology usage and resources by being given visibility of the costs associated with it.</p> <p>Chargebacks offer departmental visibility into IT resource usage and also charge departments for their use</p> <p>Showbacks offer departmental visibility into IT resource usage without charging departments for their use.</p> </li> <li> <p>Which of the following statements would be true regarding a FinOps practice? (Select One)</p> <p>At its core, FinOps is a cultural practice.</p> <p>FinOps Requires a Cultural Shift At its core, FinOps is a cultural practice. This operating model is the most efficient way for teams to manage their cloud costs. Using FinOps, teams can come together to deliver faster while gaining financial and operational control.</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal.</p> <p>What is the primary goal for the procurement business unit?</p> <p>Cloud platform relationship management.</p> <p>Explicaci\u00f3n: The primary goal for the procurement business unit when adopting a FinOps function is: Cloud platform relationship management.</p> <p></p> <p>Here's why the other options are incorrect:</p> <p>Assurance that cloud investments are aligned with business objectives: While this is a broader goal of FinOps, it's not specifically focused on procurement's role. Other stakeholders like finance and business units might be more concerned with this aspect.</p> <p>Quickly bring new products and features to market with an accurate price point: This might be a goal for product development or marketing, not directly related to procurement's FinOps involvement.</p> <p>Drive best practices into the organization through education, standardization, and cheerleading: This could be a secondary or supportive role for procurement, but not their primary focus within FinOps.</p> <p>There are clearly labeled roles for each 'Persona' and we must learn these for the exam.</p> <p>Reference : https://www.finops.org/framework/personas/#procurement</p> </li> <li> <p>FinOps Principles are north stars that guide the activities of our FinOps practice. They\u2019re developed by FinOps Foundation members, and honed through experience. When it comes to the FinOps principle of 'A centralized team drives FinOps' which of the following statements would be true? (Select Two)</p> <p>Centralized discount buying process removes rate negotiations from engineering team consideration</p> <p>Centrally govern and control Committed Use Discounts, Reserved Instances, and Volume/Custom Discounts with Cloud Providers</p> <p>Using a granular approach is recommended and Track team-level targets to drive accountability is not under the A centralized team section, it is under 'Everyone takes ownership for their cloud usage'</p> <p>Please review this page before the exam. https://www.finops.org/framework/principles/</p> </li> <li> <p>Distributed decision making coupled with the move to variable spending in cloud allows technology teams to efficiently partner with finance and business teams to make informed decisions that drive continual optimization. (True or False)  </p> <p>True</p> <p>Explicaci\u00f3n. Statement is correct. Remember that FinOps is really about collaboration. Please review the following</p> </li> <li> <p>True or False:In FinOps decisions are driven by the business value of the cloud.</p> <p>True</p> <p>Explicaci\u00f3n: Cloud has been commonly looked to a 'Cost Center'. With FinOps we look at the cloud as a business value creator. One of the main roles of FinOps is to maximize the value of the cloud spending.</p> <p>Reference: https://www.finops.org/framework/principles/</p> </li> <li> <p>When managing cloud costs specifically around containers there are several things in Google Cloud we can do to manage costs and identify these costs. Which of the following would be ways we could break down costs? (Select Three)</p> <p>Labels</p> <p>Namespaces</p> <p>Billing Hierarchy</p> <p>Explicaci\u00f3n: Google Cloud provides some robust methods to identify costs and also segment. Availability Zones is actually an AWS concept so thats incorrect. One method, recommended by Debo Aderibigbe, a Google Cloud Billing Product Manager, is to break down costs by:</p> <p>Billing Hierarchy: Organizations, folders, projects, normalizing them with cross-cloud concepts: Linked Accounts, Tags, Subscriptions, etc.</p> <p>Resources: Compute cores, RAM, GPU, TPU, Load Balancers, Persistent Disk, Custom Machines, Network Egress</p> <p>Namespaces: labeling specific, isolated containers</p> <p>Labels: Teams, cost centers, app names, environment, and more</p> <p>With a deep labeling and tagging of all of these cost drivers, users can improve the accuracy of how they invoice teams, audit costs, allocate costs, optimize overrun costs, model budgeting scenarios, or fit workload costs within quotas or under budget caps.</p> <p>Please review this page before the exam...https://www.finops.org/projects/calculating-container-costs/</p> </li> <li> <p>FinOps is about saving money. (True or False)</p> <p>False</p> <p>Explicaci\u00f3n:FinOps is about making money. Cloud spend can drive more revenue, signal customer base growth, enable more product and feature release velocity, or even help shut down a data center. Please refer to this page.</p> <p>What is FinOPs</p> </li> <li> <p>When considering shared costs we know that there are three main ways to accomplish this according to the FinOps Foundation. What approach would we want to use if we wanted to use a 'relative percentage of direct costs' for our costs? (Select One)</p> <p>Proportional</p> <p>There are typically three ways to split up shared costs: Proportional: Based on relative percentage of direct costs Even split: Split total amount evenly across targets Fixed: User-defined coefficient (the sum of coefficients needs to be 100%) This page here is perhaps one of the most important pages to review and understand before the exam.</p> <p>Identifying Shared Costs</p> </li> <li> <p>When rightsizing your containers which of following would be focused on responding dynamically to different conditions? (Select One)</p> <p>Autoscaling</p> <p>Explicaci\u00f3n Auto-scaling provides the ability to respond dynamically to different conditions, such as increased or decreased demand. This can take some architecting and iterative adjustments to get right for your application, and there is room for waste along the way. However, the more tightly your horizontal pod autoscaling (when we need more / less pods) and cluster autoscaling (when do we need more / less nodes) are configured, the less waste and unnecessary cost to run your application.</p> <p>Please review this page before the exam. (Section Optimize)</p> <p>Reference:</p> <p>https://learn.microsoft.com/en-us/azure/architecture/best-practices/auto-scaling</p> <p>https://www.finops.org/framework/domains/cloud-usage-optimization/</p> </li> <li> <p>Multiple Selection: (Select two) Your currently adopting FinOps in your organization and are in Stage 1 - Planning for FinOps in an organization. Which of the following two exercises would be understand Stage 1?</p> <p>Do Your Research </p> <p>Create a Plan</p> <p>Reference: https://www.finops.org/projects/adopting-finops/</p> </li> <li> <p>What is the model of constraints that is used in project management called? (Select One)</p> <p>Iron Triangle</p> <p>Explicaci\u00f3n The Iron Triangle (Project Triangle\u201d), is a model of the constraints of project management: speed, cost, and quality. It contends that a project manager can trade among constraints in determining the way a project is completed. A change in one constraint necessitates changes in the others to compensate. With FinOps we would use measures such as good, fast and cheap.</p> </li> <li> <p>Your organization has recently adopted a FinOps based method for dealing with cloud costs and adopting FinOps. Currently, your organization has recently completed 'Step Two' for FinOps culture in your company. What would the next stage for the organization to accomplish? (Select One)</p> <p>Preparing the organization for FinOps</p> <p>Explicaci\u00f3n: The next step after Stage 1 - Planning for FinOps in an Organization (Laying the groundwork) is the Stage 2 - Socializing FinOps for adoption in an organization. Then After Step 2 would be Stage 3 - Preparing the organization for FinOps</p> <p>Please reference this page before the exam. Adopting FinOps</p> </li> <li> <p>Which of the following would be correct when comparing TBM to FinOps? (Select Three)</p> <p>TBM takes a top-down view whereas FinOps takes a more bottoms up view.</p> <p>FinOps has great controls into cloud, granulatity, and prescriptive methods but does not incluide decision data.</p> <p>FinOps focuses on cloud processes, cloud data, and cloud execution whereas TBM provides the genereal ledger (GL) data (labor costs, licensing, revenue data)</p> <p>Explicaci\u00f3n TBM is a value management framework for decision making by CIOs, CTOs, CFO, and the team. Technology Business Management defines the tools, processes, data, and people needed to manage the business of technology.(Looks at all IT Investments and is a top down model) FinOps is the practice of bringing financial accountability to the variable spend model of cloud, enabling distributed</p> <p>teams to make business trade-offs between speed, cost, and quality.(Cloud Only and is bottom up model) TBM = Broad Focused while FinOps = Very Focused</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal. What is the primary goal for a Chief Technology Officer (CTO)? (Select One)</p> <p>Leverage technology to give the business a market and competitive advantage</p> <p>Explicaci\u00f3n: There are clearly labeled roles for each 'Persona' and we must learn these for the exam.</p> <p>Reference : https://www.finops.org/framework/personas/</p> </li> <li> <p>In a FinOps based organization spending is a concern only for finance team and the FinOps team members. (True or False)</p> <p>False</p> <p>Explicaci\u00f3n: False.</p> <p>Spending is a concern for everyone, whether the finance team, engineering, production, etc. In a FinOps-based organization, spending is a concern for all teams, not just the finance team and FinOps team members. FinOps is a collaborative effort that requires everyone in the organization to be aware of and accountable for their cloud spending. This includes engineering teams, product teams, and even executives. Here are some of the reasons why spending is a concern for all teams in a FinOps-based organization:</p> <ul> <li>Engineering teams: Engineering teams are responsible for designing and implementing cloud-based systems. They need to be aware of the cost implications of their design decisions.</li> <li>Product teams: Product teams are responsible for developing and launching new products and features. They need to understand the cost of running these products and features in the cloud.</li> <li>Executives: Executives are ultimately responsible for the financial performance of the organization. They need to have a clear understanding of cloud spending and how it is impacting the bottom line.</li> </ul> <p>By making spending a concern for all teams, organizations can achieve the following benefits:</p> <ul> <li>Reduced cloud costs: When everyone is aware of the cost of cloud usage, they are more likely to make decisions that will optimize costs.</li> <li>Increased agility: When teams are empowered to make their own decisions about cloud usage, they can move more quickly and innovate more effectively.</li> <li>Improved financial transparency: When everyone has access to accurate and up-to-date information about cloud spending, there is more transparency and accountability.</li> </ul> <p>In short, FinOps is not just about saving money. It is also about driving business value by enabling teams to make informed decisions about cloud usage. When spending is a concern for all teams, organizations can achieve the best of both worlds: they can save money and innovate more effectively.</p> <p>Please review What is FinOps</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal. What is the primary goal for the Engineering Lead? (Select One)</p> <p>Delivery faster and high quality services to the organization, whilst maintaining business as usual</p> <p>Explicaci\u00f3n: There are clearly labeled roles for each 'Persona' and we must learn these for the exam.</p> <p>References: FinOps Personas</p> </li> <li> <p>In the Inform Stage of the FinOps cycle which of the following would be true regarding. (Select One)</p> <p>The IT, finance, and business departments rely on timely and relevant data to create customized FinOps frameworks and processes.</p> <p>Explanation: The Inform stage of the FinOps cycle is focused on providing timely and relevant data to the IT, finance, and business departments. This data is used to create customized FinOps frameworks and processes that align with the organization's operational and financial goals. The Inform stage is about collecting, analyzing, and presenting data to inform decision-making and optimize cloud operations. Option 1 is incorrect because it describes the Optimize stage of the FinOps cycle. Option 3 and 4 are not directly related to the Inform stage.</p> </li> <li> <p>'IT Asset Management' would be under what domain according to the FinOps Foundation? (Select One)</p> <p>Understanding Cloud Usage and Cost</p> <p>Explicaci\u00f3n: There are six specific domains in FinOps according to the FinOps Foundation. We will want to be able to understand what topics are covered by each domain. The FinOps Foundation has put out an excellent downloadable poster that we should use as a study aid. https://www.finops.org/img//resources/FinOps%20Poster_011021.pdf</p> </li> <li> <p>Which phase of the FinOps cycle is where continuous optimization should really occur? (Select One)</p> <p>Operate</p> <p>Explicaci\u00f3n The lifecycle phase operate in summary is focused continuous improvement. It is critical you understand these three phases for the exam. Review this page here. FinOps Phases</p> </li> <li> <p>Which of the following statements would be correct about Weighted Average Cost of Capital? (Select One)</p> <p>This is the rate company is expected to pay on average to all its securities holders to finance the operation of the business.</p> <p>Explicaci\u00f3n: eighted Average Cost of Capital - the rate the company is expected to pay on average to all its securities holders to finance the operation of the business. Importantly this is set by the external market (what the market is willing to pay for various forms of the company\u2019s securities) not by management.</p> <p>Please review this page before the exam. https://www.finops.org/resources/terminology/</p> </li> <li> <p>Which of the following methods would we use if we wanted to ensure 'a user defined coefficient' ?</p> <p>Fixed</p> <p>Explicaci\u00f3n: There are typically three ways to split up shared costs: Proportional: Based on relative percentage of direct costs Even split: Split total amount evenly across targets Fixed: User-defined coefficient (the sum of coefficients needs to be 100%) This page here is perhaps one of the most important pages to review and understand before the exam.</p> <p>Reference:  A Guide to Spreading Out Shared Cloud Costs (finops.org)</p> </li> <li> <p>FinOps Principles are north stars that guide the activities of our FinOps practice. These principles are clearly broken down and we must encourage members to practice these. When it comes to these principles which of the following activities would be under the 'Teams need to Collaborate' principle? (Select One)</p> <p>Define governance and controls for cloud usage</p> <p>Explicaci\u00f3n Honestly, some of these activities may or not intuitively seem like they are under specific principles. This is perhaps the most confusing part of the content to remember.</p> <p>For Teams need to collaborate these are the activities specified by the FinOps Foundation:</p> <p>Finance moves at the speed and granularity of IT</p> <p>Engineering considers cost as a new efficiency metric</p> <p>Continuously improve your practice to gain efficiency and innovation Define governance and controls for cloud usage</p> <p>Please refer to this page before the exam. https://www.finops.org/framework/principles/</p> </li> <li> <p>What is the primary goal of a FinOps Practitioner in an organization? (Select One)</p> <p>Drive best practice into the organization through education, standardization and cheerleading.</p> <p>Explicaci\u00f3n: Being a FinOps practitioner about collaboration thru several means. There are clear objectives, metrics, benefits and frustrations that come with the job. A FinOps champion will be able to describe the value of FinOps more effectively, minimizing the time and effort to gain alignment.</p> <p>FinOps Personas</p> </li> <li> <p>How has cloud computing impacted enterprise financial operations? (Select Two)</p> <p>Change from a fixed spending model to a variable spending model</p> <p>Utilization of an OPEX based procurement</p> <p>Explicaci\u00f3n: With advent of Cloud Computing organizations went from a fixed and predictable spending model to cloud driven model that based on variable and less predictable spending model. Because of these spending changes organization went to a procurement model that is now OPEX based as compared to the on premises which was a procurement model that driven by CAPEX funding.</p> </li> <li> <p>You have started working a new role in an organization that practices FinOps. Your new role has focused on FinOps for some of your duties. Which of the following would likely be considered a FinOps professionals responsibility? (Select Two)</p> <p>Maximize the value of the cloud spend</p> <p>Continuously improve upon the metrics for efficiency</p> <p>Explicaci\u00f3n: A FinOps professional should be more administrative in nature. Proactive but not a manager either. The role should be focused on metrics and providing value. The other answers would be a better choice for an engineer or cloud architect.</p> </li> <li> <p>AWS has a wealth of FinOps capabilities that we could use as an AWS user. Which of the following AWS Services would we use to track costs and usage and send alerts when a threshold is exceeded? (Select One)</p> <p>AWS Budgets</p> <p>Explicaci\u00f3n: AWS Budgets allows users to set up alerts, initiated when actual or forecasted costs and usage exceed predetermined budget thresholds. The goal of AWS Budgets is to reduce unintentional over-spending. AWS Budgets also allows for the configuration of automated responses if costs or usage exceed desired limits.</p> </li> <li> <p>You have been asked to assemble the first FinOps team for your company. What would be two factors you must consider when organizing your team? (Select Two)</p> <p>Complexity of your cloud usage</p> <p>Complexity of your organization</p> <p>Explicaci\u00f3n: The complexity of your organization can entail the layers of your management, size of the business units, experience of employees, etc. The complexity of your cloud usage can be really critical to understand what cost structure are efficient and what ones may not be. Team members from engineering think and speak differently as opposed to members from finance so we must have a common approach to communications to reduce complexity.</p> </li> <li> <p>What is the purpose of a blended rate?</p> <p>To standardize the rate you pay for the same tupe of resource</p> <p>Explicaci\u00f3n: Blended Rate information on its invoice showing the effective rate for a group of resources with the same attributes where some of the resources are receiving a discount from reservations and some are not.</p> </li> <li> <p>What is the primary purpose of the FinOps Framework?</p> <p>To provide a set of concepts and measurements to support an analysis of current operating maturity.</p> <p>Expliaci\u00f3n:</p> <p></p> <p>FinOps Framework Overview:</p> <p>FinOps Maturity Model:</p> </li> <li> <p>What is the concept of a \"Lens\" used for in FinOps?</p> <p>To talk about how you inspect and analyze a FinOps Practice</p> <p>Explicaci\u00f3n References: https://www.finops.org/projects/finops-assessment/</p> </li> <li> <p>How has cloud computing impacted enterprise financial operations?</p> <p>Utilization of OPEX based procurement</p> <p>Explicaci\u00f3n: With advent of Cloud Computing organizations went from a fixed and predictable spending model to cloud driven model that based on variable and less predictable spending model. Because of these spending changes organization went to a procurement model that is now OPEX based as compared to the on premises which was a procurement model that driven by CAPEX funding.</p> </li> <li> <p>You have been asked to assemble the first FinOps team for your company. What would be two factors you must consider when organizing your team? (Select Two)</p> <p>Complexity of your organization</p> <p>Complexity of the Cloud usage</p> <p>Explicaci\u00f3n: The complexity of your organization can entail the layers of your management, size of the business units, experience of employees, etc. The complexity of your cloud usage can be really critical to understand what cost structure are efficient and what ones may not be. Team members from engineering think and speak differently as opposed to members from finance so we must have a common approach to communications to reduce complexity.</p> </li> <li> <p>What is the name of the file format used in AWS Cost and Usage reports? (Select One)</p> <p>CSV</p> <p>Explicaci\u00f3n: The AWS Cost and Usage Reports (AWS CUR) contains the most comprehensive set of cost and usage data available.</p> <p></p> </li> <li> <p>Which of following is a simple formula for cloud spending? (Select One)</p> <p>Spend = Usage \u00d7 Rate</p> <p>The simple formula plays a key part of deciding both how to optimize and who in the organization takes optimization. Usage could be the number of hours of a resource used and the rate is the hourly (or per second) amount paid for the usage of that resource.</p> </li> <li> <p>\u201cManage Commitment Based Discounts\u201d would be under what domain according to the FinOps Foundation? (Select One)</p> <p>Cloud Rate Optimization</p> <p>There are six specific domains in FinOps according to the FinOps Foundation. We will want to be able to understand what topics are covered by each domain. The FinOps Foundation has put out an excellent downloadable poster that we should use as a study aid.</p> <p>https://www.finops.org/img//resources/FinOps%20Poster_011021.pdf</p> </li> <li> <p>Which of the following is true regarding teams working in FinOps organizations? (Select Two)</p> <p>All teams have a role to play in FinOps </p> <p>Teams have different motivators that drive spend and savings.</p> <p>Some other basic realities are with FinOps teams are 1. Teams need to work together with a balance of empathy for one another\u2019s goals. 2. FinOps practitioners help align teams to organizational goals. Teams inside your organization are able to work together to understand one another\u2019s goals alongside a centralized FinOps team that is helping to build out reporting and practices to assist everyone in achieving them.</p> </li> <li> <p>What is the model of constraints that is used in project management called? (Select One)</p> <p>Iron Triangle</p> <p>Explicaci\u00f3n: The Iron Triangle (Project Triangle\u201d), is a model of the constraints of project management: speed, cost, and quality. It contends that a project manager can trade among constraints in determining the way a project is completed. A change in one constraint necessitates changes in the others to compensate. With FinOps we would use measures such as good, fast and cheap.</p> </li> <li> <p>Your FinOps lead has requested all cloud expenses and would like to understand all costs realized and paid for this quarter. What type of expense would consider this? (Select One)</p> <p>Operational Expenditure (OPEX)</p> <p>Explicaci\u00f3n: When you capitalize something, it becomes an asset of the company, whether or not it gets expensed within a specific period(CAPEX). If it benefits only the current period, then it\u2019s an expense that is expended in this period with no future benefit, making it an operational expense(OPEX). Capitalization causes total outlays to differ from expenses in a similar period, with the delta being that which is capitalized.</p> </li> <li> <p>The FinOps journey consists of three detailed phases which are Inform, Optimize and Operate. Which of the following statements would be a correct description of the Inform Phase? (Select One)</p> <p>Empowering organizations and teams with visibility, allocation, benchmarking, budgeting, and forecasting.</p> <p>The on-demand and elastic nature of cloud, along with customized pricing and discounts, makes it necessary for accurate and timely visibility for intelligent decisions. Accurate allocation of cloud spend based on tags, accounts, or business mappings enable accurate chargeback and showback. Business and financial stakeholders also want to ensure they are driving ROI while staying within budget and accurately forecasting spend, avoiding surprises. Benchmarking as a cohort and against teams provides organizations with the necessary metrics to develop a high performing team.</p> <p>For the exam it is critical we can distinguish between the Phases\u2026 References:  https://www.finops.org/framework/phases/</p> </li> <li> <p>What is the name of the organization that created the FinOps Principles?</p> <p>FinOps Fundation</p> <p>Explicaci\u00f3n References: https://www.finops.org/framework/principles/</p> </li> <li> <p>What is the name of the first principle?</p> <p>Teams need to collaborate</p> <p>Explicaci\u00f3n References: https://www.finops.org/framework/principles/</p> </li> <li> <p>What drives continuous improvement?</p> <p>Automation of resources</p> <p>Explicaci\u00f3n References: https://www.finops.org/framework/principles/</p> </li> <li> <p>What is the Data Efficiency team responsible for?</p> <p>Tracks the latencies to access and use data, and can estimate the performance impact of applying data efficiency approaches.</p> <p>Explicaci\u00f3n References: https://www.finops.org/projects/managing-data-efficiency-playbook/</p> </li> <li> <p>How frequently are forecast updates needed in FinOps?</p> <p>As required by finance</p> <p>Explicaci\u00f3n References: https://www.finops.org/framework/phases/</p> </li> <li> <p>What is the most common type of forecast?</p> <p>Annual forecast</p> <p>Explicaci\u00f3n References: https://www.finops.org/framework/phases/</p> </li> <li> <p>What is budgeting for Cloud?</p> <p>A process of collecting estimated expenses for a specific period of time</p> </li> <li> <p>What does the term 'favorable to budget' mean?</p> <p>There are less expenses than as planned inthe budget</p> <p>Explicaci\u00f3n References: https://www.finops.org/framework/capabilities/budget-management/</p> </li> <li> <p>Which of the following are not considered goals of the FinOps journey? (Select Two)</p> <p>Efficiency</p> <p>SLO's</p> <p>Explanation: The Inform Phase of the FinOps journey is about understanding the current state of your system. Due to the on-demand and elastic nature of access to cloud resources, along with variable pricing structures, it is critical to have access to timely and accurate system metrics to make appropriate, informed decisions. In this phase there are five primary goals: Visibility Allocation Benchmarking Budgeting Forecasting</p> <p>Please review this page before the exam https://www.finops.org/framework/phases/</p> </li> <li> <p>When proposing the adoption of a FinOps function within an organization, there will be a need to brief a variety of personas among the executive team to gain approval, buy-in, and involvement in conducting FinOps and achieving its goals. Every role has a clearly documented Primary Goal. What is the primary goal for the procurement business unit? (Select One)</p> <p>Cloud platform relationshio management</p> </li> <li> <p>Please refer to the graphic of the Phases of the FinOps Lifecycle for this question What is the correct order of the FinOps Lifecycle phases? Please replace 1,2,3 with correct sequence (Select One)</p> <p>Inform, Optimize and Operate</p> </li> <li> <p>Which of the following is most important when Benchmarking performance of internal cloud teams?</p> <p>Benchmarking cloud teams consistenly against each other</p> </li> <li> <p>why would companies consider including trainers or process design experts on the FinOps team?</p> <p>creating training or processes that are independient of functional domain can be as important as actual FinOps Capability training to FinOps team success</p> </li> <li> <p>In Aligning optimization plans to the business, which of the following are the most important?</p> <p>Ensuring that commintment-based discounts are purchased before optimization is done</p> </li> <li> <p>Which of these would NOT be an example of a Rightsizing action?</p> <p>changing database instances to run on smaller servers</p> </li> <li> <p>In which phase of the FinOps lifecycle would the FinOps team execute a purchase of a commitment-based discount that meets the threshold of their commitment purchasing metric?</p> <p>Optimize</p> </li> <li> <p>Which of these is a KPI a FinOps team might use to determine what percentage of a commitment purchase is being applied to running resources?</p> <p>commitment/reservation coverage%</p> </li> <li> <p>Which of these is NOT a feature of FinOps?</p> <p>FinOps should be completed prior to beginning cloud migration</p> </li> <li> <p>What two outcomes does the FinOps team seek above all? (Select two)</p> <p>Optimization and operation</p> <p>Breaking down cultural barriers and distributed responsability for managibg Cloud usage Cost</p> </li> <li> <p>Which item is a common mistake a FinOps might make while Rightsizing?</p> <p>Not considering peak demand, but planning using average</p> </li> <li> <p>By reducing resource usage by removing or only running a resource when we need it, we can reduce overall cost. this describes</p> <p>Workload management</p> </li> <li> <p>The FinOps team's skills in the various FinOps capabilities will grow from being basic to greater mastery over time as it iterates through the FinOps lifecycle. this concept is best described as</p> <p>Crawl, Walk, Run</p> </li> <li> <p>Each time it cycles through the FinOps lifecycle, the FinOps team will:</p> <p>build experience and mature its capabilities</p> </li> <li> <p>During the operate phase of the FinOps lifecycle, which of these would be a key to success with FinOps stakeholders?</p> <p>Automation of all rightsizing actions</p> </li> <li> <p>You have started working a new role in an organization that practices FinOps. Your new role has focused on FinOps for some of your duties. Which of the following would likely be considered a FinOps professionals responsibility? (Select Two)</p> <p>Continuously improve upon the agreed metrics for efficiency</p> <p>Maximize the value of the cloud spend</p> </li> <li> <p>What is the primary goal of a FinOps Practitioner in an organization? (Select One)</p> <p>Drive best practices into the organization through education, standardization, and cheerleading</p> </li> <li> <p>IT Asset Management' would be under what domain according to the FinOps Foundation? (Select One)</p> <p>Understanding Cloud Usage and Cost</p> </li> <li> <p>Your organization has recently adopted a FinOps based method for dealing with adopting FinOps. Currently, your organization has recently completed 'Laying the Groundwork' for FinOps culture in your company. What would the next stage for the organization to accomplish? (Select One)</p> <p>Socializing FinOps for adoption in an organization</p> </li> <li> <p>Cloud providers such as AWS and GCP allow for discounts by letting customers commit to a cloud service provider for a set amount of resource usage such as using a Reserved Instance or Committed Discounts. What is the term we would call this pricing strategy? (Select One)</p> <p>Reservations</p> </li> <li> <p>The spending patterns have changed quite a bit when compared to on premises consumption models. Which of the following statements would correct how DevOps and Cloud have changed IT purchasing. (Select two)</p> <p>Engineers have the power to spend company money with code</p> <p>spending is dynamic.</p> </li> <li> <p>When a resource charge is discounted by a reservation what would that usage be called? (Select One)</p> <p>Covered</p> </li> <li> <p>What is the model of constraints that is used in project management called? (Select One)</p> <p>Iron Triangle</p> </li> <li> <p>How has cloud computing impacted enterprise financial operations?</p> <p>Change from a fixed spending model to a variable spending model</p> </li> <li> <p>What is the correct definition of an image? (Select One)</p> <p>A template of a container with the software that needs to be run.</p> </li> <li> <p>The CFO has just approached the FinOps team members and requested that all costs that are being submitted and analyzed should be amortized. The CFO also requested that the costs be allocated to each business unit. Would this be a best practice? (True or False)</p> <p>True</p> </li> <li> <p>Which of the following is the FinOps simple definition of 'forecasting'. (Select One)</p> <p>Forecasting is the practice of predicting future spending</p> </li> <li> <p>Ticketing systems, Monitoring systems, Configuration management systems, workflow systems, CI/CD pipeline automation tools, all can provide ways to automate parts of your FinOps process (True or False)</p> <p>True</p> </li> <li> <p>Which of the following are not considered goals of the FinOps journey?</p> <p>Efficiency</p> </li> <li> <p>Which of the following would be considered a 'measure of success' for a FinOps based organization? (Select Two)</p> <p>Overall Tagging Compliance is 90% or above </p> <p>The cloud cost reporting ecosystem becomes a fundamental aspect of the IT department</p> </li> <li> <p>Your currently working with the head of finance to understand how to identify specific cloud usage to specific business units. What would we use to account for costs for each business units and then debit the business unit for the cloud usage?</p> <p>Chargeback</p> </li> <li> <p>Which of the following would be the most direct description of what FinOps is about? (Select One)</p> <p>FinOps brings financial accountability to the variable spend model of cloud.</p> </li> <li> <p>which of the following would be true regarding the Inform Stage of the FinOps cycle . (Select One)</p> <p>The IT, finance, and business departments rely on timely and relevant data to create customized FinOps frameworks and processes.</p> </li> <li> <p>Anomaly detection isn\u2019t just about identifying expense thresholds but It\u2019s also important to identify unusual spikes in usage. (True or False)</p> <p>True</p> </li> <li> <p>FinOps as we likely learned requires a culture shift in how our organization addresses cloud spend. Which of the following would be a true statement regarding the decision making in a FinOps organization? (Select One)</p> <p>Distributed decision making coupled with the move to variable spending in cloud allows technology teams to efficiently partner with finance and business teams to make informed decisions that drive continual optimization.</p> </li> <li> <p>The variable cost model of the cloud is a risk for cloud spending of an organization. (True or False)</p> <p>False</p> </li> <li> <p>In a FinOps based organization spending is a concern only for finance team and the FinOps team members. (True or False)</p> <p>False</p> </li> <li> <p>In the world of FinOps the process of spreading out shared costs is iterative, and evolves over time.(True or False)</p> <p>True</p> </li> <li> <p>Should the FinOps team be a gatekeeper to cloud spending? (Select One)</p> <p>No</p> </li> <li> <p>Your FinOps lead has requested all cloud expenses and would like to understand all costs realized and paid for this quarter. What type of expense would consider this? (Select One)</p> <p>Operational ependiture (OPEX)</p> </li> <li> <p>Which of the following is an open source container management platform that we use in the cloud routinely? (Select One)</p> <p>Kubernetes</p> </li> <li> <p>Distributed decision making, coupled with the move to variable spending in cloud, allows technology teams to efficiently partner with finance and business teams to make informed decisions that drive continual optimization. (True or False)</p> <p>True</p> </li> <li> <p>Which of the following methods would we use if we wanted to ensure 'a user defined coefficient' ? (Select One)</p> <p>Fixed</p> </li> <li> <p>There are effectively two 'levers' that are used to reduce costs in cloud computing. What are they? (Select Two)</p> <p>Avoiding Costs </p> <p>Reducing Costs</p> </li> <li> <p>Which of the following are some common reasons it can be harder to bill and report on Kubernetes costs? (Select Two)</p> <p>one-to-one mappings of tags to teams don\u2019t cover some of the complex use cases that container utilization can create</p> <p>Containerized environments are much more dynamic than noncontainerized ones</p> </li> <li> <p>In Finops, Everyone Should take ownership of their cloud usage. (True or False)</p> <p>True</p> </li> <li> <p>Which of the following would be the correct description of what a 'cluster' is in Kubernetes? (Select One)</p> <p>A group of server instances, managed by container orchestration.</p> </li> <li> <p>In FinOps, Rate and Discount Optimization is Centralized. (True or False)</p> <p>True</p> </li> <li> <p>Finance teams should bring their deeper understanding of Finance concepts to the FinOps team and help the organization understand the Finance impacts of decisions at every stage (True or False)</p> <p>True</p> </li> <li> <p>Which of the following term used to refer to company owned or company-controlled data center space. Usually used to differentiate from public cloud environments where application migrations are targeting workloads.</p> <p>On-premises</p> </li> <li> <p>Which of the following is a cloud cost optimization strategy for storage?</p> <p>Using cold storage for infrequently accessed data</p> </li> <li> <p>Which of the following is a cloud cost optimization strategy for content delivery?</p> <p>Using CDN services instead of just object storage</p> </li> <li> <p>What is the main challenge after cloud migration is finished?</p> <p>Cost management and efficient optimization</p> </li> <li> <p>What are the teams that need to collaborate strongly for effective cloud cost management and optimization?</p> <p>Finance, operation, product mamagement, and engineering teams</p> </li> <li> <p>What are some of the commonly cited pain points when it comes to financial cloud management?</p> <p>All of the above</p> </li> <li> <p>What is required for accurate cloud cost forecasting?</p> <p>Deep expertise and real-time data</p> </li> <li> <p>What is cloud cost projection?</p> <p>The process of estimating the impacts of changes to your company's cloud hosting solution</p> </li> <li> <p>What is the first step in cloud expense management?</p> <p>Keeping track of past expenses</p> </li> <li> <p>What is the purpose of creating a cloud spend budget?</p> <p>To set guidelines for maximum cloud spend</p> </li> <li> <p>What is one of the reasons that lead to oversizing in cloud environments?</p> <p>Weak performance of testing methods</p> </li> <li> <p>What is the benefit of using a cloud cost comparison tool?</p> <p>To project your company\u00b4s cloud costs against other cloud platforms and regions</p> </li> <li> <p>What is the purpose of multi-cloud adoption?</p> <p>to reduce cloud costs by switching between multiple cloud platforms.</p> </li> <li> <p>Which of the following is a cloud cost optimization strategy for virtual machines?</p> <p>Using spot instances for short-term task</p> </li> <li> <p>What does workload management suggest in terms of variable cost resources?</p> <p>Only run the resource while using it</p> </li> <li> <p>What is the primary goal of the CEO in the context of FinOps?</p> <p>Assurance that cloud investments are aligned with business objectives.</p> </li> <li> <p>What is the primary goal of the IT Finance Manager in the context of FinOps?</p> <p>Accurately budget, forecast, and report cloud costs.</p> </li> <li> <p>Which of the following is a cost optimization strategy for object storage in the cloud?</p> <p>enabling retention settings for partial objects</p> </li> <li> <p>What is the primary goal of the Procurement role in the context of FinOps?</p> <p>Cloud platform relationship management.</p> </li> <li> <p>What is the frustration of the CFO role in the context of FinOps?</p> <p>Extreme pressure to either justify or bring the cloud bill down</p> </li> <li> <p>Which of the following is a cloud cost driver?</p> <p>All of the above</p> </li> <li> <p>What is the term for the process of forecasting future cloud costs based on historical usage patterns?</p> <p>Cost forecasting</p> </li> <li> <p>Which of the following is an AWS service that </p> <p>AWS CloudFormation</p> </li> <li> <p>What is the primary benefit of using reserved instances?</p> <p>Lower hourly cost</p> </li> <li> <p>What is the term for the process of analyzing and optimizing cloud spend on an ongoing basis?</p> <p>Cloud cost management</p> </li> <li> <p>Which of the following is a pricing model used by cloud providers?</p> <p>All of the above</p> </li> <li> <p>How can organizations gain a better understanding of the cost of their cloud?</p> <p>By trackimg their cloud usage and costs across their entire cloud estates</p> </li> <li> <p>What is the benefit of having visibility into cloud spend?</p> <p>It enchances understanding of the real cost of cloud and how it translates into bisiness value</p> </li> <li> <p>What is the purpose of a financial audit in financial operations?</p> <p>To ensure the accuracy and completeness of financial data</p> </li> <li> <p>Which of the following is NOT a typical function of a Cloud financial operations (FinOps) team?</p> <p>Developing and executing marketing campaigns</p> </li> <li> <p>Your currently adopting FinOps in your organization and are in Stage 1 - Planning for FinOps in an organization. Which of the following two exercises would be understand Stage 1? (Select Two)</p> <p>Do Your Research </p> <p>Create a Plan</p> </li> <li> <p>FinOps Principles are north stars that guide the activities of our FinOps practice. These principles are clearly broken down and we must encourage members to practice these. When it comes to these principles which of the following activities would be under the 'Teams need to Collaborate' principle? (Select One)</p> <p>Define governance and controls for cloud usage</p> </li> <li> <p>Which of the following is a cloud cost optimization strategy for networking?</p> <p>Consolidating data transfers</p> </li> <li> <p>The FinOps journey consists of three iterative phases \u2015 Inform, Optimize and Operate. Which of the following statements would be a correct description of the Inform Phase? (Select One)</p> <p>Empowering organizations and teams with visibility, allocation, benchmarking, budgeting, and forecasting.</p> </li> <li> <p>AWS provides what is called a 'Blended Rate' on its invoices. What is the blended rate showing? (Select One)</p> <p>Shows the effective rate for a group of resources with the same attributes</p> </li> <li> <p>In Cloud Computing some costs can be considered fixed and some are variable. Which of the following costs would generally a fixed costs, meaning predictable monthly or annual costs? (Select One)</p> <p>Support and Maintenance</p> </li> <li> <p>What is the first step in planning for FinOps in an organization?</p> <p>Seeking out stakeholders within the organization</p> </li> <li> <p>In order to determine adoption strategy for FinOps in an organization during research, what should be done? </p> <p>Conduct research on pain points being experienced by the organization during your conversations, such as cloud costs breaking busuness cases, general perception of cost overruns, lack of cost visibility by cloud consumers, etc.</p> </li> <li> <p>Which of the following should be done to measure the FinOps function and stakeholder engagement in planning for FinOps in an organization?</p> <p>Identity KPIs (Key Performance Indicators) that will be used to measure the FinOps function</p> </li> <li> <p>What is the main cause of cloud wastage?</p> <p>Running non-productionresources 24/7</p> </li> <li> <p>What is the potential savings that companies can make by turning off idle resources overnight and on weekends?</p> <p>65%</p> </li> <li> <p>Why would companies consider including trainers or process design experts on the FinOps team?</p> <p>Creating training or processes that are independent of functional domain can be as important as actual FinOps Capability training to FinOps team success.</p> </li> <li> <p>The daily view in Azure cost explorer is designed to show what?</p> <p>Irregularities as cost spikes or dips from day to day</p> </li> <li> <p>Your currently working with the head of finance to understand how to identify specific cloud usage to specific business units. What would we use to account for costs for each business units and then debit the business unit for the cloud usage?</p> <p>Chargeback</p> </li> <li> <p>What is the best course of action when wanting to shut off resources?</p> <p>Consult Engineering teams</p> </li> <li> <p>In which maturity level of the FinOps framework are the capabilities well understood and followed within the organization?</p> <p>Run</p> </li> <li> <p>When rightsizing your containers which of following would be focused on responding dynamically to different conditions?</p> <p>Autoscaling</p> </li> <li> <p>Which of the following is an open source container management platform that we use in the cloud routinely?</p> <p>Kubernetes</p> </li> <li> <p>How can organizations gain a better understanding of the cost of their cloud?</p> <p>By tracking their cloud usage and costs across their entire cloud estates</p> </li> <li> <p>What would be some common names that could used for a FinOps team? (Select Three)</p> <p>Cloud Business Office</p> <p>Cloud Economics Team</p> <p>Cloud Center of Excellence</p> </li> <li> <p>Which of the following is NOT a key component of FinOps?</p> <p>Risk assessment and mitigation</p> </li> <li> <p>What is the key challenge of FinOps?</p> <p>Transitioning to a Finops culture from a data center culture</p> </li> <li> <p>Why 'Policy and Governance' frameworks important?</p> <p>Organizations cnnot sustainably deliver business value from cloud without them</p> </li> <li> <p>What are the three types of governance?</p> <p>Guidelines, Guardrails, Automation</p> </li> <li> <p>When configuring access to the Budgets API, what is the best practice for giving multiple IAM users query access to the API?</p> <p>Creating a programmatic access IAM role for each of them</p> </li> <li> <p>What are the two AWS managed policies for budget actions?</p> <p>user and budgets</p> </li> <li> <p>How Cost analysis in Azure used to show a potential budget breach?</p> <p>When there's a potential budget breach, projected overspending is shown in red</p> </li> <li> <p>The daily view in Azure cost explorer is designed to show what?</p> <p>irregularities as cost spikes or dips from day to day.</p> </li> <li> <p>Which of the following are the three ways that we would be able to split up shared costs? (Select Three)</p> <p>Proportional</p> <p>Even Split</p> <p>Fixed</p> </li> <li> <p>Which of the following are the Fin-Ops Maturity Assessment Model steps/phases? (Select Three)</p> <p>Crawl</p> <p>Walk</p> <p>Run</p> </li> <li> <p>Which phase of the FinOps cycle is where continuous optimization should really occur?  (Select One) </p> <p>Operate</p> </li> <li> <p>Distributed decision making coupled with the move to variable spending in cloud allows technology teams to efficiently partner with finance and business teams to make informed decisions that drive continual optimization. (True or False)</p> <p>True</p> </li> <li> <p>Which of the following would be the correct description of what a 'cluster\" is in Kubernetes? (Select One)</p> <p>A group of server instance, manage by container orchestration</p> </li> <li> <p>How many types of forecasting methods are there?</p> <p>four</p> </li> <li> <p>Which of the following is not a type of forecasting?</p> <p>Maximum Forecasting</p> </li> <li> <p>What is the main advantage of Cloud Forecasting?</p> <p>The ability to automatically adapt to changes in cloud spend behavior</p> </li> <li> <p>What is the conservative approach to forecasting?</p> <p>Use the forecast for the last month of the forecast period and project that forward at a flat rate</p> </li> <li> <p>How far into the future do organizations typically forecast workloads?</p> <p>12 months</p> </li> <li> <p>Which of the following NIST Cloud characteristics uses the business model of shared resources in a cloud environment? (Select one)</p> <p>Multi-Tenancy</p> </li> <li> <p>Why is forecasting important?</p> <p>It helps organizations make decisions about the future</p> </li> <li> <p>State whether the following statement is true or False. A capability may sit within one or more Domains, and may encompass a variety of related specific skills and specializations in order to execute successfully. (True or False)</p> <p>True</p> </li> <li> <p>What is the key objective of FinOps teams?</p> <p>To promote both 'cost avoidance,' wich related to usage, and 'cost optimization,' which relates to rate</p> </li> <li> <p>What is the primary driver of effort for engineers?</p> <p>Functionality and delivery deadines</p> </li> <li> <p>What are the two drivers of engineering action?</p> <p>Culture &amp; Governance</p> </li> <li> <p>What is the primary focus of a FinOps team?</p> <p>To drive engineering action on cost avoidance through cultural and governance initiatives</p> </li> <li> <p>What is fundamental to effective cost avoidance?</p> <p>Ownership an accountability</p> </li> <li> <p>Which of the following is not a significant tactic which respondents use to drive accountability?</p> <p>Cost Reduction and Cost Control</p> </li> <li> <p>What is the goal of \"showback\" reporting?</p> <p>To provide real-time information on cloud usage and costs</p> </li> <li> <p>What is the main aim of financial accountability?</p> <p>To join up the organization's financial management processes with the dynamic and granular patterns of cloud spend</p> </li> <li> <p>What is the key element in developing engineer's financial accountability?</p> <p>Chargeback of clous costs</p> </li> <li> <p>What is the best course of action when wanting to shut off resources?</p> <p>Consult with Engineering teams</p> </li> <li> <p>Which of the following is an advantage of consulting Engineering teams before presenting cost optimization savings to leadership?</p> <p>Avoiding accidental conflict by not getting consensus from business units or functional areas.</p> </li> <li> <p>What is the main incentive for volume discounts?</p> <p>To reward large cloud users</p> </li> <li> <p>Which of the following is not needed to identify in order to calculate projected costs correctly on the cloud platform?</p> <p>The Infraesructure costs</p> </li> <li> <p>State whether the following statement is true or false. Benchmarking as a cohort and against teams provides organizations with the necessary metrics to develop a high performing team.</p> <p>True</p> </li> <li> <p>State whether the following statement is true or false. Any company may be in multiple phases at any time depending on which business unit, application or team is on the journey.</p> <p>True</p> </li> <li> <p>State whether the following statement is true or false. The Fin-Ops principles are in no particular order, and they should be taken as a whole.</p> <p>True</p> </li> <li> <p>State whether the following statement is true or false. Teams should understand how their contributions help the organization reach goals.</p> <p>True</p> </li> <li> <p>State whether the following statement is true or false. Teams should not rely on the organization guidance.</p> <p>False</p> </li> <li> <p>State whether the following statement is true or false. In the containerized world, traditional FinOps cost allocation (e.g. capacity planning) is no longer needed.</p> <p>False</p> </li> <li> <p>State whether the following statement is true or false. Shared resources, like containers, create challenges with cost allocation, cost visibility, and resource optimization.</p> </li> </ol> <p>True</p> <ol> <li> <p>What is the billing model for cloud services?</p> <p>Pay-as-you-go</p> </li> <li> <p>You can run Kubernetes on virtual machine services provided by which of the following?</p> <p>All major cloud providers</p> </li> <li> <p>State whether the following statement is true or false. KPIs can be things like active accounts, widgets sold, ad impressions and so forth.</p> <p>True</p> </li> <li> <p>For driver-based forecasting, the goal is not to identify why workloads scale differently from their drivers.</p> <p>False</p> </li> <li> <p>State whether the following statement is true or false. Depending on the maturity of the organization, tagging may be manual, use automated tag hygiene monitoring, or integrated in CI/CD pipelines with tag-or-terminate policies in place.</p> <p>True</p> </li> <li> <p>State whether the following statement is true or false. Trend based forecasting will be able to capture out-of-band events such as launching a new product or feature, launching in a new country, or the effect of TV commercials on consumer behavior.</p> <p>False</p> </li> <li> <p>Multiple Selection (Select Three) Which of the following are part of Fin-Ops Principles ?</p> <p>Teams need to collaborate</p> <p>Everyone takes ownership for their cloud usage</p> <p>A centralized team drives FinOps</p> </li> <li> <p>Which of the following is not a FinOps Domain?</p> <p>True</p> </li> <li> <p>The FinOps journey consists of three iterative phases \u2014 Inform, Optimize and Operate.</p> <p>True</p> </li> <li> <p>State whether the following statement is true or false. Teams and organizations can optimize the environment by buying more resources.</p> <p>False</p> </li> </ol>"},{"location":"03_cisco/fundamentos_python_1/","title":"Fundamentos de Python 1","text":""},{"location":"03_cisco/fundamentos_python_1/#modulo-1-introduccion-a-python-y-a-la-programacion-informatica","title":"M\u00f3dulo 1. Introducci\u00f3n a Python y a la programaci\u00f3n inform\u00e1tica","text":""},{"location":"03_cisco/fundamentos_python_1/#modulo-2-tipos-de-datos-varialbles-operaciones-basicas-de-entrada-y-salida-operadores-basicos","title":"M\u00f3dulo 2. Tipos de datos, varialbles, operaciones b\u00e1sicas de entrada y salida, operadores b\u00e1sicos","text":""},{"location":"03_cisco/fundamentos_python_1/#modulo-3-valores-booleanos-ejecucion-condicional-bucles-listas-y-su-procesamiento-operaciones-logicas-y-de-bit-a-bit","title":"M\u00f3dulo 3. Valores Booleanos, ejecuci\u00f3n condicional, bucles, listas y su procesamiento, operaciones l\u00f3gicas y de Bit a Bit","text":""},{"location":"03_cisco/fundamentos_python_1/#modulo-4-funciones-tuplas-diccionarios-excepciones-y-procesamiento-de-datos","title":"M\u00f3dulo 4. Funciones, tuplas, diccionarios, excepciones y procesamiento de datos","text":""},{"location":"04_english/A1/","title":"A1","text":""},{"location":"04_english/A1/#greetings-farewells","title":"Greetings &amp; farewells","text":""},{"location":"04_english/A1/#saying-hello","title":"Saying Hello","text":"Formal Informal Good morning What\u00b4s up? Good afternoon How's it going? Good evening How are you doing How about you? Hello/Hi <p>Examples:</p> <ul> <li>Hello, I am Eddier</li> <li>Hi, nice to meet you Monica. I'm Eddier</li> <li>Good morning. How are you?</li> <li>Great. What about you?</li> <li>What's up, Monica?</li> <li>No bad. What about you? Who's it going?</li> </ul>"},{"location":"04_english/A1/#saying-goodbye","title":"Saying Goodbye","text":"Formal Informal Have a great day Bye Good bye Bye-bye Good nigth See you! <p>Examples:</p> <ul> <li>Have a great day, Monica</li> <li>Good bye. It was good to see you</li> <li>I'm going to bed now. Good night!</li> <li>Bye-bye, love! Sweet dreams.</li> </ul>"},{"location":"04_english/A1/#part-1","title":"Part 1","text":"image response Hi. My name is Eddier. I am a Consultant You are ... You are a student from Smart He is Freddy. He is a fireman She is Daniela. She is an engineer We are Pedro, Juan and Carlos. We are doctors."},{"location":"04_english/A1/#activity-1","title":"Activity 1","text":"image response I am a ... chef You are a... cashier He is a... truck driver She is a police officer We are... waiters They are... farmers"},{"location":"04_english/A1/#activity-2","title":"Activity 2","text":"image response Who am I? A consultant Who is he A student Who is the person A fireman Who is she An engineer Who are you? Doctors Who are we Soccer players"},{"location":"04_english/A1/#personal-information","title":"Personal information","text":"image response Hi. My name is Eddier I am a consultant You are a student You are a student for Smart He is Freddy He is a fireman She is Daniela She is an engineerr We are Pedro, Juan and Carlos We are doctors They are Mario and Camilo They are soccer players"},{"location":"04_english/A1/#the-albhabet","title":"The Albhabet","text":"letter pronunciation Example A ei as in Angel B bi as in Boy C si as in Cat D di as in Dog E i as in F ef as in Family G yi as in Goat H eich as in House I ai as in Ice cream J yei as in Jam K kei as in King L el as in Lemon M em as in Money N en as in Notebook O o as in Orange P pi as in Potato Q kiu as in Queen R ar as in Rabbit S es as in Start T ti as in Tomato U iu as in Uniform V vi as in Violin W do-bul-iu as in Women X ex as in X-ray Y uai as in Yogurt Z dsi as in Zebra <ul> <li>emilee</li> <li>jayden</li> <li>catherin</li> <li>damian</li> <li>nicholas</li> <li>isabelle</li> <li> <p>zoey</p> </li> <li> <p>chair</p> </li> <li>eraser</li> <li>desk</li> <li>board</li> <li>scissors</li> <li>rulers</li> <li>book</li> <li>Pensicl</li> <li>clip</li> <li>folder</li> </ul> <p>Hello and good morning, my name is Eddier Ocampo, I am from Colombia and I am a consultant for Red Hat company. My email is eddier.ocampo@gmail.com and my number is 3238015629</p>"},{"location":"04_english/A1/#numbers","title":"Numbers","text":"# Example 0 zero Two times zero equals zero 1 one There is one table 2 two There are two kids 3 three There are three apples 4 four There are four cats 5 five There are five pencils 6 six There are six books 7 seven There are seven hens 8 eight There are eigth bananas 9 nine There are nine chickens 10 ten There are ten hamburgers"},{"location":"04_english/A1/#ask-and-tell","title":"Ask and tell","text":""},{"location":"04_english/A1/#pronouns","title":"Pronouns","text":"<ul> <li>I am from Colombia</li> <li>You are from Panam\u00e1</li> <li>He is from Cameroon</li> <li>She is from Autralia</li> <li>It is from England</li> <li>We are from Ireland</li> <li>They are from Brazil, United States, Mexico and United Kindom</li> </ul>"},{"location":"04_english/A1/#countries-nationalities","title":"Countries &amp; Nationalities","text":"Country Nationality Canada Canadians Unites States Americans Belize Belozean Bahamas Bahamian Jamaica Jamaicans Trinidad and Tobago Trinidadian(s)and Tobagonian(s) Guyana Guyanese United Kingdom Britsh Ireland Irish Malta Maltese Australia Autralian New Zealand New Zealander"},{"location":"04_english/A1/#verb-to-be","title":"Verb To be","text":"<ul> <li>Personal Information</li> <li>Do NOT say \"I to be\"</li> <li>Am, Is (She, He, It) Are (You, We, They)</li> <li>A men, a woman or it (is)</li> <li>Positive S + TB + Compl</li> <li>Negative S + Am/Is/Are + Not + Compl </li> <li>Interrogative Am/Is/Are + S + Compl?</li> </ul> Complet form short form I am I'm You are You're She is She's He is He's It is It's Question Answer Is Shakira from Cameroon? No, she isn't. She is from Colombia Is Donald Trump a businessman? Yes he is a businessman Are The Beatles from England? Yes, they are. The Beatles are from england Are Freddie Mercury and Bob Marley singers? Yes, they are. Freddie Mercury and Bob Marley are singers Is Angelina Jolie a lawyer? No, she insn't. She is a famous actress Is the Eifefel Tower from France? Yes, it is. It is from France Is Tom Cruise from New Seeland? No, he ins\u00b4t. he is from the Unetid States <p>Mark Zuckerberg is a media magnate. He is the co-founder of Facebook Inc. His middle name is Elliot. He isn\u2019t from Ireland. He isn't 17 years old. He \u2019s a software developer. His career started in 2004. His wife is Priscilla Chan. His Facebook profile is https://www.facebook.com/zuck .</p>"},{"location":"04_english/A1/#wh-questions","title":"WH Questions","text":"Answer WQ This is a desktop What is it? This flag is from Colombia Where is this flag from? Because he likes teaching other people Why is he a teacher? He is short and funny What is he like? My birthday is on 28 Abril When is your birthday? He is a student Who is he? WQ Answer What time is it? It's five o'clock Where do you live? I live in Guarne Who do you live with? I live with my wife How old are you? I am 42 years old When is new  year's eve? New Year's eve is on December 31 st. Why are you sad? Because I failed Math Which is your coat? My coat is the red one <p>Good morning Sir. Passport, please   Here it is   Sorry, what's your Id numb</p>"}]}